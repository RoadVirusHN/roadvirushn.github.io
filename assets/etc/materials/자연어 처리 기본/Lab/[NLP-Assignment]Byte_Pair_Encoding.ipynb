{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bpe_camper.ipynb의 사본","provenance":[{"file_id":"1Ue3inlDkAVEyLatLKGQ9iP3EIUG5dw9b","timestamp":1613947166310}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"koQ-w1sV34sz"},"source":["# Natural Language Processing\r\n","## Assignment 4: Byte Pair Encoding\r\n","\r\n","### 1. Introduction\r\n","\r\n","- 일반적으로 하나의 단어에 대해 하나의 embedding을 생성할 경우 out-of-vocabulary(OOV)라는 치명적인 문제를 갖게 됩니다. 학습 데이터에서 등장하지 않은 단어가 나오는 경우 Unknown token으로 처리해주어 모델의 입력으로 넣게 되면서 전체적으로 모델의 성능이 저하될 수 있습니다. 반면 모든 단어의 embedding을 만들기에는 필요한 embedding parameter의 수가 지나치게 많습니다.\r\n","이러한 문제를 해결하기 위해 컴퓨터가 이해하는 단어를 표현하는 데에 데이터 압축 알고리즘 중 하나인 byte pair encoding 기법을 적용한 sub-word tokenizaiton이라는 개념이 나타났습니다. \r\n","- 본 과제에서는 byte pair encoding을 이용한 간단한 sub-word tokenizer를 구현해봅니다.\r\n","과제 노트북의 지시사항과 각 함수의 docstring과 [논문](https://arxiv.org/pdf/1508.07909.pdf)의 3페이지 algorithm 1 참고하여 build_bpe 함수를 완성하고 모든 test case를 통과해주세요."]},{"cell_type":"markdown","metadata":{"id":"nNGuOpGM5VZD"},"source":["## 2-1.build_bpe 함수를 완성해주세요."]},{"cell_type":"code","metadata":{"id":"9go8KbPe3s-L","executionInfo":{"status":"ok","timestamp":1613962405930,"user_tz":-540,"elapsed":680,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}}},"source":["from typing import List, Dict, Set\r\n","from itertools import chain\r\n","import re\r\n","from collections import defaultdict, Counter\r\n","\r\n","\r\n","def build_bpe(\r\n","        corpus: List[str],\r\n","        max_vocab_size: int\r\n",") -> List[int]:\r\n","    \"\"\" BPE Vocabulary Builder\r\n","    Implement vocabulary builder for byte pair encoding.\r\n","    Please sort your idx2word by subword length in descending manner.\r\n","\r\n","    Hint: Counter in collection library would be helpful\r\n","\r\n","    Note: If you convert sentences list to word frequence dictionary,\r\n","          building speed is enhanced significantly because duplicated words are\r\n","          preprocessed together\r\n","\r\n","    Arguments:\r\n","    corpus -- List of words to build vocab\r\n","    max_vocab_size -- The maximum size of vocab\r\n","\r\n","    Return:\r\n","    idx2word -- Subword list\r\n","    \"\"\"\r\n","    # Special tokens\r\n","    PAD = BytePairEncoding.PAD_token  # Index of <PAD> must be 0\r\n","    UNK = BytePairEncoding.UNK_token  # Index of <UNK> must be 1\r\n","    CLS = BytePairEncoding.CLS_token  # Index of <CLS> must be 2\r\n","    SEP = BytePairEncoding.SEP_token  # Index of <SEP> must be 3\r\n","    MSK = BytePairEncoding.MSK_token  # Index of <MSK> must be 4\r\n","    SPECIAL = [PAD, UNK, CLS, SEP, MSK]\r\n","\r\n","    WORD_END = BytePairEncoding.WORD_END  # Use this token as the end of a word\r\n","    # YOUR CODE HERE\r\n","    vocab_list = Counter(corpus)\r\n","    vocab = dict([(str(' '.join(x[:-1])) + ' ' + str(x[-1] + ' _'), y) for (x, y) in vocab_list.items()])\r\n","\r\n","    def get_stats(wordsDict):\r\n","      pairs = defaultdict(int)\r\n","      for word, count in wordsDict.items():\r\n","          symbols = word.split()\r\n","          for idx in range(len(symbols)-1):\r\n","              pairs[symbols[idx],symbols[idx+1]] += count\r\n","      return pairs\r\n","\r\n","    def merge_dict(pair, v_in):\r\n","        v_out = {}\r\n","        bigram = re.escape(' '.join(pair))\r\n","        p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\r\n","        for word in v_in:\r\n","            w_out = p.sub(''.join(pair),word)\r\n","            v_out[w_out]=v_in[word]\r\n","        return v_out\r\n","\r\n","    idx2word = []\r\n","    for token_list in vocab.keys():\r\n","        for token in token_list.split():\r\n","            if token not in idx2word:\r\n","                idx2word.append(token)\r\n","    \r\n","    for i in range(max_vocab_size):\r\n","        pairs = get_stats(vocab)\r\n","        if not pairs: break\r\n","        best = max(pairs, key=pairs.get)\r\n","        vocab = merge_dict(best, vocab)\r\n","        idx2word.append(best[0]+best[1])\r\n","        if len(idx2word) == max_vocab_size-len(SPECIAL):\r\n","            break\r\n","\r\n","    idx2word = SPECIAL + sorted(idx2word, key=len, reverse=True)\r\n","    return idx2word"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KBJnrNlY5cjW"},"source":["## 2-2. build_bpe 함수 평가"]},{"cell_type":"code","metadata":{"id":"ZG6-h8Wv5KWB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613962408000,"user_tz":-540,"elapsed":635,"user":{"displayName":"윤준석","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCmI1sT1yHDMSiz3v1SLvL13Y6JDuE9ORflX7O=s64","userId":"08731269143009806715"}},"outputId":"9cd9d63c-064d-4863-9a14-237e1df04951"},"source":["#############################################\r\n","# Helper functions below. DO NOT MODIFY!    #\r\n","#############################################\r\n","\r\n","class BytePairEncoding(object):\r\n","    \"\"\" Byte Pair Encoding class\r\n","    We aren't gonna use this class for encoding. Because it is too slow......\r\n","    We will use sentence piece Google have made.\r\n","    Thus, this class is just for special token index reference.\r\n","    \"\"\"\r\n","    PAD_token = '<pad>'\r\n","    PAD_token_idx = 0\r\n","    UNK_token = '<unk>'\r\n","    UNK_token_idx = 1\r\n","    CLS_token = '<cls>'\r\n","    CLS_token_idx = 2\r\n","    SEP_token = '<sep>'\r\n","    SEP_token_idx = 3\r\n","    MSK_token = '<msk>'\r\n","    MSK_token_idx = 4\r\n","\r\n","    WORD_END = '_'\r\n","\r\n","    def __init__(self, corpus: List[List[str]], max_vocab_size: int) -> None:\r\n","        self.idx2word = build_bpe(corpus, max_vocab_size)\r\n","\r\n","    def encode(self, sentence: List[str]) -> List[int]:\r\n","        return encode(sentence, self.idx2word)\r\n","\r\n","    def decoder(self, tokens: List[int]) -> List[str]:\r\n","        return decode(tokens, self.idx2word)\r\n","\r\n","\r\n","#############################################\r\n","# Testing functions below.                  #\r\n","#############################################\r\n","\r\n","\r\n","def test_build_bpe():\r\n","    print(\"======Building BPE Vocab Test Case======\")\r\n","    PAD = BytePairEncoding.PAD_token\r\n","    UNK = BytePairEncoding.UNK_token\r\n","    CLS = BytePairEncoding.CLS_token\r\n","    SEP = BytePairEncoding.SEP_token\r\n","    MSK = BytePairEncoding.MSK_token\r\n","    WORD_END = BytePairEncoding.WORD_END\r\n","\r\n","    # First test\r\n","    corpus = ['abcde']\r\n","    vocab = build_bpe(corpus, max_vocab_size=15)\r\n","    assert vocab[:5] == [PAD, UNK, CLS, SEP, MSK], \\\r\n","        \"Please insert the special tokens properly\"\r\n","    print(\"The first test passed!\")\r\n","\r\n","    # Second test\r\n","    assert sorted(vocab[5:], key=len, reverse=True) == vocab[5:], \\\r\n","        \"Please sort your idx2word by subword length in decsending manner.\"\r\n","    print(\"The second test passed!\")\r\n","\r\n","    # Third test\r\n","    corpus = ['low'] * 5 + ['lower'] * 2 + ['newest'] * 6 + ['widest'] * 3\r\n","    vocab = set(build_bpe(corpus, max_vocab_size=24))\r\n","    assert vocab > {PAD, UNK, CLS, SEP, MSK, 'est_', 'low', 'newest_', \\\r\n","                    'i', 'e', 'n', 't', 'd', 's', 'o', 'l', 'r', 'w',\r\n","                    WORD_END} and \\\r\n","           \"low_\" not in vocab and \"wi\" not in vocab and \"id\" not in vocab, \\\r\n","        \"Your bpe result does not match expected result\"\r\n","    print(\"The third test passed!\")\r\n","\r\n","    # forth test\r\n","    corpus = ['aaaaaaaaaaaa', 'abababab']\r\n","    vocab = set(build_bpe(corpus, max_vocab_size=13))\r\n","    assert vocab == {PAD, UNK, CLS, SEP, MSK, 'aaaaaaaa', 'aaaa', 'abab', 'aa',\r\n","                     'ab', 'a', 'b', WORD_END}, \\\r\n","        \"Your bpe result does not match expected result\"\r\n","    print(\"The forth test passed!\")\r\n","\r\n","    # fifth test\r\n","    corpus = ['abc', 'bcd']\r\n","    vocab = build_bpe(corpus, max_vocab_size=10000)\r\n","    assert len(vocab) == 15, \\\r\n","        \"Your bpe result does not match expected result\"\r\n","    print(\"The fifth test passed!\")\r\n","\r\n","    print(\"All 5 tests passed!\")\r\n","test_build_bpe()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["======Building BPE Vocab Test Case======\n","The first test passed!\n","The second test passed!\n","The third test passed!\n","The forth test passed!\n","The fifth test passed!\n","All 5 tests passed!\n"],"name":"stdout"}]}]}