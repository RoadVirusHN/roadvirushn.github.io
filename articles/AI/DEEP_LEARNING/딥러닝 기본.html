<!DOCTYPE html>
<html lang="kr"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ë”¥ëŸ¬ë‹ ê¸°ë³¸ | ğŸ§ SUBBRAIN</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="ë”¥ëŸ¬ë‹ ê¸°ë³¸" />
<meta property="og:locale" content="kr" />
<meta name="description" content="style: number min_depth: 2 max_depth: 3 varied_style: true ë”¥ëŸ¬ë‹ ê¸°ë³¸(Deep learning Basic)" />
<meta property="og:description" content="style: number min_depth: 2 max_depth: 3 varied_style: true ë”¥ëŸ¬ë‹ ê¸°ë³¸(Deep learning Basic)" />
<link rel="canonical" href="http://localhost:4000/articles/AI/DEEP_LEARNING/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:url" content="http://localhost:4000/articles/AI/DEEP_LEARNING/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:site_name" content="ğŸ§ SUBBRAIN" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-12-14T13:41:08+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ë”¥ëŸ¬ë‹ ê¸°ë³¸" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-14T13:41:08+09:00","datePublished":"2022-12-14T13:41:08+09:00","description":"style: number min_depth: 2 max_depth: 3 varied_style: true ë”¥ëŸ¬ë‹ ê¸°ë³¸(Deep learning Basic)","headline":"ë”¥ëŸ¬ë‹ ê¸°ë³¸","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/articles/AI/DEEP_LEARNING/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8.html"},"url":"http://localhost:4000/articles/AI/DEEP_LEARNING/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="ğŸ§ SUBBRAIN" /><link rel="icon" type="image/x-icon" href="/assets/img/common/favicon.ico">
</head>
<div class="scrollWrapper">
  <div class="scrollbar"></div>
  <div class="progressbar"></div>
  <div class="scrollbarButton"></div>
</div>

<link rel="stylesheet" href="/assets/css/obsidian/obs-scrollbar.css" />

<!--<div class="redirection">
  <h1 class="name">Redirection for full experience.</h1>
  <br>
  Move to <br /> <a class="to" href="#">netlify url</a><br />
  <div>after <span class="counter">10</span>secs.</div>
  press <button class="cancle">here</button> to cancle.
</div>
<div class="overlay"></div>
<script type="module" src="/assets/scripts/common/components/init_redirection.js"></script>

<link rel="stylesheet" href="/assets/css/common/redirection.css" />-->

<body><header class="site-header" role="banner">

  <div class="wrapper" style="display: flex; justify-content: space-between;"><div id="header-wrapper">
    <a class="site-title" rel="author" href="/blog">ğŸ§ SUBBRAIN</a>

    </div><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><script src="https://unpkg.com/lunr/lunr.js"></script>
<link rel="stylesheet" href="/assets/css/common/searchbar.css" />

<form id="search-form" method="get">
  <span id="search-wrapper">
    <span id="tag-holder" ></span>
    <input type="text" id="search-box" placeholder='Prefix "#" to add Tag.' autocomplete="off">
    <span class="inner-search" >ğŸ”</span>
  </span>
</form><a class="page-link" href="/">ABOUT ME</a><a class="page-link" href="/blog">ALL ARTICLES</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
    <link rel="stylesheet" href="/assets/css/common/drawer.css" />
<button class="drawer-button open">â–¶ï¸</button>
<div id="drawer" class="close">
  <button class="drawer-button close">
    â—€ï¸
  </button>
  <div class="drawer-content">
    <div class="my-description">
      <div class="avatar-section" style="display: flex; flex-direction: row;">

        <img src="/assets/img/common/avatar.png" alt="avatar" class="avatar">
        <div style="display: flex; flex-direction: column; margin-left: 5px;">
          <a href="/about/">
            <h3 class="name">ROADVIRUSHN</h3>
          </a>
          <div class="stack-list" style="margin: 5px 0 0 5px;">
            <a title="My github page" href="https://github.com/RoadVirusHN">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#github"></use>
  </svg>
</a>
<a title="My G-mail" href="mailto:roadvirushn@gmail.com">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#gmail"></use>
  </svg>
</a>
<a title="My Blog" href="https://luminous-bubblegum-8e9be4.netlify.app">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#blog"></use>
  </svg>
</a>
          </div>
        </div>
        <!-- <h4 class="name">(JUNSEOK YUN)</h4> -->
      </div>
      <p style="margin: 5px 0 0 0;">
        í’€ìŠ¤íƒ ì›¹ğŸŒ ê°œë°œì ì§€ë§ìƒ ğŸ§‘ğŸ½â€ğŸ’»
        <br>
        â• ì¸ê³µì§€ëŠ¥ ê´€ì‹¬ ğŸ¤–
      </p>
    </div>
      <hr>
      <div class="categories">
        <h3 style="margin: 0;"><a href="/">Categories</a></h3>
        <ul class="category-list">
  
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/COMPUTER_SCIENCE/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">COMPUTER_SCIENCE</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 7
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/DATABASE/">DATABASE</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ALGORITHM/">ALGORITHM</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 16 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/OS/">OS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/NETWORK/">NETWORK</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 8 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ETC/">ETC</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/OSSU/">OSSU</a>
        </h4>
          <span style="font-size: xx-small;">
             
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/PL/">PL</a>
        </h4>
          <span style="font-size: xx-small;">
             
            ğŸ“‚: 1
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/WEB/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">WEB</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 3
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/FRONTEND/">FRONTEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/BACKEND/">BACKEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 2
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/CI,CD/">CI,CD</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 2
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/ETC/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">ETC</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 3
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/ETC/ETCS/">ETCS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 10 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/ETC/SUBBRAIN ê°œë°œê¸°/">SUBBRAIN ê°œë°œê¸°</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 5 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/ETC/YOS ê°œë°œê¸°/">YOS ê°œë°œê¸°</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”— </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/AI/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">AI</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 9
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/AITOOLS/">AITOOLS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/CV/">CV</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DEEP_LEARNING/">DEEP_LEARNING</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DATA_VIS/">DATA_VIS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/GRAPH/">GRAPH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/LIGHTWEIGHT/">LIGHTWEIGHT</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/MATH/">MATH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/NLP/">NLP</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/STRUCTURED_DATA/">STRUCTURED_DATA</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
    </ul>
  </li>
  
</ul>
      </div>
      <hr>
      <div class="recent-view">
        <h3 style="margin: 0;">Recent views</h3>
        <ul style="margin: 0;">
          <li>
            <strong style="color:rgb(219, 219, 12);">1 <a id="recent-1"></a></strong>
          </li>
          <li>
            2 <a id="recent-2"></a>
          </li>
          <li>
            3 <a id="recent-3"></a>
          </li>
          <li>
            4 <a id="recent-4"></a>
          </li>
          <li>
            5 <a id="recent-5" style="overflow: hidden;"></a>
          </li>
        </ul>
      </div>
    </div>
    <hr>
  <div style="height: 7vh;"></div>
</div>
    <div class="wrapper">
      <article class="article h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="article-header">
    <h1 class="article-title a-name" itemprop="name headline">ë”¥ëŸ¬ë‹ ê¸°ë³¸</h1>
    <p class="article-meta">
      <time class="dt-published" datetime="2022-12-14T13:41:08+09:00" itemprop="datePublished">Dec 14, 2022
      </time></p>
  </header>

  <div class="article-content e-content" itemprop="articleBody">
     
  
<script>
  MathJax = {
    tex: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"],
      ],
    },
    svg: {
      fontCache: "global",  
     // scale: 1.5,
    },
    chtml: {
     // scale: 1.5,
    },
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>
 
 


<script src="/assets/scripts/bundle/obsidian.bundle.js"></script>
<link rel="stylesheet" href="/assets/css/obsidian/callout.css" />
<link rel="stylesheet" href="/assets/css/obsidian/image.css" />
<link rel="stylesheet" href="/assets/css/obsidian/link-warning.css" />
<link rel="stylesheet" href="/assets/css/obsidian/preview.css" />

<div class="content-section">
  <html><head></head><body><ol id="markdown-toc-0"><li lvl="2"><a id="markdown-toc-0-0" href="#Historical-Review">Historical Review</a><ul><li lvl="3"><a id="markdown-toc-0-1" href="#ì†Œê°œ">ì†Œê°œ</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-2" href="#ë”¥ëŸ¬ë‹ì˜-ì—­ì‚¬">ë”¥ëŸ¬ë‹ì˜ ì—­ì‚¬</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-3" href="#ë‰´ëŸ´-ë„¤íŠ¸ì›Œí¬-Neural-Networks-MLP">ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬(Neural Networks) - MLP</a><ul><li lvl="3"><a id="markdown-toc-0-4" href="#Neural-Networks">Neural Networks</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-5" href="#Linear-Neural-Networks">Linear Neural Networks</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-6" href="#Activation-function-and-Multi-layer-Perceptron">Activation function and Multi-layer Perceptron</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-7" href="#Optimization">Optimization</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-8" href="#Convolutional-Neural-Networks">Convolutional Neural Networks</a><ul><li lvl="3"><a id="markdown-toc-0-9" href="#Convolution-ì—°ì‚°">Convolution ì—°ì‚°</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-10" href="#CNN-êµ¬ì¡°ì™€-ìš©ì–´">CNN êµ¬ì¡°ì™€ ìš©ì–´</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-11" href="#Convolution-Arithmetic">Convolution Arithmetic</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-12" href="#1x1-convolutionë¥¼-í™œìš©í•œ-ìµœì í™”">1x1 convolutionë¥¼ í™œìš©í•œ ìµœì í™”</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-13" href="#Modern-CNN">Modern CNN</a><ul></ul></li><li lvl="2"><a id="markdown-toc-0-14" href="#Computer-Vision-Applications">Computer Vision Applications</a><ul><li lvl="3"><a id="markdown-toc-0-15" href="#Semantic-Segmentation">Semantic Segmentation</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-16" href="#Detection">Detection</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-17" href="#Sequential-Models-RNN">Sequential Models - RNN</a><ul><li lvl="3"><a id="markdown-toc-0-18" href="#Sequential-Model">Sequential Model</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-19" href="#Recurrent-Neural-Network-RNN">Recurrent Neural Network(RNN)</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-20" href="#Long-Short-Term-Memory-LSTM">Long Short Term Memory(LSTM)</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-21" href="#Gated-Recurrent-Unit-GRU">Gated Recurrent Unit(GRU)</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-22" href="#Transformer-ëª¨ë¸">Transformer ëª¨ë¸</a><ul><li lvl="3"><a id="markdown-toc-0-23" href="#Transformer">Transformer</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-24" href="#Transform-ëª¨ë¸ì˜-ê·¼í™©">Transform ëª¨ë¸ì˜ ê·¼í™©</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-25" href="#Generative-Models-ìƒì„±-ëª¨ë¸">Generative Models(ìƒì„± ëª¨ë¸)</a><ul><li lvl="3"><a id="markdown-toc-0-26" href="#Introduction">Introduction</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-27" href="#Basic-Discrete-Distributions">Basic Discrete Distributions</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-28" href="#Structure-Through-Independence-Conditional-Independence">Structure Through Independence &amp; Conditional Independence</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-29" href="#Auto-regressive-Model">Auto-regressive Model</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-30" href="#"></a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-31" href="#Latent-Variable-Models">Latent Variable Models</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-32" href="#Generative-Adversarial-Network-GAN">Generative Adversarial Network(GAN)</a><ul></ul></li></ul></li></ol>
<h1 id="ë”¥ëŸ¬ë‹-ê¸°ë³¸-Deep-learning-Basic">ë”¥ëŸ¬ë‹ ê¸°ë³¸(Deep learning Basic)</h1>

<blockquote>
  <p>ë³¸ ìë£ŒëŠ” Naver BoostAI campì˜ ê°•ì˜ë¥¼ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤</p>
</blockquote>

<h2 id="Historical-Review">Historical Review</h2>

<h3 id="ì†Œê°œ">ì†Œê°œ</h3>

<ul>
  <li>êµ¬í˜„(ì½”ë”©) ì‹¤ë ¥, ìˆ˜í•™ ìŠ¤í‚¬, ìµœì‹  ë…¼ë¬¸ ê¸°ìˆ  ë“±ì˜ ëŠ¥ë ¥ì´ ì¤‘ìš”í•˜ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210201114543323.png" alt=""></p>

<p><strong>[img 0. ì¸ê³µì§€ëŠ¥ì˜ ëŒ€ë¶„ë¥˜]</strong></p>

<ul>
  <li>ì¸ê³µì§€ëŠ¥ : ì¸ê°„ì˜ ì§€ëŠ¥ì„ í‰ë‚´</li>
  <li>ë¨¸ì‹ ëŸ¬ë‹ : ë°ì´í„°ë¥¼ í†µí•´ ì¸ê³µì§€ëŠ¥ì„ í•™ìŠµ</li>
  <li>
    <p>ë”¥ ëŸ¬ë‹ : ì‹¬ì¸µ ì‹ ê²½ë§ì„ í™œìš©í•œ ëª¨ë¸ ì´ìš©í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹, networkë¥¼ ê¹Šê²Œ ìŒ“ìŒ</p>
  </li>
  <li>ë”¥ëŸ¬ë‹ì— í•„ìš”í•œ 4ê°€ì§€ ìš”ì†Œ
    <ul>
      <li>ëª¨ë¸ì´ í•™ìŠµí•  ë°ì´í„° : í’€ê³ ìí•  ë¬¸ì œì— ë”°ë¼ í•„ìš”í•œ ë°ì´í„°ê°€ ë‹¤ë¥´ë‹¤.
        <ul>
          <li>Detection, Classification, Visual QnA ë“±</li>
        </ul>
      </li>
      <li>ë°ì´í„°ë¡œ í•™ìŠµ, íŒë‹¨í•  ëª¨ë¸ : ë°ì´í„°ë¥¼ í•„ìš”í•œ ë°ì´í„°ë¡œ ë°”ê¿”ì£¼ëŠ” ê²ƒ
        <ul>
          <li>AlexNet, GoogLeNet, GAN ë“±</li>
        </ul>
      </li>
      <li>ëª¨ë¸ í•™ìŠµ ë°©ë²•ì¸ loss í•¨ìˆ˜ : ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•
        <ul>
          <li>ë‹¨ìˆœíˆ ì¤„ì´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ í•™ìŠµí•˜ì§€ì•Šì€ ë°ì´í„°ë“±ì—ë„ ë™ì‘í•´ì•¼í•¨.</li>
          <li>MSE, CE, MLE ë“±</li>
        </ul>
      </li>
      <li>loss í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•  ì•Œê³ ë¦¬ì¦˜ : loss ë¥¼ ì–´ë–»ê²Œ ì¤„ì¼ ê²ƒì¸ê°€?
        <ul>
          <li>SGD, Adagrad ë“±ì´ ìˆìŒ</li>
          <li>ì¶”ê°€ë¡œ Ensemble, MixUp, Dropout ë“± í…Œí¬ë‹‰ì´ ìˆìŒ</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="ë”¥ëŸ¬ë‹ì˜-ì—­ì‚¬">ë”¥ëŸ¬ë‹ì˜ ì—­ì‚¬</h3>

<blockquote>
  <p>Denny Britzì˜ Deep Learningâ€™s Most Importat Ideas - A Bref Historical Reviewë¥¼ ì°¸ì¡°í•¨</p>
</blockquote>

<ul>
  <li>2012 - AlexNet: ìµœì´ˆë¡œ ì¸ê³µì§€ëŠ¥ ëŒ€íšŒì—ì„œ 1ë“±ì„ í•œ DeepLearning ë°©ë²•ë¡ . ì‹œì´ˆ</li>
  <li>2013 - DQN : ê°•í™”í•™ìŠµì— ì“°ì¸ ë°©ë²•ë¡ , Q Learning ì ‘ëª©, Deepmindì˜ ì‘í’ˆ</li>
  <li>2014 - Encoder/Decorder : ì¸ê³µì§€ëŠ¥ ë²ˆì—­ì— ì“°ì´ëŠ” ë°©ë²•ë¡ , ë‹¤ë¥¸ ì–¸ì–´ì˜ ì—°ì†ìœ¼ë¡œ ë²ˆì—­</li>
  <li>2014 - Adam Optimizer :  íš¨ê³¼ ì¢‹ì€ optimizer, ì™ ë§Œí•˜ë©´ ì˜ëœë‹¤ë¼ëŠ” ëœ»ì´ë¼ê³  í•¨.</li>
  <li>2015 - Generative Adversarial Network(GAN) : ìƒˆë¡œìš´ ê²ƒì„ ìƒì„±í•˜ëŠ” ë° ë§ì´ ì‚¬ìš©í•˜ëŠ” AI</li>
  <li>2015 - Residual Networks(ResNet) :  ë„ˆë¬´ ê¹Šì–´ì§„ Network layerì˜ ì„±ëŠ¥ ì €í•˜ë¥¼ ë§‰ì•„ì¤Œ
    <ul>
      <li>inputì„ ì¶”ê°€ë¡œ ë„£ì–´ì£¼ëŠ” ê²ƒ</li>
    </ul>
  </li>
  <li>2017 - Transformer : attention êµ¬ì¡°ë¥¼ ì´ìš©í•œ googleì˜ ë°©ë²•ë¡ </li>
  <li>2018 - BERT(fine-tuned NLP models) : Transformer + bidirection êµ¬ì¡°ë¥¼ í™œìš©í•œ ëª¨ë¸
    <ul>
      <li>Bidirectional Encoder Representations from Transformersì˜ ì•½ì</li>
    </ul>
  </li>
  <li>2019 - Big Language Models(GPT-X) : OpenAIì—ì„œ ë§Œë“  BERTì˜ Language ëª¨ë¸, êµ‰ì¥íˆ ë§ì€ parameterë¡œ ì´ë£¨ì–´ì§</li>
  <li>2020 - Self-Supervised Learning: SimCLR( a simple framework for contrastive learning of visual representations)ì˜ ì¤„ì¸ë§, í•™ìŠµ ë°ì´í„° ì™¸ì˜ ë¼ë²¨ì„ ëª¨ë¥´ëŠ” ë°ì´í„°ë¥¼ í™œìš©, ì§€ë„ í•™ìŠµ + ë¹„ì§€ë„ í•™ìŠµ
    <ul>
      <li>ì‹œë®¬ë ˆì´í„°, ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•´ í•™ìŠµ ë°ì´í„°ë¥¼ ì¶”ê°€ë¡œ ë§Œë“œëŠ” ì—°êµ¬ë„ í™œë°œíˆ ì´ë¤„ì§€ëŠ” ì¤‘</li>
    </ul>
  </li>
</ul>

<h2 id="ë‰´ëŸ´-ë„¤íŠ¸ì›Œí¬-Neural-Networks-MLP">ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬(Neural Networks) - MLP</h2>

<h3 id="Neural-Networks">Neural Networks</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210201235023750.png" alt=""></p>

<p><strong>[img 1. ë‘ë‡Œ ì†ì˜ ì‹ ê²½ë§]</strong></p>

<blockquote>
  <p><em>ë™ë¬¼ì˜ ìƒë¬¼í•™ì  ì‹ ê²½ë§ì—ì„œ ì˜ê°ì„ ë°›ì€ ì»´í“¨íŒ… ì‹œìŠ¤í…œ</em> - wikipedia</p>
</blockquote>

<ul>
  <li>
    <p>ìƒë¬¼í•™ì  êµ¬ì¡°ë§Œ ë¹„ìŠ·í•  ë¿, ì‹¤ì œ ì‘ë™ì›ë¦¬ì™€ëŠ” ê´€ê³„ì—†ìŒ.</p>
  </li>
  <li>
    <p>í–‰ë ¬ì˜ ê³±ê³¼ ë¹„ì„ í˜• ì—°ì‚°ì˜ ë°˜ë³µì„ í†µí•˜ì—¬ í•¨ìˆ˜(ë…¼ë¦¬)ë¥¼ ê·¼ì‚¬ì¶”ì •í•˜ëŠ” ê²ƒ.</p>
    <ul>
      <li>neural networks are function approximators that stack affine transformations followed by nonlinear transformations.</li>
    </ul>
  </li>
</ul>

<h3 id="Linear-Neural-Networks">Linear Neural Networks</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202001255581.png" alt=""></p>

<p><strong>[img 2. ì„ í˜• ëª¨ë¸ ê·¸ë˜í”„]</strong></p>

<ul>
  <li>Data: $\mathcal{D} = {(x_i,y_i)}^N_{i=1}$ : input ê°’ê³¼ output ê°’ì´ ê°ê° í•˜ë‚˜</li>
  <li>
    <p>Model: $\hat{y} = wx+b,\ \hat{y} : ëª¨ë¸ì˜\ ì˜ˆìƒì¹˜$ : ì„ í˜• ê·¸ë˜í”„ë¡œ ì´ë£¨ì–´ì§</p>
  </li>
  <li>Loss: $loss =\frac{1}{N}\sum^N_{i=1}(y_i-\hat{y_i})^2$ : ì‹¤ì œ ê°’ê³¼ ì–¼ë§ˆë‚˜ ë‹¤ë¥¸ê°€ì— ëŒ€í•œ ì²™ë„, ë³´í†µ MSE loss í•¨ìˆ˜ë¡œ loss ì¸¡ì •</li>
</ul>

\[\frac{\partial loss}{\partial w} = \frac{\partial}{\partial w} \frac{1}{N}\sum^N_{i=1}(y_i - \hat{y_i})^2 = \frac{\partial}{\partial w} \frac{1}{N}\sum^N_{i=1}(y_i - wx_i-b)^2 =-\frac{1}{N}\sum^N_{i=1}-2(y_i-wx_i-b)x_i \\
\frac{\partial loss}{\partial b} = \frac{\partial}{\partial b} \frac{1}{N}\sum^N_{i=1}(y_i - \hat{y_i})^2 = \frac{\partial}{\partial b} \frac{1}{N}\sum^N_{i=1}(y_i - wx_i-b)^2 =-\frac{1}{N}\sum^N_{i=1}-2(y_i-wx_i-b)\]

<p><strong>[math 2. backprogationì„ ì´ìš©í•œ wì™€ bì˜ í¸ë¯¸ë¶„ê°’ êµ¬í•˜ê¸°]</strong><br>
\(w = w - \eta\frac{\partial loss}{\partial w},\ b = b-\eta \frac{\partial loss}{\partial b}\)<br>
<strong>[math 2-1. loss ê°’ì„ ì¤„ì´ê¸° ìœ„í•œ ìƒˆë¡œìš´ wì™€ b ì—…ë°ì´íŠ¸]</strong></p>

<ul>
  <li>
    <p>ì´ëŸ¬í•œ ë°©ì‹ìœ¼ë¡œ ìµœì ê°’ì„ êµ¬í•˜ëŠ” ê²ƒì„ gradient descentë¼ê³  í•œë‹¤.</p>
  </li>
  <li>
    <p>matrix ì—°ì‚°ì„ í†µí•˜ì—¬ ì—¬ëŸ¬ ì°¨ì›ì˜ inputê³¼ output ë˜í•œ í•´ê²° ê°€ëŠ¥</p>
    <ul>
      <li>matrix ì—°ì‚°ì€ ë‘ ë²¡í„° ê³µê°„ ìƒì˜ ë³€í™˜ì„ ì˜ë¯¸í•¨</li>
    </ul>
  </li>
</ul>

<h3 id="Activation-function-and-Multi-layer-Perceptron">Activation function and Multi-layer Perceptron</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202005745910.png" alt=""></p>

<p><strong>[math 3. Activation fucntionì˜ ì¢…ë¥˜ì™€ ê·¸ë˜í”„ ëª¨ì–‘]</strong></p>

<ul>
  <li>ê° ë¬¸ì œ, ë°ì´í„°ë§ˆë‹¤ ì‚¬ìš©í•´ì•¼í•  Activation functionì´ ë‹¤ë¥´ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202010053005.png" alt=""></p>

<p><strong>[img 3. Multi-Layer Perceptron]</strong></p>

<ul>
  <li>
    <p>ì´ëŸ¬í•œ ì—¬ëŸ¬ matrix ì—°ì‚°ê³¼ matrix ì—°ì‚° ì‚¬ì´ì˜ activation functionì— ì˜í•´ nonlenar transformì„ ê±°ì³ì„œ ì—¬ëŸ¬ ì¸µì˜ neural networkê°€ ëœë‹¤.</p>
  </li>
  <li>
    <p>ê° ë¬¸ì œë§ˆë‹¤ loss functionì„ ë‹¤ë¥´ê²Œ í•˜ê²Œ ëœë‹¤.</p>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202010517717.png" alt=""></p>

    <ul>
      <li>Regression Task : ì„ í˜• ë¬¸ì œ (ì§‘ í¬ê¸° vs ì§‘ ê°€ê²©) ê°™ì€ ë¬¸ì œì—ì„œëŠ” MSE ë“±ì„ ì‚¬ìš©</li>
      <li>Classification Task : ë¶„ë¥˜ ë¬¸ì œ(ì†ê¸€ì”¨ ìˆ«ì êµ¬ë¶„) ê°™ì€ ë¬¸ì œëŠ” CE ë“±ì„ ì‚¬ìš©(ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ classë¥¼ ì„ íƒ)</li>
      <li>Probabilistic Task : í™•ë¥  ë¬¸ì œ(ë‚˜ì´ ë§ì¶”ê¸° ) ê°™ì€ ë¬¸ì œì—ëŠ” MLEë¥¼ ì‚¬ìš©.</li>
    </ul>
  </li>
</ul>

<p><strong>[img 3. Multi-Layer Perceptron]</strong></p>

<ul>
  <li>ì‹¤ìŠµì€ https://colab.research.google.com/drive/14lEFtnt3kEn-LiwTKTwpUB-3VQ0Xx84W#scrollTo=3AS5BdrMw1E9 ë˜ëŠ” mlp.ipynb íŒŒì¼ ì°¸ì¡°</li>
</ul>

<h3 id="Optimization">Optimization</h3>

<p>ê´€ë ¨ ì‹¤ìŠµ : https://colab.research.google.com/drive/1p4H1mZpa41n3C8fQCtknQ0NfJGtEUIl6#scrollTo=B-uu6x8DFwZ9 í˜¹ì€ optm.ipynb ì°¸ì¡°</p>

<h4 id="ìš©ì–´ì˜-ì •ì˜">ìš©ì–´ì˜ ì •ì˜</h4>

<ul>
  <li>
    <p>Gradient Descent(ê²½ì‚¬ í•˜ê°•): ë°˜ë³µ 1ì°¨ ë¯¸ë¶„ì„ í†µí•˜ì—¬ lossì˜ êµ­ì†Œ ìµœì†Œì ì„ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜</p>
  </li>
  <li>
    <p>First-order iterative optimization algorithm for finding a local minimum of a differntiable function.</p>
  </li>
  <li>
    <p>Generalization(ì¼ë°˜í™”): training errorì™€ test errorì˜ ì°¨ì´ê°€ ì ìŒì„ ì˜ë¯¸.</p>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202102047493.png" alt=""></p>

    <p><strong>[img 4. generalizationì˜ ê·¸ë˜í”„]</strong></p>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202102119698.png" alt=""></p>

    <p><strong>[img 4-1. fittingì˜ ë„ì‹í™”]</strong></p>

    <ul>
      <li>underfittingì€ ë„ˆë¬´ trainingì„ ì•ˆí•´ì„œ ê·¸ë˜í”„ê°€ ì ì ˆí•˜ì§€ ì•ŠìŒ</li>
      <li>overfittingì€ ë„ˆë¬´ trainingì„ ë§ì´í•´ì„œ ìœ ì—°ì„±ì´ ì—†ê³ , í•´ë‹¹ ë°ì´í„° ì´ì™¸ì˜ ë°ì´í„°ì— ë¶€ì í•©</li>
    </ul>
  </li>
  <li>
    <p>Cross-validation(êµì°¨ ê²€ì¦, ë˜ëŠ” k-fold validation)</p>

    <ul>
      <li>ë°ì´í„°ë¥¼ kê°œë¡œ ë‚˜ëˆˆ ë’¤ í•™ìŠµ ë°ì´í„°ì™€ ê²€ì¦(validation) ë°ì´í„°ë¥¼ ë°”ê¿”ê°€ë©° hyper parametrë¥¼ ì •í•˜ëŠ” ëª¨ë¸ ê²€ì¦ ê¸°ìˆ </li>
      <li>
        <p>training, validation, test ë°ì´í„°ë¡œ ë‚˜ëˆ„ê²Œ ëœë‹¤.</p>
      </li>
      <li>parameter : ìµœì í•´ì—ì„œ ì°¾ëŠ” ê°’(weight, bias ë“±)</li>
      <li>hyper-parameter: ë‚´ê°€ ì‹œì‘í•  ë•Œ ì£¼ëŠ” ê°’(loss function, learning rate ë“±)</li>
    </ul>
  </li>
  <li>
    <p>Bias(í¸í–¥) and Variance(ë¶„ì‚°ë„):  ë¶„ì‚°ì´ ì ì€ ê²ƒì´ ì¢‹ë‹¤.</p>
    <ul>
      <li>ìš°ë¦¬ê°€ ì¤„ì´ëŠ” costëŠ” ì‚¬ì‹¤ ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰˜ë©° ë¬´ì—‡ì„ ì¤„ì¼ ì§€ ìƒê°í•´ë´ì•¼í•œë‹¤.</li>
      <li>noiseê°€ ë§ì€ ë°ì´í„°ë©´ biasì™€ varianceë¥¼ ë‘˜ë‹¤ ì¤„ì´ëŠ” ê²ƒì´ í˜ë“œë¯€ë¡œ ê³¨ë¼ì•¼í•¨</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202102906498.png" alt=""></p>

<p><strong>[img 4-2. bias, variance ê·¸ë¦¼]</strong><br>
\(Given\ \mathcal{D} = \{(x_i,t_i)\}^N_{i=1},\ where t = f(x)+ \epsilon\ and\ \epsilon \sim \mathcal{N}(0, \sigma^2)\\
\stackrel {\mathbb{E}\left[(t-\hat{f})^2\right]}{cost} = \mathbb{E}\left[(t-f +f-\hat{f})^2\right]=\dots=\stackrel {\mathbb{E}\left[(f-\mathbb{E}[\hat{f}]^2)^2\right]}{bias^2}+\stackrel {\mathbb{E}[(\mathbb{E}[\hat{f}]-\hat{f})^2]}{variance}+\stackrel {\mathbb{E}[\epsilon]}{noise}\)<br>
<strong>[math 4. cost(loss)ì˜ êµ¬ì„±]</strong></p>

<ul>
  <li>bootstrapping : í•™ìŠµ ë°ì´í„°ë¥¼ ì¼ë¶€ë§Œ(ì˜ˆë¥¼ ë“¤ì–´ 80%ë§Œ) ì“´ ë°ì´í„°ë¥¼ ê°ê¸° ë‹¬ë¦¬í•˜ì—¬ ì—¬ëŸ¬ê°œ ë§Œë“¤ì–´ ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ í•™ìŠµì‹œì¼œ ë³´ëŠ”ê²ƒ
    <ul>
      <li>í•™ìŠµê²°ê³¼ê°€ ì¼ì •í•˜ë©´ ë°ì´í„°ê°€ ì¼ì •í•œ ê²ƒì´ê³ , ê²°ê³¼ê°€ ê°ì–‘ê°ìƒ‰ì´ë©´ í¸ì°¨ê°€ í° ê²ƒì´ë‹¤.</li>
      <li>ì´ë ‡ê²Œ ë§Œë“  ì—¬ëŸ¬ í•™ìŠµ ë°ì´í„°ì˜ ì—¬ëŸ¬ ëª¨ë¸ì˜ í‰ê· ì´ë‚˜ votingì„ ì·¨í•˜ê¸°ë„ í•¨.(ì•™ìƒë¸”)</li>
    </ul>
  </li>
  <li>bagging(Bootstrapping aggregating) vs boosting
    <ul>
      <li>bagging : bootstrapingìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ì—¬ëŸ¬ê°œì˜ ëª¨ë¸ (ì•™ìƒë¸” ê¸°ë²•)</li>
      <li>boosting : ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ í•´ë³¸ ë’¤, í•´ë‹¹ ëª¨ë¸ë¡œ ê²°ê³¼ë¥¼ ì¸¡ì •í•´ ì˜ ì˜ˆì¸¡ëª»í•˜ëŠ” ë°ì´í„°ë§Œ ëª¨ì•„ì„œ ê°€ì¤‘ì¹˜ë¥¼ ë” í¬ê²Œ ì¤€ ë’¤, (ëœë¤ ë½‘ê¸°ì— ë” ë§ì´ í• ë‹¹?) ìƒˆë¡œìš´ ëª¨ë¸ë¡œ ë§Œë“  ë’¤ ì´ì „ ëª¨ë¸ê³¼ í•©ì¹˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì§„í–‰ (ì•™ìƒë¸” ê¸°ë²•ì˜ í•œ ì¢…ë¥˜)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202110400607.png" alt=""></p>

<p><strong>[img 4-3. bagging boosting ê·¸ë¦¼]</strong></p>

<h4 id="Practical-Gradient-Descent-Methods">Practical Gradient Descent Methods</h4>

<h5 id="Gradient-Descent-Methods">Gradient Descent Methods</h5>

<ul>
  <li>Stochastic gradient descent
    <ul>
      <li>update with the gradient computed from a single sample</li>
      <li>í•˜ë‚˜ì˜ ìƒ˜í”Œë§ˆë‹¤  ê²½ì‚¬ë¥¼ ê³„ì‚°</li>
    </ul>
  </li>
  <li>Mini-batch gradient descent
    <ul>
      <li>update with the gradient computed from a subset of data</li>
      <li>batch í¬ê¸°ì˜ ìƒ˜í”Œë§ˆë‹¤ ê²½ì‚¬ë¥¼ ê³„ì‚°</li>
      <li>ê°€ì¥ ìì£¼ ì‚¬ìš©í•¨</li>
    </ul>
  </li>
  <li>Batch gradient descent
    <ul>
      <li>update with the gradient computed from the whole data</li>
      <li>í•œë²ˆì— ëª¨ë“  ìƒ˜í”Œì„ í™œìš©í•˜ì—¬ ê²½ì‚¬ë¥¼ ê³„ì‚°</li>
    </ul>
  </li>
</ul>

<h5 id="Batch-size-Matters">Batch-size Matters</h5>

<ul>
  <li>ì¼ë°˜ì ìœ¼ë¡œ batch sizeê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ë„ˆë¬´ ì˜¤ë˜ê±¸ë¦¬ê³ , í¬ë©´ ê³„ì‚°ëŸ‰ì´ ë„ˆë¬´ ë§ë‹¤.</li>
  <li>ì—°êµ¬ ê²°ê³¼ batch-sizeê°€ ì‘ì„ ìˆ˜ë¡ ìœ ë¦¬í•˜ë‹¤ëŠ” ê²ƒì´ ì‹¤í—˜ì ìœ¼ë¡œ ì¦ëª…ë¨</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202111631170.png" alt=""></p>

<p><strong>[img 5. batch sizeê°€ ì‘ì„ ìˆ˜ë¡ ì¢‹ì€ ì´ìœ ]</strong></p>

<ul>
  <li>batch sizeê°€ ì‘ìœ¼ë©´ Flat Minimum, í¬ë©´ Sharp Minimumìœ¼ë¡œ ë„ì°©í•˜ëŠ” ê²½í–¥ì´ í¬ë‹¤.</li>
  <li>Flat Minimumì€ test data ì—ì„œë„ generalizationì´ ì˜ë˜ìˆì§€ë§Œ sharp minimuì—ì„œëŠ” ì‹¤ì œ testing ë°ì´í„°ì™€ ê°­ì´ í¬ë‹¤.</li>
</ul>

<h4 id="optimizer">optimizer</h4>

<ul>
  <li>íŠ¹ì„±ì„ í™•ì¸í•˜ê³  ìƒí™©ì— ë”°ë¼ ê³¨ë¼ì„œ ì‚¬ìš©í•´ì•¼í•¨</li>
</ul>

<h5 id="Gradient-Descent">Gradient Descent</h5>

<p>$W_{t+1} \leftarrow W_t - \eta g_t,\ \eta:learning\ rate,\ g_t:Gradient$</p>

<p><strong>[math 6. ê²½ì‚¬í•˜ê°•ë²• ]</strong></p>

<ul>
  <li>ê°€ì¥ ê¸°ë³¸ì ì¸ ë°©ë²•</li>
  <li>ì ì ˆí•œ learning rateë¥¼ ì¡ëŠ” ê²ƒì´ í˜ë“¦</li>
</ul>

<h5 id="Momentum">Momentum</h5>

\[a_{t+1} \leftarrow \beta a_t + g_t\\ a_{t+1}:accumulation,\ \beta: momentum \\
W_{t+1} \leftarrow W_t - \eta a_{t+1}\\ \eta:learning\ rate\]

<p><strong>[math 6-1. ëª¨ë©˜í…€ ê°œë…]</strong></p>

<ul>
  <li>ì´ì „ gradientì˜ ê°’ì´ ì˜í–¥ì„ ì¡°ê¸ˆ ë°›ì€ gradientë¡œ ì—…ë°ì´íŠ¸</li>
  <li>ê¸°ë³¸ë²„ì „ë³´ë‹¤ ì¡°ê¸ˆ ë‚«ë‹¤.</li>
</ul>

<h5 id="Nestrerov-Accelerated-Gradient">Nestrerov Accelerated Gradient</h5>

\[a_{t+1} \leftarrow \beta a_t + \nabla \mathcal{L}(W_t-\eta \beta a_t)  \\ \nabla \mathcal{L}(W_t-\eta \beta a_t):Lookahead\ gradient,\ \beta: momentum \\
W_{t+1} \leftarrow W_t - \eta a_{t+1}\\ \eta:learning\ rate,\ g_t:Gradient\]

<p><strong>[math 6-2. NAG]</strong></p>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202122304219.png" alt=""></p>

<p><strong>[img 6. NAGì™€ Momentum ì°¨ì´ì ]</strong></p>

<ul>
  <li>momentumì„ ê³„ëŸ‰í•¨</li>
  <li>ìµœì†Œ ì§€ì ì— ë„ë‹¬í•˜ëŠ” ê²ƒì´ ì¦ëª…ë¨</li>
  <li>ì´ì „ gradientì™€ í˜„ì¬ ê·¸ë ˆë””ì–¸íŠ¸ë¡œ êµ¬í•˜ëŠ” ë°©ë²•ê³¼ ë‹¬ë¦¬ ì´ì „ momentum gradient ë²¡í„°ì—ì„œ í˜„ì¬ ë²¡í„°ë¡œ ì´ë™í•œë‹¤ëŠ” ë‹¤ë¥¸ì ì´ ìˆìŒ</li>
</ul>

<h5 id="Adagrad">Adagrad</h5>

\[W_{t+1} = W_t - \frac{\eta}{\sqrt {Gt+\epsilon}}g_t\\
G_t : Sum\ of\ gradient\ squares,\ \epsilon:for\ numerical\ stability\]

<p><strong>[math 6-3. Adagrad ê°œë…]</strong></p>

<ul>
  <li>íŒŒë¼ë¯¸í„°ì˜ ë³€í™”ëŸ‰ì´ ë„ˆë¬´ ì ê²Œ ë³€í•˜ë©´ í¬ê²Œ, ë§ì´ ë³€í™”í•´ì˜¨ íŒŒë¼ë¯¸í„°ëŠ” ì ê²Œ learning rateë¥¼ ì¡ì•„ì£¼ì–´ ì¡°ì •í•´ì¤Œ</li>
  <li>ë’¤ë¡œ ê°€ë©´ ê°ˆìˆ˜ë¡ G~t~ê°€ ì»¤ì ¸ì„œ ë¬´í•œëŒ€ë¡œ ê°€ê¹Œì´ ë³€í•´ ê±°ì˜ learning rateê°€ 0ìœ¼ë¡œ ìˆ˜ë ´ë˜ëŠ” ë‹¨ì </li>
  <li>$\epsilon$ì€ ë¶„ëª¨ê°€ 0ì´ ë˜ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì£¼ëŠ” ì•„ì£¼ ì‘ì€ ê°’.</li>
</ul>

<h5 id="Adadelta">Adadelta</h5>

\[G_t = \gamma G_{t-1} + (1-\gamma)g_t^2\\
W_{t+1} = W_t - \frac{\sqrt{H_{t-1}+\epsilon}}{\sqrt {G_t+\epsilon}}g_t\\
H_t=\gamma H_{t-1}+ (1-\gamma)(\Delta W_t)^2\\
G_t:EMA\ of\ gradient\ squares,\ H_t: EMA\ of\ difference\ squares\]

<p><strong>[math 6-4. Adadelta ê°œë…]</strong></p>

<ul>
  <li>learning rateë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.</li>
  <li>window sizeë¥¼ ì •í•˜ê³  í•´ë‹¹ size step ë§Œí¼ë§Œ learning rateì— ì˜í–¥ì„ ì£¼ê²Œí•˜ì—¬ ë¬´í•œëŒ€ë¡œ ìˆ˜ë ´í•˜ëŠ” ê²ƒì„ ë§‰ìŒ
    <ul>
      <li>ì˜ˆë¥¼ ë“¤ì–´ ìœˆë„ìš° ì‚¬ì´ì¦ˆ 10ì´ë²ˆ 11ë²ˆ ë°”ë€Œë©´ ì²«ë²ˆì§¸ íŒŒë¼ë¯¸í„° ë³€í™”ëŠ” ì˜í–¥ì„ ì•ˆì£¼ê²Œ í•˜ê³  11ë²ˆì§¸ë¥¼ ëŒ€ì‹  ì¶”ê°€.</li>
    </ul>
  </li>
  <li>ìµœê·¼ 100ê°œì˜ ê°’ë“¤ì„ ëª¨ë‘ ì €ì¥í•˜ë©´ ë©”ëª¨ë¦¬ê°€ í„°ì§€ë¯€ë¡œ, exponentialì„ ì´ìš©í•´ì„œ êµ¬í•¨</li>
</ul>

<h5 id="RMSprop">RMSprop</h5>

\[G_t = \gamma G_{t-1} + (1-\gamma)g_t^2\\
W_{t+1} = W_t - \frac{\eta}{\sqrt {G_t+\epsilon}}g_t\\
G_t:EMA\ of\ gradient\ squares,\ \eta: stepsize\]

<p><strong>[math 6-5. RMSprop ê°œë…]</strong></p>

<ul>
  <li>adadeltaì— stepsizeë§Œ ì¶”ê°€, ê·¸ëƒ¥ ê²½í—˜ì , ì‹¤í—˜ì ìœ¼ë¡œ ê¹¨ë‹¬ì€ ì‹</li>
</ul>

<h5 id="Adam">Adam</h5>

\[m_t = \beta_1 m_{t=1} + (1-\beta_1)g_t\\
v_t = \beta_2v_{t-1} - (1-\beta_2)g_t^2\\
W_{t+1} = W_t - \frac{\eta}{\sqrt {v_t+\epsilon}}\frac{\sqrt{1-\beta_2^t}}{1-\beta_1^t}m_t\\
M_t:Momentum,\ v_t: EMA\ of\ gradient\ squares,\ \eta: Step\ size\]

<p><strong>[math 6-6. Adam ê°œë…]</strong></p>

<ul>
  <li>RMSdropì— momenturmì„ í•©ì¹œ ê°œë…</li>
  <li>ë¬´ë‚œí•˜ê³  ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.</li>
</ul>

<h4 id="Regularization">Regularization</h4>

<ul>
  <li>generalizationì„ ìœ„í•´ í•™ìŠµì— ì œí•œì„ ê±°ëŠ” ë°©ë²•</li>
</ul>

<h5 id="Early-Stopping">Early Stopping</h5>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202152349645.png" alt=""></p>

<p><strong>[img 7. early stopping]</strong></p>

<ul>
  <li>validation errorì™€ training errorë¥¼ ë¹„êµí•˜ë©° generalization gapì´ ê°€ì¥ ì ì„ ë•Œ stopí•˜ëŠ” ë°©ë²•</li>
</ul>

<h5 id="Parameter-Norm-Penalty">Parameter Norm Penalty</h5>

\[total\ cost = loss(\mathcal{D;W}) + \frac \alpha 2 \left \| W \right \|^2_2\\
\frac \alpha 2 \left \| W \right \|^2_2:Parameter\ Norm\ Penalty\]

<p><strong>[math 7. parameter Norm Penaltyì— ì˜í•œ cost ê³„ì‚°]</strong></p>

<ul>
  <li>parameterë“¤ì˜ í•©ì´ ë„ˆë¬´ ì»¤ì§€ëŠ” ê²ƒì„ ë°©ì§€</li>
  <li>ë¶€ë“œëŸ¬ìš´ parameterì¼ ìˆ˜ë¡ generalizationì´ ì¢‹ì€ ê²½í–¥ì´ ìˆìŒ</li>
</ul>

<h5 id="Data-Augmentation">Data Augmentation</h5>

<ul>
  <li>ë°ì´í„°ê°€ ì ì„ ë•ŒëŠ” ì˜¤íˆë ¤ ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ì´ ì„±ëŠ¥ì´ ì¢‹ì§€ë§Œ, ë°ì´í„°ê°€ í¬ë©´ í´ìˆ˜ë¡ ìµœì‹  ë”¥ëŸ¬ë‹ì´ ì¢‹ë‹¤.</li>
  <li>ë¬¸ì œëŠ” ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ, ê¸°ì¡´ì˜ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ë°”ê¾¸ì–´ì„œ ëŠ˜ë¦¬ëŠ”ê²ƒ</li>
  <li>ì´ë¯¸ì§€ ë°ì´í„°ë¡œ ì˜ˆì‹œë¥¼ ë“¤ë©´, í‘ë°±, ì¼ë¶€ ê°€ë¦¼, ì´ë¯¸ì§€ ë°©í–¥ ë°˜ì „ ë“±ì´ ìˆë‹¤.</li>
</ul>

<h5 id="Noise-Robustness">Noise Robustness</h5>

<ul>
  <li>data Augmentationê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, ë°ì´í„° ë¿ë§Œ ì•„ë‹ˆë¼ weightsì—ë„ ë…¸ì´ì¦ˆë¥¼ ì£¼ì–´ì„œ ì„±ëŠ¥ í–¥ìƒ</li>
</ul>

<h5 id="Label-Smoothing">Label Smoothing</h5>

<ul>
  <li>ë°ì´í„° 2ê°œë¥¼ ë½‘ì•„ì„œ ì„ì–´ decision boundaryë¥¼ ë¶€ë“œëŸ½ê²Œ í•´ì¤Œ</li>
  <li>mix-up ë°©ë²•, cumMix ë°©ë²• ë“±ì´ ìˆìŒ</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202153033122.png" alt=""></p>

<p><strong>[img 7-1. Label Smoothingì˜ ê·¸ë¦¼ì˜ˆì‹œ]</strong></p>

<ul>
  <li>ì„±ëŠ¥ì´ ë˜ê²Œ ì¢‹ë‹¤.</li>
</ul>

<h5 id="Dropout">Dropout</h5>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210206075343145.png" alt=""></p>

<p><strong>[img 7-1. Label Smoothingì˜ ê·¸ë¦¼ì˜ˆì‹œ]</strong></p>

<ul>
  <li>ëœë¤í•˜ê²Œ neuronì„ ë²„ë¦°ë‹¤.</li>
  <li>ì„±ëŠ¥ì€ ì¢‹ì•„ì§€ì§€ë§Œ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…ì´ ë˜ì§„ ì•ŠìŒ</li>
</ul>

<h5 id="Batch-Normalization">Batch Normalization</h5>

\[\mu_B = \frac 1 m \sum_{i=1}^m x_i\\
\sigma^2_B = \frac 1 m \sum^m_{i=1}(x_i-\mu_B)^2\\
\hat{x}_i =\frac {x_i - \mu_B}{\sqrt{\sigma^2_B+\epsilon}}\]

<p><strong>[math 7-1. Batch Normalization ê³„ì‚°]</strong></p>

<ul>
  <li>ë…¼ë€ì´ í¬ì§€ë§Œ ì„±ëŠ¥ì´ ì¢‹ì•„ì§.</li>
  <li>layerë“¤ì˜ parameterë“¤ì˜ ê°’ì„ í‰ê· ê³¼ ë¶„ì‚°ì„ ì´ìš©í•˜ì—¬ ê°™ì€ ê°’ìœ¼ë¡œ ë°”ê¿ˆ.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210202153306844.png" alt=""></p>

<p><strong>[img 7-2. ë‹¤ë¥¸ normalizationì˜ ì¢…ë¥˜]</strong></p>

<h2 id="Convolutional-Neural-Networks">Convolutional Neural Networks</h2>

<h3 id="Convolution-ì—°ì‚°">Convolution ì—°ì‚°</h3>

<ul>
  <li>2ê°œì˜ í•¨ìˆ˜ê°€ ìˆì„ë•Œ 2ê°œì˜ í•¨ìˆ˜ë¥¼ ì„ëŠ” operator</li>
  <li>ì—°ì† ê³µê°„, ì´ìƒ ê³µê°„ì— ë”°ë¼ ìˆ˜ì‹ ë‹¤ë¦„</li>
  <li>IëŠ” ì „ì²´ ê³µê°„, KëŠ” í•„í„°</li>
</ul>

<p>\(\cdot Coninuous\ convolution:\ (f*g)(t) = \int f(\tau)g(t-\tau)d\tau=\int f(t-\tau)g(t)d\tau\\
\cdot Discrete\ convolution:\ (f*g)(t) = \sum^\infty_{i=-\infty} f(i)g(t-i)=\sum^\infty_{i=-\infty} f(t-i)g(i)\\
\cdot 2D\ image\ convolution:\ (I*K)(i,j) = \sum_m\sum_n I(m,n)K(i-m,j-n)=\sum_m\sum_n I(i-m,i-n)K(m,n)\\\)<br>
<strong>[math 8. Convolution operator]</strong></p>

<ul>
  <li>2ì°¨ì› ì½˜ë³¼ë£¨ì…˜ ì—°ì‚°ì˜ ì˜ˆì‹œ.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210204153947830.png" alt=""></p>

<p><strong>[img 8. 2D image Convolution ê·¸ë¦¼]</strong><br>
\(O_{11}=I_{11}K_{11}+I_{12}K_{12}+I_{13}K_{13}+I_{21}K_{21}+I_{22}K_{22}+I_{23}K_{23}+I_{31}K_{31}+I_{32}K_{32}+I_{33}K_{33}+bias\\
O_{12}=I_{12}K_{11}+I_{13}K_{12}+I_{14}K_{13}+I_{22}K_{21}+I_{23}K_{22}+I_{24}K_{23}+I_{32}K_{31}+I_{33}K_{32}+I_{34}K_{33}+bias\\
O_{13}=I_{13}K_{11}+I_{14}K_{12}+I_{15}K_{13}+I_{23}K_{21}+I_{24}K_{22}+I_{25}K_{23}+I_{33}K_{31}+I_{34}K_{32}+I_{35}K_{33}+bias\\
O_{14}=I_{14}K_{11}+I_{15}K_{12}+I_{16}K_{13}+I_{24}K_{21}+I_{25}K_{22}+I_{26}K_{23}+I_{34}K_{31}+I_{35}K_{32}+I_{36}K_{33}+bias\)<br>
<strong>[math 8-1. 2D image Convolution operation]</strong></p>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210204155235797.png" alt=""></p>

<p><strong>[img 8-2. 2D image Convolution filter operation]</strong></p>

<ul>
  <li>2ì°¨ì› ì´ë¯¸ì§€ì˜ ê²½ìš° tensorë¡œ í‘œí˜„ë˜ë©°, ë³´í†µ rgbë¡œ ê³„ì‚° ì‹œ ë’¤ì˜ X3(R,G,B)ì€ ìƒëµì´ ëœë‹¤.</li>
  <li>ì¦‰ 5X5 convolution ì—°ì‚°ì€ ê¸°ë³¸ì ìœ¼ë¡œ 5x5x3ì—ì„œ x3ì´ ìƒëµëœ ê²ƒì´ë‹¤.</li>
  <li>ê³„ì‚° ê²°ê³¼ëŠ” x1ì´ ëœë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210204155415463.png" alt=""></p>

<p><strong>[img 8-3. 2D image Convolution featuremap]</strong></p>

<ul>
  <li>feature mapì„ ì—°ì‚°í•  ë•Œ ì—¬ëŸ¬ ì¸µì˜ featureê°€ ë‚˜ì˜¤ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ê²¹ì˜ í•„í„°ë¥¼ ê³±í•˜ì—¬ ë§Œë“œëŠ” ê²ƒì´ë‹¤.</li>
</ul>

<h4 id="maxpool2dì¸µ-ì›ë¦¬">maxpool2dì¸µ ì›ë¦¬</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208011810873.png" alt=""></p>

<p><strong>[img. Maxpool 2dì¸µ ì˜ˆì‹œ]</strong></p>

<ul>
  <li>ê° êµ¬ì—­ì„ kenelsizeì™€ stride ë§Œí¼ ë‚˜ëˆ„ì–´ ê°€ì¥ í°ê°’ì„ ì·¨í•¨</li>
  <li>Maxê°’ì„ ì·¨í•˜ëŠ” Maxpoolì´ì™¸ì—ë„ í‰ê· ê°’ì„ ì·¨í•˜ëŠ” averagepoolë“±ë„ ìˆë‹¤.</li>
  <li>featureampì˜ í¬ê¸°ê°€ ì¤„ì–´ë“¤ì–´ ì„±ëŠ¥ì„ ì¤„ì´ê³  íŠ¹ì§•ì„ ë‘ë“œëŸ¬ì§€ê²Œ í•  ìˆ˜ ìˆë‹¤.</li>
  <li>ë‹¤ë§Œ, ê³µê°„ ì •ë³´(ìœ„ì¹˜, ë°©í–¥, ë¹„ìœ¨)ë“±ì´ ëª¨í˜¸í•´ ì§€ê¸°ë„ í•œë‹¤.</li>
</ul>

<h3 id="CNN-êµ¬ì¡°ì™€-ìš©ì–´">CNN êµ¬ì¡°ì™€ ìš©ì–´</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210204160439761.png" alt=""></p>

<p><strong>[img 8-4. CNN êµ¬ì¡°]</strong></p>

<ul>
  <li>Convolutionê³¼ pooling layerëŠ” feature extractionì„ í•˜ëŠ” ì—­í• </li>
  <li>Fully connected LayerëŠ” decision making(ex) classification)ì„ ìœ„í•œ ì¸µ
    <ul>
      <li>ê³ ì „ì ì¸ CNNì™€ ë‹¬ë¦¬ ìµœê·¼ì—ëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ê¸° +  generalization ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ FCLì„ ì¤„ì´ëŠ” ì¶”ì„¸</li>
    </ul>
  </li>
</ul>

<ol>
  <li>Stride</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210206163938570.png" alt=""></p>

<p><strong>[img. Stride 1ê³¼ 2ì˜ ì°¨ì´ ê·¸ë¦¼]</strong></p>

<ul>
  <li>pixelì„ ë›°ì–´ë„˜ëŠ” ìˆ˜,  filterì˜ ë°€ë„,</li>
  <li>filterê°€ stride ìˆ˜ ë§Œí¼ pixelì„ ë„˜ì–´ê°€ë©° ìƒì„±í•œë‹¤.</li>
  <li>2ì°¨ì›ì˜ ê²½ìš° x,y 2ê°œë¡œ ì„¤ì • ê°€ëŠ¥</li>
</ul>

<ol>
  <li>Padding</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210206172007377.png" alt=""></p>

<p><strong>[img. paddingì˜ ìœ ë¬´ ì°¨ì´ ê·¸ë¦¼]</strong></p>

<ul>
  <li>Stride ë“±ìœ¼ë¡œ ì¸í•´ ì™¸ë¶€ë¡œ ë‚˜ê°€ëŠ” í”½ì…€ì„ paddingìœ¼ë¡œ ì¶”ê°€í•¨</li>
  <li>zero paddingì€ 0ì„ ë„£ëŠ”ë‹¤ëŠ” ì˜ë¯¸, ì´ë¡œì¨ inputê³¼ outputì˜ space dimensionì´ ê°™ì•„ì§</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210206173139477.png" alt=""></p>

<p><strong>[img. stride, paddingì˜ ì˜ˆì‹œ]</strong></p>

<h3 id="Convolution-Arithmetic">Convolution Arithmetic</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210207221941702.png" alt=""></p>

<p><strong>[img. $3 \times 3$  kernel, Padding 1, Stride 1 ì˜ ì—°ì‚°  parameter ê³„ì‚° ì˜ˆì‹œ]</strong></p>

<ul>
  <li>parameterì˜ ìˆ˜ëŠ” ê°€ì¤‘ì¹˜ì˜ ìˆ˜</li>
  <li>
    <p>convolution layerì˜ í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” <em>(í•„í„° í­  X í•„í„° ë†’ì´  X ì…ë ¥ ì±„ë„ ìˆ˜ X ì¶œë ¥ ì±„ë„ ìˆ˜)</em>ë¡œ ê³„ì‚°</p>
  </li>
  <li>
    <p>ìœ„ ì˜ˆì‹œëŠ” $3 \times 3 \times 128 \times 64 = 73,728 $ ê°œì˜ í•™ìŠµ íŒŒë¼ë¯¸í„° ìˆ˜</p>
  </li>
  <li>Max pooling layerëŠ” parameter outputì´ ì—†ë‹¤.
    <ul>
      <li>ë©”ëª¨ë¦¬ ì„±ëŠ¥ ì œí•œ ë•Œë¬¸ì— 2ê°œë¡œ ë‚˜ëˆ„ì–´ trainig í•˜ëŠ” layer?</li>
      <li>ê·¸ëŸ¬ë¯€ë¡œ ë‚˜ë‰œ ìˆ˜ë§Œí¼ ê³±í•´ì£¼ë©´ ëœë‹¤.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210207232952600.png" alt=""></p>

<p><strong>[img. convolution ì—°ì‚° ì¶”ê°€ ì˜ˆì‹œ]</strong></p>

<ul>
  <li>$5 \times 5 \times 48 \times 128*2 \approx 307k$</li>
  <li>êµ³ì´ ì •í™•íˆ ìˆ«ìë¥¼ ì„¸ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ëŒ€ëµì ì¸ ì–‘(ë§ˆì¹˜ ì•Œê³ ë¦¬ì¦˜ì˜ big O í‘œê¸°ì²˜ëŸ¼) ì„±ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210207234905710.png" alt=""></p>

<p><strong>[img. dense layer (fully connected layer) ì—°ì‚° ì˜ˆì‹œ]</strong></p>

<ul>
  <li>
    <p>inputì˜ neuronê³¼ outputì˜ neuronì˜ ìˆ˜ë¥¼ ê³±í•œ ë§Œí¼ì´ë‹¤.</p>
  </li>
  <li>
    <p>$13 * 13 * 128 * 2 \times 2048 *2 \approx 177M$</p>
  </li>
  <li>$2048 * 2 \times 2048 *2 \approx 16M$</li>
  <li>$2048*2 \times 1000 \approx 4M$</li>
  <li>Convolution operatorëŠ” ê°™ì€ kernelì„ ì—°ì‚°ì— ì“°ë©´ì„œ parameterê°€ ê³µìœ ë˜ë¯€ë¡œ ë¹„êµì  ì ë‹¤.</li>
  <li>1000ë°° ì´ìƒì˜ parameterê°€  fully connected layerì— ì“°ì´ë¯€ë¡œ ì´ ë¶€ë¶„ì„ ì¤„ì´ëŠ” ì¶”ì„¸ì´ë‹¤.</li>
</ul>

<h3 id="1x1-convolutionë¥¼-í™œìš©í•œ-ìµœì í™”">1x1 convolutionë¥¼ í™œìš©í•œ ìµœì í™”</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208001104816.png" alt=""></p>

<p><strong>[img. 1x1 convolution ì ìš©ì— ì˜í•œ ì°¨ì›(filter)ì˜ ê°ì†Œ íš¨ê³¼]</strong></p>

<ul>
  <li>1x1 convolution layer ì—°ì‚°ì„ í†µí•˜ì—¬ ì°¨ì›(filter)ë¥¼ ê°ì†Œì‹œì¼œ parameter ìˆ˜ë¥¼ ì¤„ì´ë©°, ì¸µ ìˆ˜ëŠ” ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.</li>
  <li>bottleneck êµ¬ì¡°ì˜ ì›ë¦¬</li>
</ul>

<h2 id="Modern-CNN">Modern CNN</h2>

<ul>
  <li>~2018ë…„ ê¹Œì§€ì˜ CNN ê¸°ìˆ </li>
  <li>ImageNet Large-Scale Visual Recognition Challenge ìœ„ì£¼
    <ul>
      <li>Classification, Detection, Localization, Segmentation ë“±ì˜ ë¶€ë¬¸ì´ ìˆìŒ</li>
    </ul>
  </li>
  <li>ë”¥ëŸ¬ë‹ì˜ ìµœê·¼ Error rateëŠ” 3.5% ì´í•˜ë¡œ ì¸ê°„ì˜ 5.1% ë³´ë‹¤ ì—ëŸ¬ê°€ ì ë‹¤.</li>
</ul>

<ol>
  <li>AlexNet</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208080644909.png" alt=""></p>

<p><strong>[img. AlexNet êµ¬ì¡°]</strong></p>

<ul>
  <li>
    <p>ì»´í“¨í„° ì„±ëŠ¥ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë„¤íŠ¸ì›Œí¬ë¥¼ 2ê°œì˜ ê¸¸ë¡œ ë‚˜ëˆˆ 8ë‹¨ì˜ layer.</p>
  </li>
  <li>11x11x3 filter ì‚¬ìš©
    <ul>
      <li>fitlerì˜ í¬ê¸°ê°€ í´ìˆ˜ë¡ convolution ì—°ì‚° ì‹œ, ê³ ë ¤ë˜ëŠ” inputì˜ í¬ê¸°(receptive field)ê°€ ì»¤ì§</li>
      <li>receptive field : feature map ì¶”ì¶œì‹œ ê³ ë ¤ ê°€ëŠ¥í•œ ì…ë ¥ì˜ spacial dimension.</li>
      <li>ë‹¨, parameterì˜ ìˆ˜ê°€ ì»¤ì§</li>
    </ul>
  </li>
  <li>ReLU í™œì„± í•¨ìˆ˜ ì‚¬ìš©.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208081912800.png" alt=""></p>

<ul>
  <li><strong>[img. Relu í•¨ìˆ˜, 0 ì´í•˜ëŠ” 0ìœ¼ë¡œ ë°”ê¾¼ë‹¤.]</strong>
    <ul>
      <li>ì„ í˜• ëª¨ë¸ì˜ ì¥ì , í•™ìŠµì´ ìš©ì´, generalization íš¨ê³¼ê°€ ì¢‹ê³ , Vanishing gradient problem ê·¹ë³µ</li>
    </ul>
  </li>
  <li>2ê°œ GPU ì‚¬ìš©, Data augmentation, Dropout í™œìš©
    <ul>
      <li>ê·¸ ì™¸ì—ë„ Local Response normalization, Overlapping pooling í™œìš©</li>
    </ul>
  </li>
</ul>

<ol>
  <li>VGGNet</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208082150147.png" alt=""></p>

<p><strong>[img.VGGNet êµ¬ì¡°]</strong></p>

<ul>
  <li>
    <p>3x3 convolution filterë¥¼ í™œìš©í•˜ì—¬ íŒŒë¼ë¯¸í„° ìˆ˜ ì¤„ì„</p>
  </li>
  <li>
    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208090026567.png" alt=""></p>

    <p><strong>[img. 3x3 filter ë‘ë²ˆ ì‚¬ìš© vs 5x5 filter í•œë²ˆ ì‚¬ìš© íŒŒë¼ë¯¸í„° ìˆ˜ ë¹„êµ]</strong></p>

    <ul>
      <li>í•„í„°ë¥¼ í†µí•´ ë³´ëŠ” input fieldì˜ í¬ê¸°ëŠ” ê°™ìœ¼ë‚˜ 2ë²ˆ ê±¸ì¹¨ìœ¼ë¡œ ì¨ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ëŠ” ì¤„ì¼ ìˆ˜ ìˆë‹¤.</li>
      <li>ì´ ë°©ë²•ì„ í†µí•´ ë³´í†µ ìµœëŒ€ 7x7 í•„í„°ë¥¼ ë„˜ì§€ ì•ŠëŠ”ë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>Dropoutê³¼ 1x1 convolutionì„ dense layerì— í™œìš©</p>
  </li>
  <li>
    <p>16ì¸µ ë²„ì „(VGG16), 19ì¸µ ë²„ì „(VGG19)ì´ ìˆìŒ</p>
  </li>
</ul>

<ol>
  <li>GoogleNet</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208090439348.png" alt=""></p>

<p><strong>[img. googlenet êµ¬ì¡°]</strong></p>

<ul>
  <li>
    <p>NIN êµ¬ì¡°(Network in Network) : ë„¤íŠ¸ì›Œí¬ ë‚´ë¶€ì— ëª¨ë“ˆ í˜•ì‹ì˜ ì‘ì€ ë„¤íŠ¸ì›Œí¬ë“¤ì˜ ë°˜ë³µì´ ì¡´ì¬</p>
  </li>
  <li>
    <p>Inception blocks: ì—¬ëŸ¬ê°œë¡œ í¼ì¡Œë‹¤ê³  ë‹¤ì‹œ í•©ì³ì§€ëŠ” ë¸”ë¡</p>

    <ul>
      <li><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208090603118.png" alt=""></li>
    </ul>

    <p><strong>[img. inception ëª¨ë“ˆ]</strong></p>

    <ul>
      <li>
        <p>ì—¬ëŸ¬ ê°œì˜ responsedë¥¼ ì¶”ì¶œ ê°€ëŠ¥</p>
      </li>
      <li>
        <p>1x1 Conv layerì— ì˜í•´ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ ê°ì†Œ.</p>
      </li>
      <li>
        <p>ì±„ë„ ë°©í–¥ì˜ ì°¨ì›ì„ ì¤„ì´ëŠ” íš¨ê³¼ê°€ ìˆìŒ</p>
      </li>
    </ul>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208092105983.png" alt=""></p>

    <p><strong>[img. 1x1 convolutionì˜ ì±„ë„ ê°ì†Œ íš¨ê³¼ì— ì˜í•œ íŒŒë¼ë¯¸í„° ìˆ˜ ê°ì†Œ]</strong></p>
  </li>
  <li>
    <p>VGGNet, AlexNetì— ë¹„í•´ layerëŠ” ê¹Šì§€ë§Œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì˜¤íˆë ¤ ì ìŒ</p>
  </li>
</ul>

<ol>
  <li>ResNet</li>
</ol>

<ul>
  <li>
    <p>ê¹Šì€ ì¸µì„ ê°€ì§„ DNNì˜ training errorì™€ test errorì˜ ê°­ì„ ì¤„ì´ê³  í•™ìŠµì„ ìš©ì´í•˜ê²Œ í•¨.</p>
  </li>
  <li>
    <p>ì´ë¥¼ í†µí•´ ê¹Šì€ ì¸µì˜ DNNì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•´ì¤Œ.</p>
  </li>
  <li>
    <p>parameter  ìˆ˜ëŠ” ì¤„ê³ , ì„±ëŠ¥ì„ ëŠ˜ì–´ë‚˜ê¸° ì‹œì‘í•¨</p>
  </li>
  <li>
    <p>Residual connection (or Identity map)</p>

    <ul>
      <li>
        <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208093731195.png" alt=""></p>

        <p><strong>[img. identity map(residual map) ë¹„êµ]</strong></p>
      </li>
      <li>
        <p>ì¶œë ¥ ê°’ì„ ì¼ë¶€ layer ë„ˆë¨¸ì˜ ì¶œë ¥ì— ë”í•´ ì¤Œ(skip connection)</p>
      </li>
      <li>ìœ„ ì²˜ëŸ¼ ë”í•´ì£¼ëŠ” simp shortcut ë°©ì‹ê³¼ 1x1 conv layerë¥¼ ê±°ì³ì„œ ë”í•´ì£¼ëŠ” Projected shortcut ë°©ì‹(ì°¨ì›ì„ ë§ì¶°ì¤˜ì•¼ ë” í•´ì§€ë¯€ë¡œ)ì´ ìˆë‹¤.</li>
      <li>
        <p>ì¼ë°˜ì ìœ¼ë¡œ convolution layer ë‹¤ìŒì— batch Norm, activation í•¨ìˆ˜ ìˆœìœ¼ë¡œ ë°°ì¹˜ë˜ë©°, Residual í•©ì‚°ì€ batch Norm ë’¤ì—, activation ì•ì—ì„œ ì´ë£¨ì–´ì§„ë‹¤.</p>

        <ul>
          <li>ë…¼ë€ì´ ìˆìœ¼ë©°, ìˆœì„œê°€ ë°”ë€Œì–´ì•¼ ì„±ëŠ¥ì´ ì¢‹ì•„ì§ˆ ë•Œë„ ì‡ë‹¤.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>Bottleneck architecture</p>

    <ul>
      <li>1x1 conv layerì„ í†µí•´ input channelì„ ì¤„ì—¬ì„œ parameter ìˆ˜ë¥¼ ì¤„ì´ê³ ,  ë‹¤ì‹œ ì±„ë„ì„ ëŠ˜ë ¤ì„œ ê°’ì„ ë”í•  ìˆ˜ ìˆê²Œ í•¨.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208095358891.png" alt=""></p>

<p><strong>[img. bottleneck architecture ê·¸ë¦¼]</strong></p>

<ol>
  <li>DenseNet</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208103813747.png" alt=""></p>

<p><strong>[img. Resnetê³¼ DenseNet ì°¨ì´]</strong></p>

<ul>
  <li>Resnetê³¼ ë‹¬ë¦¬ ê²°ê³¼ê°’ì„ ë”í•˜ëŠ” ê²ƒì´ ì•„ë‹Œ concatenation í•˜ëŠ” ë°©ì‹</li>
  <li>ì±„ë„ì´ ì ì  ê¸°í•˜ ê¸‰ìˆ˜ì ìœ¼ë¡œ ì»¤ì§€ë¯€ë¡œ, ì¤‘ê°„ì— í•œë²ˆì”© ì±„ë„ì„ ì¤„ì—¬ì¤Œ
    <ul>
      <li>Dense Block : layerê²°ê³¼ë¥¼ concatenateí•˜ì—¬ ì±„ë„ì„ ëŠ˜ë¦¼</li>
      <li>Transition Block : batchnormê³¼ 1x1 conv, 2x2 avgPoolingì„ í†µí•˜ì—¬ ì±„ë„ ìˆ˜ ì¤„ì„</li>
      <li>ìœ„ ë‘ blockì˜ ë°˜ë³µ</li>
    </ul>
  </li>
  <li>ê°„ë‹¨í•˜ê³  ì„±ëŠ¥ì´ ì¢‹ë‹¤.</li>
</ul>

<h2 id="Computer-Vision-Applications">Computer Vision Applications</h2>

<h3 id="Semantic-Segmentation">Semantic Segmentation</h3>

<ul>
  <li>ì´ë¯¸ì§€ ë‚´ë¶€ì˜ ì¼ë¶€(í”½ì…€)ë¥¼ ë¬¼ì²´ë¡œì¨ ì‹ë³„í•˜ëŠ” ë¬¸ì œ</li>
  <li>ììœ¨ ì£¼í–‰ì—ì„œ ì‚¬ëŒ, ì¸ë„, ìë™ì°¨ ë“±ì„ ì‹ë³„í•˜ëŠ” ë“±ì— ì‚¬ìš©</li>
</ul>

<h4 id="Fully-Convolutional-Network-FCN">Fully Convolutional Network(FCN)</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208195212790.png" alt=""></p>

<p><strong>[img. ê¸°ì¡´ì˜ CNN vs Fully Convolutional Network]</strong></p>

<ul>
  <li>
    <p>dense layerì„ ê±°ì¹˜ì§€ ì•Šê³ , convolution layerë¡œ ë°”ê¾¸ì–´ ê²°ê³¼ì˜ í¬ê¸°ë¥¼ 10ì´ ì•„ë‹Œ ì°¨ì›ì˜ ìˆ˜ë¥¼ 10ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì„ convolutionalizationì´ë¼ê³  í•œë‹¤.</p>
  </li>
  <li>
    <p>ì–‘ìª½ ë‹¤ parameter ìˆ˜ëŠ” ë˜‘ê°™ì´ 4x4x16x10 = 2560ìœ¼ë¡œ ê°™ë‹¤.</p>
  </li>
  <li>
    <p>í•˜ì§€ë§Œ ì´ë¥¼ í†µí•˜ì—¬ ì›ë³¸ë³´ë‹¤ sizeê°€ ì¤„ì–´ë“  heat mapì„ êµ¬í•  ìˆ˜ ìˆë‹¤.</p>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208210608453.png" alt=""></p>

<p><strong>[img. convolutionalize ë¥¼ í†µí•œ heat map ìƒì„±, ê³ ì–‘ì´ì˜ ì¶”ì •ìœ„ì¹˜ í™•ì¸ì´ ê°€ëŠ¥í•´ì§. ]</strong></p>

<h4 id="Deconvolution-conv-transpose">Deconvolution(conv transpose)</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208212617919.png" alt=""></p>

<p><strong>[img. Deconvolution ê°œë…]</strong></p>

<ul>
  <li>ìœ„ì˜ ì¤„ì–´ë“  sizeë¥¼ ì›ë˜ëŒ€ë¡œ ëŒë¦¬ê¸° ìœ„í•´ Deconvolutionì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.</li>
  <li>ì›ë˜ í”½ì…€ì„ ê·¸ëŒ€ë¡œ ëŒë ¤ì£¼ì§„ ì•Šìœ¼ë‚˜ ì›ë³¸ í¬ê¸°ë¡œ ëŒì•„ê°€ê²Œ ëœë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208212709296.png" alt=""></p>

<p><strong>[img. Deconvolutionì˜ ë„ì‹í™”]</strong></p>

<h3 id="Detection">Detection</h3>

<ul>
  <li>ì´ë¯¸ì§€ ë‚´ ë¬¼ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì°¾ëŠ” ë¬¸ì œ</li>
</ul>

<h4 id="R-CNN">R-CNN</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208213527247.png" alt=""><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208214004374.png" alt=""></p>

<p><strong>[img. R-CNNì˜ ì ˆì°¨ì™€ ì˜ˆì‹œ]</strong></p>

<ol>
  <li>ì´ë¯¸ì§€ì—ì„œ Selective searchë¥¼ í†µí•´ ë¬¼ì²´ë¡œ ì¶”ì •ë˜ëŠ” ë¶€ë¶„ì˜ bounding boxë¥¼ bounding box regressionì„ í†µí•˜ì—¬ ì „ë¶€ ë½‘ëŠ”ë‹¤.</li>
  <li>í•´ë‹¹ bounding boxë¥¼ ê°™ì€ í¬ê¸°ë¡œ ë°”ê¾¼ ë’¤, CNN(ì—¬ê¸°ì„œëŠ” AlexNet)ì„ í†µí•˜ì—¬ featureë¥¼ ë½‘ëŠ”ë‹¤.</li>
  <li>featuresë¥¼ SVM(support vector machine)ì„ í†µí•˜ì—¬ classificationí•œë‹¤.</li>
</ol>

<ul>
  <li>1ë²ˆì˜ ë¬¼ì²´ë¥¼ ì¶”ì •ë˜ëŠ” ë¶€ë¶„ì˜ bounding boxë¥¼ ì „ë¶€ ë½‘ëŠ” ë¶€ë¶„ì´ ì—„ì²­ë‚˜ê²Œ ëŠë¦¬ë‹¤.</li>
</ul>

<h4 id="SPPNet">SPPNet</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208214203081.png" alt=""></p>

<p><strong>[img. SPPNetì˜ êµ¬ì¡°]</strong></p>

<ul>
  <li>CNNì„ í•œë²ˆë§Œ ëŒë¦° ë’¤, í•´ë‹¹ ë°”ìš´ë”© ë°•ìŠ¤ í•˜ë‚˜ì—ì„œ featureë¥¼ ë½‘ê³  ë‚˜ì„œ ê·¸ê²ƒì„ spatial pyramid poolingì„ í†µí•˜ì—¬ classificationí•¨.</li>
</ul>

<h4 id="Fast-R-CNN">Fast R-CNN</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208221610071.png" alt=""></p>

<p><strong>[img. fasc R-CNN]</strong></p>

<ul>
  <li>SPPNetê³¼ ë¹„ìŠ·í•˜ë‹¤.</li>
</ul>

<ol>
  <li>ì¸í’‹ ì´ë¯¸ì§€ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì—¬ëŸ¬ê°œ ë½‘ëŠ”ë‹¤.</li>
  <li>CNN feature mapì„ ë§Œë“ ë‹¤.</li>
  <li>ROI(region of interest) poolingì„ í†µí•˜ì—¬ feature mapì„ ë½‘ê³ , classificationê³¼ bounding-box regressorë¥¼ ë½‘ëŠ”ë‹¤.</li>
</ol>

<h4 id="Faster-R-CNN">Faster R-CNN</h4>

<ul>
  <li>
    <p>Fast R-CNN + Region Proposal Network</p>
  </li>
  <li>
    <p>Region Proposal Network(RPN)</p>
  </li>
  <li>
    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208222331311.png" alt=""></p>

    <p><strong>[img. RPN ì˜ˆì‹œ]</strong></p>

    <ul>
      <li>ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜ ë˜í•œ êµìœ¡í•¨, classificationì€ í•˜ì§€ ì•ŠìŒ.</li>
      <li>Anchor Boxes: ë¯¸ë¦¬ ì •ì˜í•œ ë¬¼ì²´ í¬ê¸°ë¡œ ì´ë£¨ì–´ì§„ kernel</li>
    </ul>
  </li>
  <li>
    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208222455115.png" alt=""></p>

    <p><strong>[img. RPN ì°¨ì›]</strong></p>

    <ul>
      <li>RPNì˜ Fully Convì— ì˜í•´ í•´ë‹¹ ê³µê°„ì´ ì›í•˜ëŠ” ë¬¼ì²´ë¥¼ ê°€ì§€ê³  ìˆëŠ”ì§€ íŒë‹¨</li>
      <li>3ê°œì˜ region í¬ê¸°(128, 256,512)ì™€ 3ê°œì˜ ë¹„ìœ¨(1:1, 1:2, 2:1)ì„ ê°€ì§„ ì´ 9ê°œì˜ anchor boxesë¥¼ ê°€ì§</li>
      <li>ê° bouding boxê°€ ì¡°ì •ë˜ì–´ì•¼í•  í¬ê¸° (width í¬ê¸°, height í¬ê¸°, x offset, y offest) 4ê°œ</li>
      <li>í•´ë‹¹ bounding boxê°€ classificationì— ì“¸ëª¨ ìˆëŠ”ê°€?(use it or not) 2ê°œ</li>
      <li>ì´ 9*(4+2) = 54ê°œì˜ ì±„ë„ì„ ê°€ì§„ Fully Convë¥¼ ê°€ì§„ë‹¤.</li>
    </ul>
  </li>
  <li>
    <p>ì¢€ ë” ì¢‹ì€ ì„±ëŠ¥ì˜ detection ê°€ëŠ¥</p>
  </li>
</ul>

<h4 id="YOLO-You-only-look-once">YOLO(You only look once)</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208224922143.png" alt=""></p>

<p><strong>[img. yolo ì˜ˆì‹œ]</strong></p>

<ul>
  <li>
    <p>v5 ê¹Œì§€ ë‚˜ì™”ìŒ, ì•„ì£¼ ë¹ ë¦„, ë¦¬ì–¼ íƒ€ì„ì„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.</p>
  </li>
  <li>
    <p>ì¶”ì¶œí•œ bounding boxë“¤ì˜ featureë¥¼ í†µí•´ ê°ê° classification í•˜ëŠ” ë°©ì‹ì´ ì•„ë‹ˆë¼, í•œêº¼ë²ˆì— ëª¨ë“  bounding boxë¥¼ classification í•¨</p>
  </li>
  <li>
    <p>ì—¬ëŸ¬ bounding boxë¥¼ ë™ì‹œì— í•œë²ˆë§Œ í•˜ë¯€ë¡œ YOLOë¼ê³  í•œë‹¤.</p>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210208231334933.png" alt=""></p>

    <p><strong>[img. YOLO ì ˆì°¨]</strong></p>

    <ol>
      <li>ë¨¼ì € ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ SxS ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆˆë‹¤.
        <ul>
          <li>ì°¾ê³  ì‹¶ì€ ë¬¼ì²´ì˜ ì¤‘ì•™ì ì´ ì†í•´ìˆëŠ” ê·¸ë¦¬ë“œì—ì„œ bouding boxì™€ classificationì„ ì§„í–‰í•œë‹¤.</li>
        </ul>
      </li>
      <li>ë¬´ì–¸ê°€ ë¬¼ì²´ì˜ ì¤‘ì•™ì ì„ ê°–ëŠ” ì—¬ëŸ¬ê°œì˜ bounding boxì˜ x,y ìœ„ì¹˜ì™€ w,h í¬ê¸° ê·¸ë¦¬ê³  ì“¸ëª¨ ì—¬ë¶€ë¥¼ ì˜ˆì¸¡í•œë‹¤ ( ì´ ì •ë³´ 5ê°œë¥¼ B ë¼ê³  í•˜ì.).</li>
      <li>ìœ„ 2ë²ˆê³¼ ë™ì‹œì— ê° ê·¸ë¦¬ë“œê°€ ì†í•œ ë¬¼ì²´ì˜ classification(Cê°œì˜ classê°€ ìˆë‹¤ê³  ê°€ì •í•˜ì)ì„ ì§„í–‰í•œë‹¤.</li>
      <li>í•´ë‹¹ ì •ë³´ë¥¼ ì·¨í•©í•œ ë’¤, SxSx(B*5+C) ì‚¬ì´ì¦ˆë¥¼ ê°€ì§„ tensorê°€ ëœë‹¤.</li>
    </ol>
  </li>
  <li>
    <p>v2ì˜ ê²½ìš° ROI ì²˜ëŸ¼ ë¯¸ë¦¬ ì •ì˜ëœ í¬ê¸°ì˜ bounding boxë¥¼ ì´ìš©í•˜ê¸°ë„ í•˜ê³ , ë‹¤ë¥¸ ëª¨ë¸ë“¤ ë˜í•œ yoloì˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ë“±ì˜ ìƒí˜¸ì˜ ì¥ì ì„ ì´ìš©í•œ ë°œì „ì„ í•œë‹¤.</p>
  </li>
</ul>

<h2 id="Sequential-Models-RNN">Sequential Models - RNN</h2>

<h3 id="Sequential-Model">Sequential Model</h3>

<ul>
  <li>sequential dataë€ ìˆœì„œ ê´€ê³„ê°€ ì¤‘ìš”í•œ ì—°ì†í˜• ë°ì´í„°ë¡œ, ì…ë ¥ì˜ ì°¨ì›ì˜ í¬ê¸°ë¥¼ ì •í™•íˆ ì•Œ ìˆ˜ ì—†ë‹¤ëŠ” ë¬¸ì œê°€ ìˆë‹¤.(ì–¸ì œ ë¶€í„° ì–¸ì œê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼í•˜ëŠ”ê°€? ì–¸ì œ ë°ì´í„°ëŠ” ëì´ ë‚˜ëŠ”ê°€?)</li>
  <li>ì´ëŸ¬í•œ ë¬¸ì œ ë•Œë¬¸ì— CNNì´ë‚˜ Fully connected layerëŠ” ì‚¬ìš© ëª»í•œë‹¤.</li>
</ul>

<ol>
  <li>Naive sequence Model</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213145729813.png" alt=""></p>

<p><strong>[img. Naive sequence Model]</strong></p>

<ul>
  <li>ê³¼ê±°ì˜ ì •ë³´ë“¤ì„ ëª¨ë‘ ê³ ë ¤í•˜ëŠ” ëª¨ë¸</li>
</ul>

<ol>
  <li>Autoregressive model(AR model)</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213145749117.png" alt=""></p>

<p><strong>[img. Autoregressive model]</strong></p>

<ul>
  <li>fixed timespan $\tau$ë§Œí¼ ë§Œì„ ê³ ë ¤í•˜ëŠ” ëª¨ë¸</li>
</ul>

<ol>
  <li>Markov model(first-order autoregressive model)</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213145807612.png" alt=""></p>

<p><strong>[img. Markov model]</strong></p>

<ul>
  <li>ë°”ë¡œ ì „ ì •ë³´ë§Œì„ ì´ìš©í•˜ëŠ” ëª¨ë¸, joint distribution í‘œí˜„ì´ ì‰¬ì›€</li>
</ul>

<ol>
  <li>Latent autoregressive model</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213145826876.png" alt=""><br>
<strong>[img. Latent autoregressive model]</strong></p>

<ul>
  <li>ì¤‘ê°„ì˜ ê³¼ê±° ì •ë³´ë“¤ì„ ìš”ì•½í•˜ëŠ” Hidden stateë¥¼ ìƒì„±í•˜ì—¬ í•´ë‹¹ ì •ë³´ë¥¼ ì´ìš©í•˜ëŠ” ëª¨ë¸</li>
</ul>

<h3 id="Recurrent-Neural-Network-RNN">Recurrent Neural Network(RNN)</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213153323143.png" alt=""></p>

<p><strong>[img. RNN ê·¸ë¦¼]</strong></p>

<ul>
  <li>RNNì€ AR modelë“¤ì„ êµ¬í˜„í•œ ì‹ ê²½ë§,</li>
  <li>Short-term dependecies : RNNì˜ ë‹¨ì , ê³¼ê±° ì‹œì ì˜ ì •ë³´ê°€ ë¯¸ë˜ì— ì˜í–¥ì„ ë¼ì¹˜ê¸° í˜ë“¦, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë°‘ì˜ LSTMì´ ë‚˜íƒ€ë‚¨.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213155738322.png" alt=""></p>

<p><strong>[img.  RNN hidden stateì˜ gradient ë¬¸ì œì˜ ì›ì¸]</strong></p>

<ul>
  <li>ë˜í•œ Activation functionì˜ ì¢…ë¥˜ì— ë”°ë¼ Vanishing/exploding gradient ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆë‹¤.
    <ul>
      <li>RNNì—ì„œ ReLUë¥¼ ì˜ ì•ˆì“°ëŠ” ì´ìœ </li>
    </ul>
  </li>
</ul>

<h3 id="Long-Short-Term-Memory-LSTM">Long Short Term Memory(LSTM)</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213160223994.png" alt=""></p>

<p><strong>[img. Vanilla RNN Unit]</strong></p>

<ul>
  <li>tanh(hyperparabolic) í•¨ìˆ˜ë¥¼ activation í•¨ìˆ˜ë¡œ í™œìš©í•˜ëŠ” ê¸°ë³¸ ìœ ë‹›ì´ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213160255147.png" alt=""></p>

<p><strong>[img. LSTM Unit]</strong></p>

<ul>
  <li>Long Term dependency ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ë° ì¢‹ì€ LSTM ìœ ë‹›</li>
  <li>ì´ì „ LSTM Unitì—ì„œ ì´í›„ LSTM Unitìœ¼ë¡œ cell stateì™€ hidden state ë¥¼ ë„˜ê²¨ì£¼ê²Œ ëœë‹¤.</li>
  <li>cell stateëŠ” hidden stateì™€ ë‹¬ë¦¬ outputìœ¼ë¡œ ë‚˜ì˜¤ì§€ ì•Šìœ¼ë©°, ì¼ì¢…ì˜ ì´ì „ ì •ë³´ë“¤ì„ summaryë¥¼ í•´ì£¼ëŠ” ì •ë³´, LSTMì˜ Core idea</li>
</ul>

<h4 id="Gate">Gate</h4>

<ul>
  <li>LSTMì„ ì´ë£¨ëŠ” 3ê°œì˜ ê²Œì´íŠ¸ê°€ ì¡´ì¬, LSTMì˜ ë°ì´í„°ë¥¼ ì¡°ì‘</li>
</ul>

<ol>
  <li>Forget Gate</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213162034756.png" alt=""></p>

<p><strong>[img. Forget gate êµ¬ì¡°]</strong></p>

<ul>
  <li>ì–´ë–¤ ì •ë³´ë¥¼ ìŠì–´ë²„ë¦´ì§€ ê²°ì •.</li>
  <li>f~t~ëŠ” sigmoidë¥¼ ì‚¬ìš©í•˜ì—¬ 0 ì—ì„œ 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë‚˜ì˜¤ë©°,  ì´ì „ cell state ì •ë³´ì˜ ì¼ë¶€ë¥¼ ë²„ë¦¬ê±°ë‚˜ ì‚´ë¦°ë‹¤.</li>
</ul>

<ol>
  <li>Input Gate</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213162053068.png" alt=""></p>

<p><strong>[img. Input Gate êµ¬ì¡°]</strong></p>

<ul>
  <li>ì–´ë–¤ ì •ë³´ë¥¼ cell stateì— ì˜¬ë¦´ì§€ ê²°ì •</li>
  <li>i~t~ëŠ” ì´ì „ Hidden stateì™€ X~t~ë¥¼ í†µí•˜ì—¬ ì–´ë–¤ ì •ë³´ë¥¼ ì˜¬ë¦´ì§€ ë§ì§€ ê²°ì •í•œ ê²°ê³¼ì¸ i~t~ë¥¼ ë§Œë“ ë‹¤.</li>
  <li>ë˜ í•œ ë§ˆì°¬ê°€ì§€ë¡œ ì´ì „ Hidden stateì™€ X~t~ë¥¼ í†µí•˜ì—¬ ì˜¬ë¦´ ì •ë³´ì¸ $C_t^{\sim}$(C í‹¸ë‹¤)ë¥¼ ë§Œë“ ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213162709154.png" alt=""></p>

<p><strong>[img. ìƒˆë¡œ í†µê³¼ì‹œí‚¬ Cell State í˜•ì„±]</strong></p>

<ul>
  <li>$C_t^{\sim}$ì™€ i~t~,f~t~ ë¥¼ ì´ìš©í•´ ì—…ë°ì´íŠ¸í•  Cellì„ ë§Œë“¤ê²Œ ëœë‹¤.</li>
</ul>

<ol>
  <li>Ouput Gate</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213162821444.png" alt=""></p>

<p><strong>[img. Oupt Gate êµ¬ì¡°]</strong></p>

<ul>
  <li>ìœ„ì—ì„œ ë§Œë“  Update cell stateì™€ input ì„ ì´ìš©í•´ outputê°’ì„ ë§Œë“ ë‹¤.</li>
</ul>

<h3 id="Gated-Recurrent-Unit-GRU">Gated Recurrent Unit(GRU)</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213165320497.png" alt=""></p>

<p><strong>[img. GRU unit êµ¬ì¡°]</strong></p>

<ul>
  <li>reset gateì™€ update gateë§Œ ì¡´ì¬í•˜ë©° cell stateê°€ ì¡´ì¬ í•˜ì§€ ì•Šë‹¤.
    <ul>
      <li>forget gateì™€ ë¹„ìŠ·í•œ reset gateì™€ ë¹„ìŠ·í•œ update gateê°€ ì¡´ì¬í•œë‹¤.</li>
    </ul>
  </li>
  <li>LSTMì— ë¹„í•´ êµ¬ì¡°ê°€ ë‹¨ìˆœí•˜ì—¬ parameter ìˆ˜ê°€ ì ì–´ generalization performanceê°€ ì¢‹ìœ¼ë©°, ì„±ëŠ¥ì´ ì¢‹ì€ í¸ì´ë‹¤</li>
  <li>í•˜ì§€ë§Œ ìµœê·¼ì—ëŠ” ìœ„ ì„¸ê°€ì§€ êµ¬ì¡° ì „ë¶€ë¥¼ transfromer êµ¬ì¡°ë¡œ ëŒ€ì²´ë˜ëŠ” ì¶”ì„¸ì´ë‹¤.</li>
</ul>

<h2 id="Transformer-ëª¨ë¸">Transformer ëª¨ë¸</h2>

<ul>
  <li>
    <p>Jay Alammarì˜ ë¸”ë¡œê·¸ì—ì„œ ê°€ì ¸ì˜¨ ê·¸ë¦¼ë“¤ì„(http://jalammar.github.io/illustrated-transformer/)</p>
  </li>
  <li>
    <p>ë¶ˆê·œì¹™ì ì´ê³  ì˜ˆìƒí•˜ê¸° í˜ë“  sequential ë°ì´í„°ì˜ ë¬¸ì œì ì„ í•´ê²°í•œ ëª¨ë¸</p>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213192304126.png" alt=""></p>

<p><strong>[img. sequential dataì˜ ëŒ€í‘œ ì˜¤ë¥˜]</strong></p>

<h3 id="Transformer">Transformer</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213192519328.png" alt=""></p>

<p><strong>[img. Transformer ëª¨ë¸ ì˜ˆì‹œ]</strong></p>

<ul>
  <li>
    <p>ì¬ê·€ì  êµ¬ì¡°ê°€ ì—†ëŠ” ëŒ€ì‹ , attentionì´ë€ êµ¬ì¡°ë¥¼ í™œìš©í•œ sequence model</p>
  </li>
  <li>
    <p>ê¸°ê³„ì–´ ë²ˆì—­ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì‹œì‘í–ˆì§€ë§Œ ì—¬ëŸ¬ ë¬¸ì œë¥¼ í•´ê²° í•  ìˆ˜ ìˆë‹¤.</p>
  </li>
  <li>
    <p>Encoderì™€ Decoder êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ì‡ë‹¤.</p>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213213040186.png" alt=""></p>

<p><strong>[img. NMT ë¬¸ì œì—ì„œ encoder, decoder êµ¬ì¡°]</strong></p>

<ul>
  <li>ë™ì¼í•œ êµ¬ì¡°, ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë¥¼ ë°›ëŠ” encoder, decoderê°€ ìŒ“ì—¬ìˆëŠ” êµ¬ì¡°</li>
  <li>í•˜ë‚˜ì˜ ëª¨ë¸ì— ì…ë ¥ê³¼ ì¶œë ¥ ê°’ì´ ê°ê° ë„ë©”ì¸, ì…ë ¥ì˜ ìˆ«ì ë“±ì„ ë‹¤ë¥´ê²Œ ì¤„ ìˆ˜ ìˆë‹¤.</li>
  <li>ì¦‰ encoder-decoder ëª¨ë¸ì˜ ê²½ìš°, encoderê°€ í•˜ë‚˜ì”©ì´ ì•„ë‹Œ í•œë²ˆì— ì…ë ¥ì„ ì²˜ë¦¬í•œë‹¤.</li>
</ul>

<h4 id="ì–´ë–»ê²Œ-encoderëŠ”-í•œë²ˆì—-nê°œì˜-ì…ë ¥ì„-ë™ì‹œì—-ì²˜ë¦¬í•˜ëŠ”ê°€">ì–´ë–»ê²Œ encoderëŠ” í•œë²ˆì— nê°œì˜ ì…ë ¥ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ”ê°€?</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210213221542564.png" alt=""></p>

<p><strong>[img. encoder êµ¬ì¡°]</strong></p>

<ul>
  <li>
    <p>Feed Forward Neural Network: MLPë•Œì™€ ë™ì¼</p>
  </li>
  <li>
    <p>Self-Attention: encoderì™€ decorder êµ¬ì¡°ì˜ í•µì‹¬, Attentionì´ë€ í•´ë‹¹ ë‹¨ì–´ë¥¼ ì²˜ë¦¬í•  ë•Œ ë‹¤ë¥¸ ë‹¨ì–´ì— ì–¼ë§ˆë‚˜ ê´€ê³„ì„±ì„ í• ë‹¹í•˜ëŠ” ê°€?ì´ë‹¤.</p>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214004658258.png" alt=""></p>

<p><strong>[img. ë‹¨ê³„1, 2 ]</strong></p>

<ol>
  <li>ë¨¼ì € ê° ë‹¨ì–´ë“¤ì„ embedding vectorë¡œ ë°”ê¾¼ ë’¤, self attention ì¸µì—ì„œ ì…ë ¥ëœ nê°œì˜ ë‹¨ì–´ë“¤ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ìƒˆë¡œìš´ zë²¡í„°ë¥¼ ìƒì„±í•œë‹¤.</li>
  <li>ê·¸ í›„ Feed Forwardì—ì„œëŠ” ë™ì¼í•œ ì¡°ê±´ì˜ Feed-forward ì¸µì„ ê° ë‹¨ì–´ ë…ë¦½ì ìœ¼ë¡œ í†µê³¼ ì‹œí‚¨ë‹¤.</li>
</ol>

<h5 id="ì¢€-ë”-ìì„¸í•œ-ë²¡í„°-ì²˜ë¦¬-ì˜ˆì‹œ">ì¢€ ë” ìì„¸í•œ ë²¡í„° ì²˜ë¦¬ ì˜ˆì‹œ</h5>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214004934458.png" alt=""></p>

<p><strong>[img. ë‹¨ì–´ê°€ 2ê°œ ì£¼ì–´ì¡Œì„ ì‹œ ì˜ˆì‹œ]</strong></p>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214010304363.png" alt=""></p>

<p><strong>[img. ì„¸ ë²¡í„° ìƒì„±]</strong></p>

<ul>
  <li>Self attention êµ¬ì¡°ëŠ” embeddingëœ ë²¡í„° í˜•íƒœë¡œ ë‹¨ì–´ê°€ ì£¼ì–´ì§€ë©´, ê° ë‹¨ì–´ ë§ˆë‹¤ Neutral networkë¥¼ ì´ìš©í•´ Queries, Keys, Values ë¼ëŠ” ì„¸ê°œì˜ ë²¡í„°(Q,K,V ë²¡í„°)ë¥¼ ìƒì„±í•œë‹¤.
    <ul>
      <li>ì´ ì„¸ ë²¡í„°ë¥¼ í†µí•´ embedding vectorë¥¼ ìƒˆë¡œìš´ ë²¡í„°ë¡œ ë°”ê¿”ì¤€ë‹¤.(=encoding)</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214010645549.png" alt=""></p>

<p><strong>[img. Thinking ë‹¨ì–´ì˜ Score ìƒì„±]</strong></p>

<ul>
  <li>Thinkingì˜ Queries ë²¡í„°ì™€ ëª¨ë“  ë‹¨ì–´ë“¤ì˜ Keys ë²¡í„°ë¥¼ ë‚´ì (inner product)í•˜ì—¬ Scoreë¥¼ ìƒì„±
    <ul>
      <li>Scoreë¥¼ í†µí•´ ë‹¤ë¥¸ ë‹¨ì–´ì™€ì˜ ê´€ê³„ì„±, ìœ ì‚¬ì„± ë“±(=attention)ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214012722424.png" alt=""></p>

<p><strong>[img. Scoreì˜ normalize ë° z1 ë²¡í„° ìƒì„±]</strong></p>

<ul>
  <li>Score ê°’ì„ 8(í‚¤ ë²¡í„°ì˜ ì°¨ì›(ì—¬ê¸°ì„œëŠ” 64)ì˜ ë£¨íŠ¸,$\sqrt d_k$)ë¡œ ë‚˜ëˆ  ì£¼ì–´ Normalize(ì¼ì • ë²”ìœ„ì—ë§Œ ë¨¸ë¬´ë¥´ê²Œ í•˜ê¸° ìœ„í•´ì„œ)í•œë‹¤.</li>
  <li>ì´ í›„, softmax í•¨ìˆ˜ë¡œ 0~1 ì‚¬ì´ë¡œ ë§Œë“¤ì–´ Attention weightsë¥¼ ë§Œë“ ë‹¤.</li>
  <li>Attention Weightsë¥¼ Value vectorë¡œ Weighted Sumì„ í•˜ì—¬ í•œ ë‹¨ì–´ì˜ z(ì¸ì½”ë”© ë²¡í„°) ë²¡í„°ë¥¼ ìƒì„±í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214013256771.png" alt=""></p>

<p><strong>[img. Key, Query, Value vector ìƒì„±]</strong></p>

<ul>
  <li>W^Q^,W^K^,W^V^ëŠ” ëª¨ë“  ë‹¨ì–´ê°€ ê³µìœ í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214013749122.png" alt=""></p>

<p><strong>[img. ì¸ì½”ë”© ë²¡í„° ìƒì„±]</strong></p>

<ul>
  <li>Value vectorì˜ ì°¨ì›ì€ ì—„ë°€íˆ ë§í•´ weighted sumë§Œ í•˜ë¯€ë¡œ Query vector, Key vectorì™€ ë‹¬ë¼ë„ ëœë‹¤.</li>
</ul>

<h4 id="Transformer-êµ¬ì¡°ì˜-ì¥ë‹¨ì ">Transformer êµ¬ì¡°ì˜ ì¥ë‹¨ì </h4>

<ul>
  <li>ì´ëŸ°ì‹ìœ¼ë¡œ ëª¨ë“  ë‹¨ì–´ë“¤ì´ ì„œë¡œ ì˜í–¥ì„ ì£¼ë¯€ë¡œ, ê°™ì€ ë‹¨ì–´ë¼ë„ ë‹¤ë¥¸ ë‹¨ì–´ê°€ ë“¤ì–´ê°€ë©´ ê²°ê³¼ê°’ì´ ë‹¬ë¼ì§€ë¯€ë¡œ, ë³€í™”ì— ìš©ì´í•œ ëª¨ë¸ì´ ë‚˜ì˜¨ë‹¤..</li>
  <li>ëŒ€ì‹  ëª¨ë“  ë‹¨ì–´ë¥¼ ê³ ë ¤í•´ì•¼í•˜ë¯€ë¡œ ë§ì€ ì»´í“¨íŒ… ìì›ì´ í•„ìš”í•˜ë‹¤.</li>
</ul>

<h4 id="Multi-headed-attention-MHA">Multi-headed attention(MHA)</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214014450983.png" alt=""></p>

<p><strong>[img. attentionì´ 2ë²ˆ ì‹¤í–‰ëœ ë‹¨ì–´]</strong></p>

<ul>
  <li>attention ê³¼ì •ì„ ì—¬ëŸ¬ë²ˆ ì‹¤í–‰í•¨, ë‹¨ì–´ë§ˆë‹¤ Query, Key, Value ë²¡í„°ê°€ ì—¬ëŸ¬ê°œ ìƒì„±ëœë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214014729085.png" alt=""></p>

<p><strong>[img. ì—¬ëŸ¿ ìƒì„±ëœ ì¸ì½”ë”© ë²¡í„°]</strong></p>

<ul>
  <li>ì´ë¥¼ í†µí•´ ì—¬ëŸ¬ê°œ(ì˜ˆì‹œì—ì„  8ê°œ)ì˜ ì¸ì½”ë”© ë²¡í„°(z0~z7)ë¥¼ ìƒì„±í•˜ê²Œ ëœë‹¤</li>
  <li>ì´ 8ê°œë¥¼ í•©ì³ì„œ ë‹¤ìŒ layerì— input ë˜ì–´ì•¼ í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214014854687.png" alt=""></p>

<p><strong>[img. learnable linear mapì„ í†µí•´ í†µí•©ëœ ì°¨ì›ì˜ ë²¡í„°(Z)ë¡œ ìƒì„±]</strong></p>

<ul>
  <li>inputëœ ë‹¨ì–´, embedding vectorì™€ output ì¸ì½”ë”© ë²¡í„°(z)ë“¤ì˜ ì°¨ì›ì´ ê°™ì•„ì•¼í•œë‹¤.</li>
  <li>ê·¸ëŸ¬ë¯€ë¡œ Learnable Linear ampì„ ì´ìš©í•´ êµìœ¡ì‹œí‚¨ W^o^ê°’ì„ ê³±í•´ì„œ ì°¨ì›ì„ ë§ì¶°ì¤€ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214015143739.png" alt=""></p>

<p><strong>[img. ì „ì²´ì ì¸ MHAì˜ ë™ì‘]</strong></p>

<ul>
  <li>ì‹¤ì œë¡œëŠ” ìœ„ì˜ ë°©ë²•ë³´ë‹¤ëŠ” inputì˜ embdding vectorë¥¼ nê°œë¡œ ë‚˜ëˆˆ ë’¤, ë‚˜ëˆ ì§„ ì¼ë¶€ë“¤ë¡œ attentionì„ ë§Œë“  ë’¤, ë‹¤ì‹œ concatenate í•œë‹¤.
    <ul>
      <li>ex) 100ì°¨ì› input -&gt; 10ê°œë¡œ ë‚˜ëˆ„ì–´ 10ì°¨ì› z0~z10 10ê°œ ìƒì„± -&gt; 100ì°¨ì› output<br>
(Z)ìœ¼ë¡œ í•©ì¹¨</li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <p>(ìœ„ì˜ nê°œì˜ ë™ì‹œ ì²˜ë¦¬ ì˜ˆì œì—ì„œ outputì„ êµ¬í•œ ë’¤ ë¶€í„° ì´ì–´ì§) attentionì„ í•˜ê¸° ì´ì „ì— embedding vectorì— POSITIONAL ENCODDING ì´ë¼ëŠ” ë²¡í„°ë¥¼ ë”í•´ì¤€ë‹¤.</p>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214015901821.png" alt=""></p>

    <p><strong>[img. positional encdodingì˜ í•©]</strong></p>

    <ul>
      <li>ì¼ì¢…ì˜ biasì™€ ë¹„ìŠ·í•˜ë©°, ìœ„ attention ê³¼ì •ì„ ë³´ë©´ dataì˜ sequenceì™€ independent í•˜ê¸° ë•Œë¬¸ì—(ì¦‰, ë‹¨ì–´ì˜ ìˆœì„œê°€ ë’¤ë°”ê»´ë„ ê°™ì€ ê°’ì´ ë‚˜ì˜¤ê²Œ ë˜ì–´ìˆë‹¤.) ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë”í•´ì¤€ë‹¤.</li>
    </ul>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214020050099.png" alt=""></p>
  </li>
</ol>

<p><strong>[img. 512-dimensional ì¼ì‹œ, positioinal encoding ë²¡í„° êµ¬í•˜ëŠ” ë²•1]</strong></p>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214020449236.png" alt=""></p>

<p><strong>[img. ìµœì‹  ë°©ë²•ì˜ Positional encoding êµ¬í•˜ëŠ” ë²• 2]</strong></p>

<ul>
  <li>í¬ì§€ì…˜ë³„ë¡œ íŠ¹ì • ê·¸ë˜í”„ì˜ ê°’ì„ ê°€ì ¸ì™€ ë”í•´ì£¼ë©´ ëœë‹¤.(predefined)</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214021139815.png" alt=""></p>

<p><strong>[ì „ì²´ì ì¸ encoderì˜ ê³¼ì •]</strong></p>

<h4 id="decoderì™€-encoder-ì‚¬ì´ì—ëŠ”-ì–´ë–¤-ì •ë³´ê°€-êµí™˜ë˜ëŠ”ê°€">decoderì™€ encoder ì‚¬ì´ì—ëŠ” ì–´ë–¤ ì •ë³´ê°€ êµí™˜ë˜ëŠ”ê°€?</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214023616878.png" alt=""></p>

<p><strong>[img. encoderì™€ decoder ì‚¬ì´ì˜ ì •ë³´êµí™˜ ê·¸ë¦¼]</strong></p>

<ul>
  <li>decoderì—ì„œëŠ” ì£¼ì–´ì§„ vectorë¡œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ì—­í• ì„ í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/transformer_decoding_1.gif" alt=""></p>

<p><strong>[gif. encoder decoder í†µì‹  ì• ë‹ˆë©”ì´ì…˜1]</strong></p>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/transformer_decoding_2.gif" alt=""></p>

<p><strong>[gif. encoder decoder í†µì‹  ì• ë‹ˆë©”ì´ì…˜2]</strong></p>

<ul>
  <li>ê°€ì¥ ìƒìœ„ layerì˜ encoderì˜ ê²°ê³¼ê°’(z) ë²¡í„°ì˜  keyì™€ value, ë‘ ë²¡í„°ë¥¼  decoder layerë“¤ë¡œ ë³´ë‚¸ë‹¤.</li>
</ul>

<h4 id="decoderëŠ”-ì–´ë–»ê²Œ-ê²°ê³¼ê°’ì„-ë§Œë“¤ì–´-ë‚´ëŠ”ê°€">decoderëŠ” ì–´ë–»ê²Œ ê²°ê³¼ê°’ì„ ë§Œë“¤ì–´ ë‚´ëŠ”ê°€?</h4>
<ul>
  <li>ì´í›„ decoderì— ë“¤ì–´ê°€ëŠ” Query vectorì™€ k, v ë²¡í„°ë¡œ auto regressive í•˜ê²Œ ê²°ê³¼ë¬¼ì„ ì¶œë ¥í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214024918909.png" alt=""><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214024933899.png" alt=""></p>

<p><strong>[img. decoder í•™ìŠµ ê³¼ì •]</strong></p>

<ul>
  <li>ì´í›„,  decoderì˜ slef-attention layerì—ì„œ maskingì„ í†µí•˜ì—¬ ìƒì„±í•˜ë ¤ëŠ” ë‹¨ì–´ì™€ ê·¸ ë’¤ ìƒì„±í•´ì•¼í•  ë‹¨ì–´ë“¤ì„ ê°€ë¦° ë’¤, ì•ì—ì„œ ì´ë¯¸ ìƒì„±í•œ ë‹¨ì–´ì— ì˜ì¡´í•´ì„œ í•™ìŠµí•˜ê²Œ ë§Œë“ ë‹¤.</li>
  <li>ë˜, Encoder-Decoder attention layerì—ì„œ encoderì—ì„œ ì¤€ ë²¡í„° ë‘˜ì„ ë°›ì•„ì„œ í•™ìŠµì‹œí‚¨ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214031228131.png" alt=""></p>

<p><strong>[img. decoder í•™ìŠµì˜ ìµœì¢… ê³¼ì •]</strong></p>

<ul>
  <li>ë§ˆì§€ë§‰ ì¸µì—ì„œëŠ” ë‹¨ì–´ë“¤ì˜ ë°°ì—´ì—ì„œ ë‹¨ì–´ë¥¼ ìƒ˜í”Œë§í•´ì„œ ê²°ê³¼ ê°’ì„ ë‚¸ë‹¤.</li>
</ul>

<h3 id="Transform-ëª¨ë¸ì˜-ê·¼í™©">Transform ëª¨ë¸ì˜ ê·¼í™©</h3>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214032425814.png" alt=""></p>

<p><strong>[img. encoderë§Œ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€ class êµ¬ë¶„í•˜ëŠ” ëª¨ë¸]</strong></p>

<ul>
  <li>ë‹¨ìˆœíˆ ë‹¨ì–´ë‚˜ ë‹¤ë¥¸ sequential data ë¿ë§Œì•„ë‹ˆë¼ vision ì˜ì—­ì—ë„ í™œìš©ë˜ê³  ìˆë‹¤.</li>
  <li>openAIì˜ DALL-Eì—ì„œ ë¬¸ì¥ì„ í†µí•´ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ì—°êµ¬ ë˜í•œ Transformerì˜ decoderë¥¼ í™œìš©í•˜ì—¬ ì§„í–‰í–ˆë‹¤.</li>
</ul>

<h2 id="Generative-Models-ìƒì„±-ëª¨ë¸">Generative Models(ìƒì„± ëª¨ë¸)</h2>

<h3 id="Introduction">Introduction</h3>

<ul>
  <li>Generative Modelì´ë€, ì´ë¯¸ì§€ ë“±ì„ ìƒì„±í•˜ê±°ë‚˜, í™•ë¥  ë°€ë„ë¥¼ íƒìƒ‰í•˜ê±°ë‚˜ ë¹„ì§€ë„ íŠ¹ìƒ‰ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì„ ì˜ë¯¸í•œë‹¤.
    <ul>
      <li>Generation: ì´ë¯¸ì§€ ìƒì„± ë“±(sampling)</li>
      <li>Density estimation: ì´ë¯¸ì§€ê°€ ê°•ì•„ì§€ ê°™ì€ê°€? ê³ ì–‘ì´ ê°™ì€ê°€? (anomaly detection), classify ëª¨ë¸ì„ í¬í•¨í•˜ê³  ìˆìŒ. (explicit ëª¨ë¸, &lt;=&gt; inplicit model: ìƒì„± ìœ„ì£¼ê°€ ê°€ëŠ¥í•œ ëª¨ë¸)</li>
      <li>Unsupervised representation learning:  ì´ë¯¸ì§€ ë‚´ë¶€ì˜ íŠ¹ìƒ‰ íƒìƒ‰ (feature learning)</li>
    </ul>
  </li>
</ul>

<h3 id="Basic-Discrete-Distributions">Basic Discrete Distributions</h3>

<ol>
  <li>Bernoulli distribution : ë™ì „ ë˜ì§€ê¸° ì²˜ëŸ¼ 0 ë˜ëŠ” 1ì´ ë‚˜ì˜¤ëŠ” í˜•íƒœ
    <ul>
      <li>$D={Heads, Tails}$</li>
      <li>Specify P(X = Heads)=p. Then P(X=Tails) = 1-p.
        <ul>
          <li>ì˜ˆë¥¼ ë“¤ì–´ ì•ë©´ì´ p ë©´ ë’·ë©´ì´ ë‚˜ì˜¬ í™•ë¥ ì€ 1-pë‹¤.</li>
        </ul>
      </li>
      <li>Write: X ~ Ber(p).</li>
    </ul>
  </li>
  <li>Categorical distribution: ì£¼ì‚¬ìœ„ ë˜ì§€ê¸° ê°™ì´ êµ¬ë¶„ë˜ëŠ”(discrete) ì—¬ëŸ¬ ê²°ê³¼ê°’ì´ ë‚˜ì˜¤ëŠ” í˜•íƒœ(1~6)</li>
</ol>

<ul>
  <li>$D={1,\dots,m}$</li>
  <li>Specify P(Y = i) = pi, such that $\sum^m_{i=1}p_i=1$.
    <ul>
      <li>ëª¨ë“  í™•ë¥ ì„ í•©í•´ì„œ 1</li>
    </ul>
  </li>
  <li>Write: Y ~ Cat(p~1~, â€¦, p~m~)</li>
</ul>

<ol>
  <li>ì˜ˆì‹œ</li>
</ol>

<ul>
  <li>RGB pixelì´ ê°€ì§€ëŠ” ê²½ìš°ì˜ ìˆ˜ëŠ” 256 * 256 *256ì´ë©°, í•„ìš”í•œ íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ëŠ” 255*255*255.</li>
</ul>

<h3 id="Structure-Through-Independence-Conditional-Independence">Structure Through Independence &amp; Conditional Independence</h3>

<ul>
  <li>
    <p>binary pixelì˜ ìˆ˜ê°€ 100ê°œ ë¼ê³ í•˜ë©´ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ëŠ” 2^100^-1ê°œê°€ ë˜ê³ , ì´ëŠ” ë„ˆë¬´ ë§ë‹¤.</p>
  </li>
  <li>
    <p>ë§Œì•½ ëª¨ë“  Pixelì´ ì„œë¡œ independent í•œë‹¤ê³  ê°€ì •í•˜ë©´ ê²½ìš°ì˜ ìˆ˜ëŠ” ê°™ì§€ë§Œ, íŒŒë¼ë¯¸í„°ì˜ ìˆ˜ëŠ” n(=100)ê°œë¡œ ì¤„ì¼ ìˆ˜ ìˆë‹¤.</p>
  </li>
  <li>í•˜ì§€ë§Œ ì‹¤ì œë¡œ independent í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë„ˆë¬´ ë§ì´ ì•ˆë˜ëŠ” ê°€ì •ì´ë‹¤.</li>
  <li>ì´ ë‘˜ ì‚¬ì´ì˜ íƒ€í˜‘ì ì„ ì°¾ê¸°ìœ„í•œ ê²ƒì´ Conditional independence ì´ë‹¤.</li>
</ul>

\[Chain\ Rule:\ p(x_1,\dots,x_n)=p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\dots p(x_n|x_1,\dots,x_{n-1})\\
Bayes'\ rule:\ p(x|y)=\frac {p(x,y)}{p(y)}=\frac {p(y|x)p(x)}{p(y)}\\
Conditional\ independence:\ if\ x\perp y | z,\ then\ p(x|y,z)=p(x|z)\]

<p><strong>[math. Conditional independenceì˜ ì„¸ê°€ì§€ ë£°]</strong></p>

<ul>
  <li>conditional independence: zê°€ ì£¼ì›Œ ì¡Œì„ë•Œ, x,yê°€ independenceë¼ê³  ê°€ì •í•˜ë©´ ì„±ë¦½, ì´ë¥¼ chain ruleê³¼ ì„ìœ¼ë©´ ì¢‹ì€ íƒ€í˜‘ì ì„ ê°€ì§„ ëª¨ë¸ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

\[Chain\ Rule:\ p(x_1,\dots,x_n)=p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\dots p(x_n|x_1,\dots,x_{n-1})\\\\
if\ assume\ \ X_{i+1}\perp X_1,\dots,X_{i-1}|X_i (Markov\ assumption)\\
become\ \ \ p(x_1,\dots,x_n) =p(x_1)p(x_2|x_1)p(x_3|x_2)\dots p(x_n|x_{n-1})\]

<p><strong>[math. chain ruleê³¼ conditional indepenceì˜ ì¡°í•©]</strong></p>

<ul>
  <li>Markov assumptionì„ ì´ìš©í•˜ë©´ parameter ìˆ˜ê°€ ê¸°ì¡´ì˜ 2^n^-1 ì—ì„œ 2n -1ë¡œ ë³€í•œë‹¤.</li>
  <li>ì´ëŸ¬í•œ conditional indepency ë°©ë²•ìœ¼ë¡œ ìƒì„±í•œ ëª¨ë¸ì„ Auto-regressive modelì´ë¼ê³  í•œë‹¤.</li>
</ul>

<h3 id="Auto-regressive-Model">Auto-regressive Model</h3>

<ul>
  <li>28 X 28 binary pixel ì´ë¯¸ì§€ì˜ ê²½ìš° ìš°ë¦¬ëŠ” p(x)ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ autoregressive modelë¡œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.</li>
  <li>pixelì˜ order ìˆœì„œì— ë”°ë¼ ëª¨ë¸ê³¼ ë°©ë²•ë¡ ì´ ë‹¬ë¼ì§€ê¸°ë„ í•œë‹¤.(ì•„ë˜ Pixel RNN ì°¸ì¡°)</li>
</ul>

<ol>
  <li>NADE(Neural Autoregressive Density Estimator) ëª¨ë¸</li>
</ol>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214121944653.png" alt=""></p>

<p><strong>[img. NADE ëª¨ë¸]</strong></p>

<ul>
  <li>i ë²ˆì§¸ í”½ì…€ì„ ì²«ë²ˆì§¸ ë¶€í„° i-1ë²ˆì§¸ í”½ì…€ì— dependentí•˜ê²Œ ìƒì„±(dense layer)
    <ul>
      <li>
        <table>
          <tbody>
            <tr>
              <td>ì¦‰, $p(x_i</td>
              <td>x_{1:i-1}) = \sigma(\alpha_ih_i+b_i)\ where\ h_i=\sigma(W_{&lt;i}x_{1:i-1}+c)$ ì´ë‹¤.</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li>ì…ë ¥ ì°¨ì›ì´ ì ì  ë” ì»¤ì§€ê²Œ ëœë‹¤.</li>
  <li>explicit ëª¨ë¸ì´ë©° í™•ë¥ ë¶„í¬ë¥¼ êµ¬í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

\[p(x_1,\dots,x_{784})=p(x_1)p(x_2|x_1)\dots p(x_{784}|x_{1:783}) \\
where\ each\ conditional\ probability\ p(x_i|x_{1:i-1})\ is\ computed\ independently\]

<p><strong>[math. chaine ruleì„ í†µí•œ joint probability ]</strong></p>

<ul>
  <li>ì—°ì†ì ì¸ ë¶„í¬(continuous random variables)ì¼ ê²½ìš° a mixture of gaussianì„ ì‚¬ìš©í•´ í‘œí˜„ ê°€ëŠ¥</li>
</ul>

<ol>
  <li>Pixel RNN</li>
</ol>

<ul>
  <li>ì´ë¯¸ì§€ ë‚´ì˜ pixel ìƒì„±í•˜ëŠ” auto-regressive ëª¨ë¸</li>
</ul>

\[p(x)=\prod^{n^2}_{i=1}p(x_{i,R}|x_{&lt;i})p(x_{i,G}|x_{&lt;i},x_{i,R})p(x_{i,B}|x_{&lt;i},x_{i,R},X_{i,G})\]

<p><strong>[math.nXn RGB image ìƒì„±]</strong></p>

<ul>
  <li>orderingì— ë”°ë¼ Row LSTM, Diagonal BiLSTMìœ¼ë¡œ ë‚˜ëˆ ì§</li>
</ul>

<h3 id=""><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214123411474.png" alt=""></h3>

<p><strong>[img. ë¹¨ê°„ ìƒ‰ì´ ìƒì„±í•  pixel, íŒŒë€ ìƒ‰ì´ ì°¸ì¡°í•  pixelì´ë‹¤.]</strong></p>

<h3 id="Latent-Variable-Models">Latent Variable Models</h3>

<h4 id="Variational-Auto-encoder">Variational Auto-encoder</h4>

<ul>
  <li>
    <p>Variational inference(VI, ë³€ë¶„ ì¶”ë¡ )</p>

    <ul>
      <li>VIì˜ ëª©ì ì€ ë³µì¡í•œ posterior distribution(ì‚¬í›„í™•ë¥  ë¶„í¬)ì„ variational distribution(ë³€ë¶„ ë¶„í¬)ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ê²ƒì´ë‹¤.
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Posterior distribution($p_\theta(z</td>
                  <td>x)$):  ê´€ì‹¬ìˆëŠ” random variableì˜ í™•ë¥  ë¶„í¬, ì´ê²ƒì˜ ë°˜ëŒ€, $p_\theta(x</td>
                  <td>z)$ëŠ” likelihoodë¼ê³  í•œë‹¤. zëŠ” latent vectorë¥¼ ì˜ë¯¸í•œë‹¤.</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>Variational distribution($q_\theta(z</td>
                  <td>x)$): Posterior distributionì„ ì•Œê¸° ì‰½ê²Œ ê·¼ì‚¬í•˜ëŠ” ë¶„í¬.</td>
                </tr>
              </tbody>
            </table>
          </li>
        </ul>
      </li>
      <li>KL divergenceë¥¼ lossì²˜ëŸ¼ ì´ìš©í•˜ì—¬ Variational distributionê³¼ Posterior distributionì˜ ì°¨ì´ë¥¼ ì¤„ì¸ë‹¤.</li>
    </ul>

    <p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214163504048.png" alt=""></p>

    <p><strong>[img. VIì˜ ê·¸ë¦¼í™”]</strong></p>
  </li>
  <li>
    <p>í•˜ì§€ë§Œ ìš°ë¦¬ëŠ” posterior distributionì— ê·¼ì ‘í•œ variational distributionì„ êµ¬í•˜ê¸° ì´ì „ì—, posterior distribution ìì²´ë¥¼ ëª¨ë¥¸ë‹¤.</p>
  </li>
  <li>
    <p>ì´ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ ELBO(Evidence lower bound)ë¥¼ ìµœëŒ€ë¡œ í‚¤ìš°ë©´ ë°˜ëŒ€ë¡œ objective êµ¬ê°„ì€ ì¤„ì–´ë“¤ê²Œ ëœë‹¤.</p>

    <ul>
      <li>objective êµ¬ê°„ì€ KL divegenceë¥¼ í¬í•¨í•˜ë¯€ë¡œ ì‘ì•„ì§ˆìˆ˜ë¡ lossê°€ ì‘ì•„ì§€ëŠ” íš¨ê³¼ì™€ ë¹„ìŠ·í•˜ë‹¤.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214163659637.png" alt=""></p>

<p><strong>[img.ì´ ë°©ë²•ì„ Sandwitch methodë¼ê³ ë„ ë¶€ë¥¸ë‹¤.]</strong></p>

<ul>
  <li>Posterio distributionì€ ì•Œ ìˆ˜ ì—†ì§€ë§Œ, ELBOëŠ” ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214164115555.png" alt=""></p>

<p><strong>[img. ELBOê°€ ê°€ì§€ê³  ìˆëŠ” ë‘ê°œì˜ í…€]</strong></p>

<ul>
  <li>ELBOëŠ” ë‘ê°œì˜ í…€ì„ ê°€ì§€ê³  ìˆëŠ”ë°, ê°ê° Reconstruction Termê³¼ Prior Fitting Termë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.
    <ul>
      <li>Reconstruction Term : encoderì™€ latent spaceë¥¼ ê±°ì³ decoderë¡œ ëŒì•„ì˜¤ëŠ” reconstruction lossë¥¼ ì¤„ì´ëŠ” ë¶€ë¶„</li>
      <li>Prior Fitting Term : latent spaceì˜ ì ë“¤ì˜ ë¶„í¬ê°€ Prior distribution(ì‚¬ì „ ë¶„í¬)ì™€ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ì–´ ì¤Œ</li>
    </ul>
  </li>
  <li>ìœ„ì˜ ë‘ í…€ ë•Œë¬¸ì— Variational Auto-encoderëŠ” generative modelì´ ëœë‹¤.
    <ul>
      <li>ì…ë ¥ -&gt; latent space -&gt; ë¶„í¬ ì°¾ì•„ì„œ ìƒ˜í”Œë§-&gt; decoder -&gt; output image ìƒì„±</li>
      <li>ê·¸ëƒ¥ Auto-encoderì—ëŠ” ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ generative modelì´ ì•„ë‹ˆë‹¤.</li>
    </ul>
  </li>
  <li>Variational Auto-encoderëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ì ì„ ê°€ì§€ê³  ìˆë‹¤.
    <ul>
      <li>likelihoodë¥¼ ì¸¡ì •í•˜ê¸° í˜ë“¬(intractable model)</li>
      <li>prior fitting termì˜ KL divergenceì„ loss ì²˜ëŸ¼ ì‚¬ìš©í•˜ë ¤ë©´ SGD, Adam ë“±ìœ¼ë¡œ ìµœì í™”ê°€ ë˜ì–´ì•¼í•˜ë¯€ë¡œ ë¯¸ë¶„ ê°€ëŠ¥í•´ì•¼ í•¨.</li>
      <li>ë”°ë¼ì„œ ë³´í†µ isotropic Gaussianì„ loss funtionì— ë„£ì–´ì„œ ì´ìš©í•¨
        <ul>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>isotropic Gaussian: $D_{KL}(q_\phi(z</td>
                  <td>x)</td>
                  <td>&nbsp;</td>
                  <td>\mathcal N(0,I))=\frac{1}{2}\sum^D_{i=1}(\sigma^2<em>{z_i}+\mu^2</em>{z_i}-ln(\sigma^2_{z_i})-1)$</td>
                </tr>
              </tbody>
            </table>
          </li>
          <li>ëª¨ë“  output dimensionì´ independentí•œ gaussian distributionì„ ì˜ë¯¸í•¨</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h5 id="Adversarial-Auto-encoder-AAE">Adversarial Auto-encoder(AAE)</h5>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214190444468.png" alt=""></p>

<p><strong>[img. AAE êµ¬ì¡°]</strong></p>

<ul>
  <li>KL divergenceë¼ëŠ” ì•½ì ì´ìˆëŠ” prior fitting term ëŒ€ì‹ ì— GANì„ í™œìš©í•˜ì—¬ latent distribution ì‚¬ì´ì˜ ë¶„í¬ë¥¼ ë§ì¶°ì¤Œ</li>
  <li>ìƒ˜í”Œë§ ê°€ëŠ¥í•œ distribution ì´ë¼ë©´ latent prior distributionìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•˜ë‹¤.</li>
  <li>ì„±ëŠ¥ ë˜í•œ ë¹„êµì  ì¢‹ì€ ê²½ìš°ê°€ ë§ë‹¤</li>
</ul>

<h3 id="Generative-Adversarial-Network-GAN">Generative Adversarial Network(GAN)</h3>

<h4 id="GAN-ì†Œê°œ">GAN ì†Œê°œ</h4>

<ul>
  <li>GANì€ ëŒ€ëµ 2ê°€ì§€ ë‹¨ê³„ë¡œ ì´ë£¨ì–´ì ¸ ìˆëŠ”ë°, ìƒ˜í”Œì„ ìƒì„±í•˜ëŠ” ëª¨ë¸(Generator)ê³¼, ìƒ˜í”Œì„ êµ¬ë³„í•˜ëŠ” ëª¨ë¸(discriminator)ë¡œ ë˜ì–´ìˆë‹¤.</li>
  <li>ìƒˆë¡œìš´ ìƒ˜í”Œì„ ìƒì„±í•´ì„œ êµ¬ë³„ ëª¨ë¸ì— ì „ë‹¬ :arrow_right: ì‹¤ì œ ì •ë³´ì™€ ë¹„êµí•˜ì—¬ ìƒ˜í”Œì„ êµ¬ë³„í•˜ì—¬ ìƒì„± ëª¨ë¸ì— ì „ë‹¬í•˜ê³  í•™ìŠµ :arrow_right: êµ¬ë³„í•œ ê²°ê³¼ë¥¼ í•™ìŠµí•˜ì—¬ ë” ë‚˜ì€ ìƒ˜í”Œì„ ìƒì„±í•´ì„œ ì „ë‹¬ :arrow_right: ë¬´í•œ ë°˜ë³µ</li>
  <li>ë§ˆì¹˜ ë‘ ëª¨ë¸ì´ ì„œë¡œ ì‹¸ìš°ëŠ” í˜•ì‹ì˜ ëª¨ë¸ì´ë‹¤.</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214211140677.png" alt=""></p>

<p><strong>[img. VA vs GAN ë¹„êµ]</strong></p>

<ul>
  <li>VAì˜ ê²½ìš°, Xì˜ ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ ì¸ì½”ë”, latent vector(z), ë””ì½”ë”ë¥¼ í†µê³¼í•˜ëŠ” í•™ìŠµì„ ê±°ì¹œ ë’¤, generation ë‹¨ê³„ì—ì„œëŠ” p(z)(latent distribution)ì—ì„œ ìƒ˜í”Œë§í•œ zë¥¼ decoderì— í†µê³¼ì‹œí‚¨ ë’¤, ê·¸ ê²°ê³¼ê°’ì´ ìƒì„±ëœ ìƒ˜í”Œì´ë‹¤.</li>
  <li>
    <p>GANì˜ ê²½ìš°, z(latent distribution)ì„ í†µí•´ì„œ Generatorì—ì„œ Fake ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ê³ , Real ì´ë¯¸ì§€ì™€ Fake ì´ë¯¸ì§€ë¥¼ Discriminatorê°€ êµ¬ë³„,í•™ìŠµí•´ì„œ ê·¸ ê²°ê³¼ë¥¼ Generatorì—ê²Œ ë³´ë‚´ í•™ìŠµ ì‹œí‚¨ë‹¤.</p>
  </li>
  <li>ì´ë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ í‘œí˜„í•˜ë©´ ì´ì™€ ê°™ë‹¤.   (implicity ëª¨ë¸ì´ë‹¤.)
    <ul>
      <li>Discriminator ì…ì¥<br>
\(\stackrel {max}{D}\ V(D,G)=\mathbb E_{x\sim p_{data}(x)}[logD(x)] + 	\mathbb E_{z\sim p_z(z)}[log(1-D(G(z)))]\\
where\ optimal\ discriminator\ is\ D^*_G(x)=\frac{p_{data}(x)}{p_{data}(x)+p_G(x)}\)</li>
      <li>Generator ì…ì¥</li>
    </ul>

\[\stackrel {min}{G}\ V(D,G)=\mathbb E_{x\sim p_{data}(x)}[logD(x)] + \mathbb E_{z\sim p_z(z)}[log(1-D(G(z)))]\]

    <ul>
      <li>optimal discriminator(=ìµœì ì˜ discriminator  ì¼ì‹œ ê°’) ì ìš©ì‹œ</li>
    </ul>

\[V(G,D^*_G(x)) = E_{x\sim p_{data}}\left[log\frac{p_{data}(x)}{p_{data}(x)+p_G(x)}\right]+E_{x\sim p_G}\left[log\frac{p_G(x)}{p_{data}(x)+p_G(x)}\right] \\= E_{x\sim p_{data}}\left[log\frac{p_{data}(x)}{\frac{p_{data}(x)+p_G(x)}{2}}\right]+E_{x\sim p_G}\left[log\frac{p_G(x)}{\frac{p_{data}(x)+p_G(x)}{2}}\right] - log4 \\
 = D_{KL}\left[p_{data},\frac{p_{data}+p_G}{2}\right]+D_{KL}\left[P_G,\frac {p_{data}+p_G}{2}\right]-log4\]

    <ul>
      <li>ì—¬ê¸°ì„œ,</li>
    </ul>

\[D_{KL}\left[p_{data},\frac{p_{data}+p_G}{2}\right]+D_{KL}\left[P_G,\frac {p_{data}+p_G}{2}\right] = \\ 2 \times Jenson-Shannon\ Divergence\ (JSD) = 2D_{JSD}[p_{data},p_{G}]\]

    <ul>
      <li>ì´ë©°, ìµœì¢…ì ìœ¼ë¡œ</li>
    </ul>

\[V(G,D^*_G(x)) = 2D_{JSD}[p_{data},p_{G}] - log4\]

    <ul>
      <li>ì´ëŠ” ì´ë¡ ìƒ ìµœì ì˜ discrimniator ì¼ì‹œ, ìµœì†Œí™” í•´ì•¼í•  generator ê°’ì´ë‹¤.</li>
    </ul>
  </li>
</ul>

<h4 id="ì—¬ëŸ¬-GAN-ëª¨ë¸ë“¤">ì—¬ëŸ¬ GAN ëª¨ë¸ë“¤</h4>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214231701051.png" alt=""></p>

<p><strong>[img. DCGAN ëª¨ë¸]</strong></p>

<ul>
  <li>ì´ë¯¸ì§€ ìƒì„±í•˜ëŠ” GAN ëª¨ë¸</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214231738609.png" alt=""></p>

<p><strong>[img. Info-GAN]</strong></p>

<ul>
  <li>classë¥¼ ì¶”ê°€ë¡œ ì¸í’‹ìœ¼ë¡œ ë„£ì–´ì¤Œ</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214231937794.png" alt=""></p>

<p><strong>[img. ì£¼ì–´ì§„ ë¬¸ì¥ì— ë§ëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” Text2Image]</strong></p>

<ul>
  <li>DALL-Eì™€ ë¹„ìŠ·í•¨</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214232019681.png" alt=""></p>

<p><strong>[img. Puzzle-GAN]</strong></p>

<ul>
  <li>ì›ë˜ ì´ë¯¸ì§€ë¥¼ ë³µì›í•˜ëŠ” ëª¨ë¸</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214232103984.png" alt=""></p>

<p><strong>[img. CycleGAN]</strong></p>

<ul>
  <li>ì´ë¯¸ì§€ ë‚´ë¶€ì˜ ë„ë©”ì¸ì„ ë°”ê¿”ì£¼ëŠ” ëª¨ë¸</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214232150633.png" alt=""></p>

<p><strong>[img. Cycle-consistency loss]</strong></p>

<ul>
  <li>GAN êµ¬ì¡°ê°€ 2ê°œ ë“¤ì–´ìˆëŠ” í˜•ì‹</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214232229519.png" alt=""></p>

<p><strong>[img. Star-GAN]</strong></p>

<ul>
  <li>ì´ë¯¸ì§€ë¥¼ ì»¨íŠ¸ë¡¤í•  ìˆ˜ ìˆê²Œ í•´ì¤Œ</li>
</ul>

<p><img src="/assets/img/ë”¥ëŸ¬ë‹ ê¸°ë³¸/image-20210214232421048.png" alt=""></p>

<p><strong>[img. Progressive-GAN]</strong></p>

<ul>
  <li>ê³ í•´ìƒë„ì˜ ì´ë¯¸ì§€ ìƒì„±í•˜ëŠ” ëª¨ë¸</li>
</ul>
</body></html>
</div>

  </div><a class="u-url" href="/articles/AI/DEEP_LEARNING/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B8%B0%EB%B3%B8.html" hidden></a>
  <p class="u-path" hidden>_articles/AI/DEEP_LEARNING/ë”¥ëŸ¬ë‹ ê¸°ë³¸.md</p>
  <script type="module" src="/assets/scripts/utils/update_recents.js"></script>
</article>

    </div>
  </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">ğŸ§ SUBBRAIN</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="a-name">ğŸ§ SUBBRAIN</li><li><a class="u-email" href="mailto:roadvirushn@gmail.com">roadvirushn@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li>
    <a href="https://github.com/RoadVirusHN"><svg class="svg-icon">
        <use xlink:href="/assets/svg/social-icons.svg#github"></use>
      </svg>
      <span class="username">RoadVirusHN</span></a>
  </li><!---->
</ul></div>

      <div class="footer-col footer-col-3">
        <p>ì´ê²ƒì´ ë””ì§€í„¸ ë™ë¬¼ì˜ ìˆ²ì´ë‹¤!! íŒŒë©¸í¸ (This is the Digital Animal Crossing!! Bad Ending.01)</p>
      </div>
    </div>

  </div>

</footer>
</body>

<script src="/assets/scripts/bundle/common.bundle.js"></script>

</html>