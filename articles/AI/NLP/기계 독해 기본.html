<!DOCTYPE html>
<html lang="kr"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ê¸°ê³„ ë…í•´ ê¸°ë³¸ | The Digital garden of Nurgle.</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="ê¸°ê³„ ë…í•´ ê¸°ë³¸" />
<meta property="og:locale" content="kr" />
<meta name="description" content="style: number min_depth: 2 max_depth: 3 varied_style: true ê¸°ê³„ ë…í•´(MRC) ê¸°ë³¸" />
<meta property="og:description" content="style: number min_depth: 2 max_depth: 3 varied_style: true ê¸°ê³„ ë…í•´(MRC) ê¸°ë³¸" />
<link rel="canonical" href="http://localhost:4000/articles/AI/NLP/%EA%B8%B0%EA%B3%84%20%EB%8F%85%ED%95%B4%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:url" content="http://localhost:4000/articles/AI/NLP/%EA%B8%B0%EA%B3%84%20%EB%8F%85%ED%95%B4%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:site_name" content="The Digital garden of Nurgle." />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-12-14T13:41:08+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ê¸°ê³„ ë…í•´ ê¸°ë³¸" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-14T13:41:08+09:00","datePublished":"2022-12-14T13:41:08+09:00","description":"style: number min_depth: 2 max_depth: 3 varied_style: true ê¸°ê³„ ë…í•´(MRC) ê¸°ë³¸","headline":"ê¸°ê³„ ë…í•´ ê¸°ë³¸","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/articles/AI/NLP/%EA%B8%B0%EA%B3%84%20%EB%8F%85%ED%95%B4%20%EA%B8%B0%EB%B3%B8.html"},"url":"http://localhost:4000/articles/AI/NLP/%EA%B8%B0%EA%B3%84%20%EB%8F%85%ED%95%B4%20%EA%B8%B0%EB%B3%B8.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="The Digital garden of Nurgle." /></head>
<div class="scrollWrapper">
  <div class="scrollbar"></div>
  <div class="progressbar"></div>
  <div class="scrollbarButton"></div>
</div>

<link rel="stylesheet" href="/assets/css/obsidian/obs-scrollbar.css" />

<!--<div class="redirection">
  <h1 class="name">Redirection for full experience.</h1>
  <br>
  Move to <br /> <a class="to" href="#">netlify url</a><br />
  <div>after <span class="counter">10</span>secs.</div>
  press <button class="cancle">here</button> to cancle.
</div>
<div class="overlay"></div>
<script type="module" src="/assets/scripts/common/components/init_redirection.js"></script>

<link rel="stylesheet" href="/assets/css/common/redirection.css" />-->

<body><header class="site-header" role="banner">

  <div class="wrapper" style="display: flex; justify-content: space-between;"><div id="header-wrapper">
    <a class="site-title" rel="author" href="/blog">The Digital garden of Nurgle.</a>

    </div><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><script src="https://unpkg.com/lunr/lunr.js"></script>
<link rel="stylesheet" href="/assets/css/common/searchbar.css" />

<form id="search-form" method="get">
  <span id="search-wrapper">
    <span id="tag-holder" ></span>
    <input type="text" id="search-box" placeholder='Prefix "#" to add Tag.' autocomplete="off">
    <span class="inner-search" >ğŸ”</span>
  </span>
</form><a class="page-link" href="/">ABOUT ME</a><a class="page-link" href="/blog">ALL ARTICLES</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
    <link rel="stylesheet" href="/assets/css/common/drawer.css" />
<button class="drawer-button open">â–¶ï¸</button>
<div id="drawer" class="close">
  <button class="drawer-button close">
    â—€ï¸
  </button>
  <div class="drawer-content">
    <div class="my-description">
      <div class="avatar-section" style="display: flex; flex-direction: row;">

        <img src="/assets/img/common/avatar.png" alt="avatar" class="avatar">
        <div style="display: flex; flex-direction: column; margin-left: 5px;">
          <a href="/about/">
            <h3 class="name">ROADVIRUSHN</h3>
          </a>
          <div class="stack-list" style="margin: 5px 0 0 5px;">
            <a title="My github page" href="https://github.com/RoadVirusHN">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#github"></use>
  </svg>
</a>
<a title="My G-mail" href="mailto:roadvirushn@gmail.com">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#gmail"></use>
  </svg>
</a>
<a title="My Blog" href="https://luminous-bubblegum-8e9be4.netlify.app">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#blog"></use>
  </svg>
</a>
          </div>
        </div>
        <!-- <h4 class="name">(JUNSEOK YUN)</h4> -->
      </div>
      <p style="margin: 5px 0 0 0;">
        í’€ìŠ¤íƒ ì›¹ğŸŒ ê°œë°œì ì§€ë§ìƒ ğŸ§‘ğŸ½â€ğŸ’»
        <br>
        â• ì¸ê³µì§€ëŠ¥ ê´€ì‹¬ ğŸ¤–
      </p>
    </div>
      <hr>
      <div class="categories">
        <h3 style="margin: 0;"><a href="/">Categories</a></h3>
        <ul class="category-list">
  
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/COMPUTER_SCIENCE/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">COMPUTER_SCIENCE</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 5
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/DATABASE/">DATABASE</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ALGORITHM/">ALGORITHM</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 15 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/OS/">OS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 14 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/NETWORK/">NETWORK</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 8 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ETC/">ETC</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/WEB/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">WEB</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 3
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/FRONTEND/">FRONTEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/BACKEND/">BACKEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 5 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/CI,CD/">CI,CD</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 2
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <span class="category-link">ETC</span>
    </h3>
    <span style="font-size: xx-small;">
      ğŸ“„: 9 
      
    </span>
    <ul class="child-category-list">
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”— </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/AI/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">AI</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 9
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/AITOOLS/">AITOOLS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/CV/">CV</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DEEP_LEARNING/">DEEP_LEARNING</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DATA_VIS/">DATA_VIS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/GRAPH/">GRAPH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/LIGHTWEIGHT/">LIGHTWEIGHT</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/MATH/">MATH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/NLP/">NLP</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/STRUCTURED_DATA/">STRUCTURED_DATA</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
    </ul>
  </li>
  
</ul>
      </div>
      <hr>
      <div class="recent-view">
        <h3 style="margin: 0;">Recent views</h3>
        <ul style="margin: 0;">
          <li>
            <strong style="color:rgb(219, 219, 12);">1 <a id="recent-1"></a></strong>
          </li>
          <li>
            2 <a id="recent-2"></a>
          </li>
          <li>
            3 <a id="recent-3"></a>
          </li>
          <li>
            4 <a id="recent-4"></a>
          </li>
          <li>
            5 <a id="recent-5" style="overflow: hidden;"></a>
          </li>
        </ul>
      </div>
    </div>
    <hr>
  <div style="height: 7vh;"></div>
</div>
    <div class="wrapper">
      <article class="article h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="article-header">
    <h1 class="article-title a-name" itemprop="name headline">ê¸°ê³„ ë…í•´ ê¸°ë³¸</h1>
    <p class="article-meta">
      <time class="dt-published" datetime="2022-12-14T13:41:08+09:00" itemprop="datePublished">Dec 14, 2022
      </time></p>
  </header>

  <div class="article-content e-content" itemprop="articleBody">
     
  
<script>
  MathJax = {
    tex: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"],
      ],
    },
    svg: {
      fontCache: "global",  
     // scale: 1.5,
    },
    chtml: {
     // scale: 1.5,
    },
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>
 
 


<script src="/assets/scripts/bundle/obsidian.bundle.js"></script>
<link rel="stylesheet" href="/assets/css/obsidian/callout.css" />
<link rel="stylesheet" href="/assets/css/obsidian/image.css" />
<link rel="stylesheet" href="/assets/css/obsidian/link-warning.css" />
<link rel="stylesheet" href="/assets/css/obsidian/preview.css" />

<div class="content-section">
  
<ol id='markdown-toc-0'>
<li><a href='#1-MRC-Intro-amp-Python-Basics' id='markdown-toc-0-1-MRC-Intro-amp-Python-Basics'>1. MRC Intro &amp; Python Basics</a><ul><li><a href='#Introduction-to-MRC' id='markdown-toc-0-Introduction-to-MRC'>Introduction to MRC</a></li> 
<li><a href='#Unicode-amp-Tokenization' id='markdown-toc-0-Unicode-amp-Tokenization'>Unicode &amp; Tokenization</a></li> 
<li><a href='#Looking-into-the-Dataset' id='markdown-toc-0-Looking-into-the-Dataset'>Looking into the Dataset</a></li> 

</ul></li> 
<li><a href='#Extraction-based-MRC' id='markdown-toc-0-Extraction-based-MRC'>Extraction-based MRC</a><ul><li><a href='#Extraction-based-MRC' id='markdown-toc-0-Extraction-based-MRC'>Extraction-based MRC</a></li> 
<li><a href='#Pre-processing' id='markdown-toc-0-Pre-processing'>Pre-processing</a></li> 
<li><a href='#Fine-tuning' id='markdown-toc-0-Fine-tuning'>Fine-tuning</a></li> 
<li><a href='#Post-processing' id='markdown-toc-0-Post-processing'>Post-processing</a></li> 

</ul></li> 
<li><a href='#Generation-based-MRC' id='markdown-toc-0-Generation-based-MRC'>Generation-based MRC</a><ul><li><a href='#Generation-based-MRC' id='markdown-toc-0-Generation-based-MRC'>Generation-based MRC</a></li> 
<li><a href='#Pre-processing' id='markdown-toc-0-Pre-processing'>Pre-processing</a></li> 
<li><a href='#Model' id='markdown-toc-0-Model'>Model</a></li> 
<li><a href='#Post-processing' id='markdown-toc-0-Post-processing'>Post-processing</a></li> 

</ul></li> 
<li><a href='#Passage-Retrieval-Sparse-Embedding' id='markdown-toc-0-Passage-Retrieval-Sparse-Embedding'>Passage Retrieval - Sparse Embedding</a><ul><li><a href='#Introduction-to-Passage-Retrieval' id='markdown-toc-0-Introduction-to-Passage-Retrieval'>Introduction to Passage Retrieval</a></li> 
<li><a href='#Passage-Embedding-and-Sparse-Embedding' id='markdown-toc-0-Passage-Embedding-and-Sparse-Embedding'>Passage Embedding and Sparse Embedding</a></li> 
<li><a href='#TF-IDF-Term-Frequency-Inverse-Document-Frequency' id='markdown-toc-0-TF-IDF-Term-Frequency-Inverse-Document-Frequency'>TF-IDF (Term Frequency - Inverse Document Frequency)</a></li> 

</ul></li> 
<li><a href='#Passage-Retrieval-Dense-Embedding' id='markdown-toc-0-Passage-Retrieval-Dense-Embedding'>Passage Retrieval -Dense Embedding</a><ul><li><a href='#Introduction-to-Dense-Embedding' id='markdown-toc-0-Introduction-to-Dense-Embedding'>Introduction to Dense Embedding</a></li> 
<li><a href='#Training-Dense-Encoder' id='markdown-toc-0-Training-Dense-Encoder'>Training Dense Encoder</a></li> 
<li><a href='#Passage-Retrieval-with-Dense-Encoder' id='markdown-toc-0-Passage-Retrieval-with-Dense-Encoder'>Passage Retrieval with Dense Encoder</a></li> 

</ul></li> 
<li><a href='#Passage-Retrieval-Scaling-Up' id='markdown-toc-0-Passage-Retrieval-Scaling-Up'>Passage Retrieval - Scaling Up</a><ul><li><a href='#Passage-Retrieval-and-Similarity-Search' id='markdown-toc-0-Passage-Retrieval-and-Similarity-Search'>Passage Retrieval and Similarity Search</a></li> 
<li><a href='#Approximating-Similarity-Search' id='markdown-toc-0-Approximating-Similarity-Search'>Approximating Similarity Search</a></li> 
<li><a href='#Introduction-to-FAISS' id='markdown-toc-0-Introduction-to-FAISS'>Introduction to FAISS</a></li> 
<li><a href='#Scaling-up-with-FAISS' id='markdown-toc-0-Scaling-up-with-FAISS'>Scaling up with FAISS</a></li> 

</ul></li> 
<li><a href='#Linking-MRC-and-Retrieval' id='markdown-toc-0-Linking-MRC-and-Retrieval'>Linking MRC and Retrieval</a><ul><li><a href='#Introduction-to-Open-domain-Question-Answert-ODQA' id='markdown-toc-0-Introduction-to-Open-domain-Question-Answert-ODQA'>Introduction to Open-domain Question Answert (ODQA)</a></li> 
<li><a href='#Retriever-Reader-Approach' id='markdown-toc-0-Retriever-Reader-Approach'>Retriever-Reader Approach</a></li> 
<li><a href='#Issues-and-Recent-Approaches' id='markdown-toc-0-Issues-and-Recent-Approaches'>Issues and Recent Approaches</a></li> 

</ul></li> 
<li><a href='#Reducing-Training-Bias' id='markdown-toc-0-Reducing-Training-Bias'>Reducing Training Bias</a><ul><li><a href='#Definition-of-Bias' id='markdown-toc-0-Definition-of-Bias'>Definition of Bias</a></li> 
<li><a href='#Bias-in-Open-domain-Question-Answering' id='markdown-toc-0-Bias-in-Open-domain-Question-Answering'>Bias in Open-domain Question Answering</a></li> 
<li><a href='#Annotation-Bias-from-Datasets' id='markdown-toc-0-Annotation-Bias-from-Datasets'>Annotation Bias from Datasets</a></li> 

</ul></li> 
<li><a href='#Closed-book-QA-with-T5' id='markdown-toc-0-Closed-book-QA-with-T5'>Closed-book QA with T5</a><ul><li><a href='#Closed-book-Question-Answering' id='markdown-toc-0-Closed-book-Question-Answering'>Closed-book Question Answering</a></li> 
<li><a href='#Text-to-Text-Format' id='markdown-toc-0-Text-to-Text-Format'>Text-to-Text Format</a></li> 
<li><a href='#Experiment-Results-amp-Analysis' id='markdown-toc-0-Experiment-Results-amp-Analysis'>Experiment Results &amp; Analysis</a></li> 

</ul></li> 
<li><a href='#QA-with-Phrase-Retrieval' id='markdown-toc-0-QA-with-Phrase-Retrieval'>QA with Phrase Retrieval</a><ul><li><a href='#Phrase-Retrieval-in-Open-Domain-Question-Answering' id='markdown-toc-0-Phrase-Retrieval-in-Open-Domain-Question-Answering'>Phrase Retrieval in Open-Domain Question Answering</a></li> 
<li><a href='#Dense-sparse-Representation-for-Phrases' id='markdown-toc-0-Dense-sparse-Representation-for-Phrases'>Dense-sparse Representation for Phrases</a></li> 
<li><a href='#Experiment-Results-amp-Analysis' id='markdown-toc-0-Experiment-Results-amp-Analysis'>Experiment Results &amp; Analysis</a></li> 

</ul></li> 
</ol>
<h1 id='ê¸°ê³„-ë…í•´-MRC-ê¸°ë³¸'>ê¸°ê³„ ë…í•´(MRC) ê¸°ë³¸</h1>

<blockquote>
  <p>Naver AI boostcamp ê¸°ê³„ ë…í•´ ê°•ì˜ë¥¼ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.</p>
</blockquote>

<h2 id='1-MRC-Intro-amp-Python-Basics'>1. MRC Intro &amp; Python Basics</h2>

<h3 id='Introduction-to-MRC'>Introduction to MRC</h3>

<p><strong>Machine Reading Comprehension(MRC. ê¸°ê³„ë…í•´)ë€?</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426111436197.png" alt="" /></p>

<p>ì£¼ì–´ì§„ ì§€ë¬¸(Context)ë¥¼ ì´í•´í•˜ê³ , ì£¼ì–´ì§„ ì§ˆì˜ (Query/Question)ì˜ ë‹µë³€ì„ ì¶”ë¡ í•˜ëŠ” ë¬¸ì œ</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426111736186.png" alt="" /></p>

<dl>
  <dt>1) Extractive Answer Datasets</dt>
  <dd>
    <p>ì§ˆì˜ (qeustion)ì— ëŒ€í•œ ë‹µì´ í•­ìƒ ì£¼ì–´ì§„ ì§€ë¬¸ (context)ì˜ segment (or span)ìœ¼ë¡œ ì¡´ì¬</p>
  </dd>
</dl>

<p>MRC ì¢…ë¥˜ë¡œ Cloze Tests(CBT), Span Extraction(SQuAD, KorQuAD, NewsQA) ë“±ì´ ì¡´ì¬</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426112238977.png" alt="" /></p>

<dl>
  <dt>2) Descriptive/Narrative Answer Datasets</dt>
  <dd>
    <p>ë‹µì´ ì§€ë¬¸ ë‚´ì—ì„œ ì¶”ì¶œí•œ spanì´ ì•„ë‹ˆë¼, ì§ˆì˜ë¥¼ ë³´ê³  ìƒì„±ëœ sentence (or free-form)ì˜ í˜•íƒœ</p>
  </dd>
</dl>

<p>MRC ì¢…ë¥˜ë¡œ MS MARCO, Narrative QA ë“±ì´ ì¡´ì¬</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426112702926.png" alt="" /></p>

<dl>
  <dt>3) Multiple-choice Datasets</dt>
  <dd>
    <p>ì§ˆì˜ì— ëŒ€í•œ ë‹µì„ ì—¬ëŸ¬ ê°œì˜ answer candidates ì¤‘ í•˜ë‚˜ë¡œ ê³ ë¥´ëŠ” í˜•íƒœ</p>
  </dd>
</dl>

<p>MRC ì¢…ë¥˜ë¡œ MCTest, RACE, ARC, ë“±ì´ ì¡´ì¬</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426144735600.png" alt="" /></p>

<p><strong>MRCì˜ í•´ê²°í•´ì•¼í•  ì </strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426151837948.png" alt="" /></p>

<ol>
  <li>
    <p>ë‹¨ì–´ë“¤ì˜ êµ¬ì„±ì´ ìœ ì‚¬í•˜ì§€ëŠ” ì•Šì§€ë§Œ ë™ì¼í•œ ì˜ë¯¸ì˜ ë¬¸ì¥ì„ ì´í•´ (paraphrasing)</p>
  </li>
  <li>ëŒ€ëª…ì‚¬ê°€ ì§€ì¹­í•˜ê³  ìˆëŠ” ê²ƒì´ ë¬´ì—‡ì¸ê°€?(Coreference Resolution)</li>
  <li>
    <p>ë‹µë³€ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°ëŠ”?</p>
  </li>
  <li>ì—¬ëŸ¬ ë¬¸ì„œì—ì„œ supporting factë¥¼ ì°¾ì•„ì•¼ ë‹µì„ ì•Œ ìˆ˜ ìˆëŠ” ê²½ìš°(Multi-hop reasoning)</li>
</ol>

<p><strong>MRCì˜ í‰ê°€ ë°©ë²•</strong></p>

<p>1)  Exact Match / F1 Score : For extractive answer and multiple-choice answer datasets</p>

<ul>
  <li>Exact Match (EM) or Accuracy : ì˜ˆì¸¡í•œ ë‹µê³¼ Ground-truthê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ìƒ˜í”Œì˜ ë¹„ìœ¨, (Number of correct samples) / (Number of whole samples)</li>
  <li>F1 Score : ì˜ˆì¸¡í•œ ë‹µê³¼ ground-truth ì‚¬ì´ì˜ token overlapì„ F1ìœ¼ë¡œ ê³„ì‚°
    <ul>
      <li>F1 = $\frac{2\times Precision \times Recall}{Precision+Recall}$, $Precision=\frac{num(same\ token)}{num(pred\ tokens)}$, $Recall=\frac{num(same\ token)}{num(ground_tokens)}$</li>
    </ul>
  </li>
</ul>

<p>ì˜ˆë¥¼ ë“¤ì–´, ë‹µì´ 5 days, ì˜ˆì¸¡ì´ for 5days ì´ë©´, EMì€ 0ì´ì§€ë§Œ F1: 0.8ì´ë‹¤.</p>

<p>2) ROUGE-L / BLEU : For descriptive answer datasets, Ground-truthì™€ ì˜ˆì¸¡í•œ ë‹µ ì‚¬ì´ì˜ overlapì„ ê³„ì‚°</p>

<ul>
  <li>ROUGE-L Score : ì˜ˆì¸¡í•œ ê°’ê³¼ ground-truth ì‚¬ì´ì˜ overlap recall (ROUGE-L =&gt; LCS (Longest common subsequence) ê¸°ë°˜)</li>
  <li>BLEU (Bilingual Evaluation Understudy) : ì˜ˆì¸¡í•œ ë‹µê³¼ ground-truth ì‚¬ì´ì˜ Precision (BLEU-n =&gt; uniform n-gram weight)</li>
</ul>

<h3 id='Unicode-amp-Tokenization'>Unicode &amp; Tokenization</h3>

<p>Unicodeë€, ì „ ì„¸ê³„ì˜ ëª¨ë“  ë¬¸ìë¥¼ ì¼ê´€ë˜ê²Œ í‘œí˜„í•˜ê³  ë‹¤ë£° ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì§„ ë¬¸ìì…‹ìœ¼ë¡œ, ê° ë¬¸ìë§ˆë‹¤ ìˆ«ì í•˜ë‚˜ì— ë§¤í•‘ë¨.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426141501946.png" alt="" /></p>

<p>ì¸ì½”ë”©ì´ë€, ë¬¸ìë¥¼ ì»´í“¨í„°ì—ì„œ ì €ì¥ ë° ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ì´ì§„ìˆ˜ë¡œ ë°”ê¾¸ëŠ” ê²ƒ</p>

<p>UTF-8(Unicode Transformation Format)ë€, í˜„ì¬ ê°€ì¥ ë§ì´ ì“°ëŠ” ì¸ì½”ë”© ë°©ì‹, ë¬¸ì íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ê¸¸ì´ì˜ ë°”ì´íŠ¸ë¥¼ í• ë‹¹í•œë‹¤.</p>

<p>1 byte: Standard ASCII</p>

<p>2 bytes: Arabic, Hebrew, most European scripts</p>

<p>3 bytes: BMP(Basic Multilngual Plane) - ëŒ€ë¶€ë¶„ì˜ í˜„ëŒ€ ê¸€ì (í•œê¸€ í¬í•¨)</p>

<p>4 bytes: ALL Unicode characters - ì´ëª¨ì§€ ë“±</p>

<p>í•œêµ­ì–´ì˜ ê²½ìš°, ëª¨ë“  í•œê¸€ ê²½ìš°ì˜ ìˆ˜ë¥¼ ë”°ì§„ ì™„ì„±ê³¼, ì¡°í•©í•˜ì—¬ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆëŠ” ì¡°í•©í˜•ìœ¼ë¡œ ë‚˜ë‰˜ì–´ ë¶„í¬ë˜ì–´ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426154514362.png" alt="" /></p>

<p>í† í¬ ë‚˜ì´ì§•ì€ í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒìœ¼ë¡œ, ë‹¨ì–´, í˜•íƒœì†Œ, subword ë“± ì—¬ëŸ¬ ê¸°ì¤€ì´ ì¡´ì¬í•œë‹¤.</p>

<p>Subword í† í¬ë‚˜ì´ì§•ì€ ìì£¼ ì“°ì´ëŠ” ê¸€ì ì¡°í•©ì€ í•œ ë‹¨ìœ„ë¡œ ì·¨ê¸‰í•˜ê³ , ìì£¼ ì“°ì´ì§€ ì•ŠëŠ” ì¡°í•©ì€ subwordë¡œ ìª¼ê° ë‹¤.</p>

<ul>
  <li>##ì€ ë””ì½”ë”© (í† í¬ë‚˜ì´ì§•ì˜ ë°˜ëŒ€ ê³¼ì •)ì„ í•  ë•Œ í•´ë‹¹ í† í°ì„ ì• í† í°ì— ë„ì–´ì“°ê¸° ì—†ì´ ë¶™ì¸ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸</li>
</ul>

<p>BPE(Byte-Pair Encoding)ì€ ë°ì´í„° ì••ì¶•ìš©ìœ¼ë¡œ ì œì•ˆëœ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ, NLPì—ì„œ í† í¬ë‚˜ì´ì§•ìš©ìœ¼ë¡œ í™œë°œí•˜ê²Œ ì‚¬ìš©ë˜ê³  ìˆë‹¤.</p>

<ul>
  <li>ì‚¬ëŒì´ ì§ì ‘ ì§  í† í¬ë‚˜ì´ì§•ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì€ ê²½ìš°ê°€ ë§ìŒ</li>
</ul>

<ol>
  <li>ê°€ì¥ ìì£¼ ë‚˜ì˜¤ëŠ” ê¸€ì ë‹¨ìœ„ Bigram (or Byte pair)ë¥¼ ë‹¤ë¥¸ ê¸€ìë¡œ ì¹˜í™˜í•œë‹¤.</li>
  <li>ì¹˜í™˜ëœ ê¸€ìë¥¼ ì €ì¥í•´ë‘”ë‹¤, 1ë¡œ ë‹¤ì‹œ ë°˜ë³µ</li>
</ol>

<p>ex) aaabdaaabac -&gt; Z=aa, ZabdZabac -&gt; Y=ab, Z=aa, ZYdZYac -&gt; X=ZY, XdXac</p>

<h3 id='Looking-into-the-Dataset'>Looking into the Dataset</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426155330638.png" alt="" /></p>

<p>KorQuADë€, LG CNSê°€ AI ì–¸ì–´ì§€ëŠ¥ ì—°êµ¬ë¥¼ ìœ„í•´ ê³µê°œí•œ ì§ˆì˜ì‘ë‹µ/ê¸°ê³„ë…í•´ í•œêµ­ì–´ ë°ì´í„°ì…‹</p>

<ul>
  <li>ì¸ê³µì§€ëŠ¥ì´ í•œêµ­ì–´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í•˜ë„ë¡ í•„ìš”í•œ í•™ìŠµ ë°ì´í„°ì…‹</li>
  <li>ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œ + í¬ë¼ìš°ë“œ ì†Œì‹±ì„ í†µí•´ ì œì‘í•œ ì§ˆì˜ì‘ë‹µ ìŒìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ</li>
  <li>ëˆ„êµ¬ë‚˜ ë°ì´í„°ë¥¼ ë‚´ë ¤ë°›ê³ , í•™ìŠµí•œ ëª¨ë¸ì„ ì œì¶œí•˜ê³  ê³µê°œëœ ë¦¬ë”ë³´ë“œì— í‰ê°€ ë°›ì„ ìˆ˜ ìˆìŒ</li>
  <li>2.0ì€ ë³´ë‹¤ ê¸´ ë¶„ëŸ‰ì˜ ë¬¸ì„œ, ë³µì¡í•œ í‘œì™€ ë¦¬ìŠ¤íŠ¸ ë“±ì„ í¬í•¨í•˜ëŠ” HTML í˜•íƒœë¡œ í‘œí˜„</li>
</ul>

<p>Titleê³¼ Context, Question-Answer Pairsë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426162043978.png" alt="" /></p>

<p>HuggingFace datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ â€˜squad_kor_v1â€™, â€˜squad_kor_v2â€™ë¡œ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŒ</p>

<ul>
  <li>ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— í˜¸í™˜ë¨, memory-mapped, cached ë“±ì˜ ë©”ëª¨ë¦¬ ê³µê°„ ë¶€ì¡±, ì „ì²˜ë¦¬ ê³¼ì • ë“±ì„ í”¼í•  ìˆ˜ ìˆìŒ</li>
  <li>ê¸°ë³¸ì ì¸ ë°ì´í„°ì…‹ í•¨ìˆ˜ êµ¬í˜„ë˜ì–´ ìˆìŒ.</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426155603301.png" alt="" /></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210426155624334.png" alt="" /></p>

<h2 id='Extraction-based-MRC'>Extraction-based MRC</h2>

<h3 id='Extraction-based-MRC'>Extraction-based MRC</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427094642197.png" alt="" /></p>

<p>ì§ˆë¬¸(question)ì˜ ë‹µë³€(answer)ì´ í•­ìƒ ì£¼ì–´ì§„ ì§€ë¬¸(context)ë‚´ì— spanìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ë¬¸ì œ</p>

<p>MRC ë°ì´í„° ì…‹ìœ¼ë¡œ SQuAD, KorQuAD, NewsQA, Natural Questions ë“±ì´ ì¡´ì¬í•œë‹¤.</p>

<ul>
  <li>Hugging Face Datasetì—ì„œ êµ¬í•˜ë©´ ì‰½ë‹¤.</li>
</ul>

<p>Textë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë‹µì˜ ì‹œì‘ì ê³¼ ëì ì„ ì°¾ëŠ” ë¬¸ì œê°€ ëœë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427095523808.png" alt="" /></p>

<p>ë¶„ë¥˜(Classification) ë¬¸ì œì™€ ë¹„ìŠ·í•˜ë©°, ì£¼ë¡œ ì´ì „ì— ë°°ì› ë˜ F1 scoreë‚˜ EMì„ ì§€í‘œë¡œ ì‚¼ëŠ”ë‹¤.</p>

<ul>
  <li>ë‹µì´ ì—¬ëŸ¬ê°œê°€ ë  ìˆ˜ ìˆì„ ë•ŒëŠ” ë³´í†µ ê°€ì¥ ë†’ì€ ê²ƒì„ ì¸ì •í•´ì¤€ë‹¤.</li>
</ul>

<h3 id='Pre-processing'>Pre-processing</h3>

<p>ë‹¤ìŒê³¼ ê°™ì€ ì˜ˆì‹œì˜ dataë¥¼ ì „ì²˜ë¦¬í•œë‹¤ê³  ìƒê°í•˜ì.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427134801860.png" alt="" /></p>

<p><strong>Tokenization ë‹¨ê³„</strong></p>

<p>í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(Token)ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë‹¨ê³„</p>

<p>ë„ì–´ì“°ê¸°, í˜•íƒœì†Œ, subword ë“± ì—¬ëŸ¬ ë‹¨ìœ„ í† í° ê¸°ì¤€ì´ ì‚¬ìš©ë˜ì§€ë§Œ ìµœê·¼ Out of Vcabulary(OOV) ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì •ë³´í•™ì ìœ¼ë¡œ ì´ì ì„ ê°€ì§„ Byte Pair Encoding(BPE)ì„ ì£¼ë¡œ ì‚¬ìš©í•¨</p>

<p>BPE ë°©ë²•ë¡ ì—ëŠ” WordPiece Tokenizerê°€ ì¡´ì¬.</p>

<p>â€œë¯¸êµ­ êµ°ëŒ€ ë‚´ ë‘ë²ˆì§¸ë¡œ ë†’ì€ ì§ìœ„ëŠ” ë¬´ì—‡ì¸ê°€?â€ =&gt; [â€˜ë¯¸êµ­â€™, â€˜êµ°ëŒ€â€™, â€˜ë‚´â€™, â€˜ë‘ë²ˆì§¸â€™, â€˜##ë¡œâ€™, â€˜ë†’ì€â€™, â€˜ì§â€™, â€˜##ìœ„ëŠ”â€™, â€˜ë¬´ì—‡ì¸ê°€â€™, â€˜?â€™]</p>

<p>Tokenizingê³¼ Speicial Tokenì„ ì´ìš©í•´ Tokenizing í•˜ë©´ ê²°ê³¼ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427135043627.png" alt="" /></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427135126093.png" alt="" /></p>

<p><strong>Attention Mask</strong></p>

<p>ì…ë ¥ ì‹œí€€ìŠ¤ ì¤‘ì—ì„œ attentionì„ ì—°ì‚°í•  ë•Œ ë¬´ì‹œí•  í† í°ì„ í‘œì‹œ</p>

<p>0ì€ ë¬´ì‹œ, 1ì€ ì—°ì‚°ì— í¬í•¨ë˜ë©°, ë³´í†µ [PAD]ì™€ ê°™ì€ ì˜ë¯¸ê°€ ì—†ëŠ” íŠ¹ìˆ˜í† í°ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ì‚¬ìš©</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427135320797.png" alt="" /></p>

<p><strong>input_ids ë˜ëŠ” input_token_ids</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427162608805.png" alt="" /></p>

<p>ì…ë ¥ëœ ì§ˆë¬¸ì˜ í˜•íƒœë¥¼ ì¸ë±ìŠ¤ì˜ í˜•íƒœë¡œ ë°”ê¾¸ì–´ í•™ìŠµì„ ìš©ì´í•˜ê²Œ ë§Œë“ ë‹¤.</p>

<p><strong>Token Type IDs</strong></p>

<p>ì…ë ¥ì´ 2ê°œ ì´ìƒì˜ ì‹œí€€ìŠ¤(ì˜ˆ: ì§ˆë¬¸ &amp; ì§€ë¬¸),ì¼ë•Œ, ê°ê°ì—ê²Œ IDë¥¼ ë¶€ì—¬í•˜ì—¬ ëª¨ë¸ì´ êµ¬ë¶„í•´ì„œ í•´ì„í•˜ë„ë¡ ìœ ë„</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427135402202.png" alt="" /></p>

<p><strong>ëª¨ë¸ ì¶œë ¥ê°’</strong></p>

<p>ì •ë‹µì€ ë¬¸ì„œë‚´ ì¡´ì¬í•˜ëŠ” ì—°ì†ëœ ë‹¨ì–´í† í°(span)ì´ë¯€ë¡œ, spanì˜ ì‹œì‘ê³¼ ë ìœ„ì¹˜ë¥¼ ì•Œë©´ ì •ë‹µì„ ë§ì¶œ ìˆ˜ ìˆìŒ</p>

<p>Extraction-basedì—ì„œ ë‹µì•ˆì„ ìƒì„±í•˜ê¸° ë³´ë‹¤, ì‹œì‘ìœ„ì¹˜ì™€ ëìœ„ì¹˜ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•œ. ì¦‰ Token Classification ë¬¸ì œë¡œ ì¹˜í™˜.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427135519037.png" alt="" /></p>

<h3 id='Fine-tuning'>Fine-tuning</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427103633663.png" alt="" /></p>

<p>BERTì˜ output vectorì˜ ê° elementëŠ” í•´ë‹¹ tokenì´ ë‹µì˜ ì‹œì‘ ë˜ëŠ” ëì¼ í™•ë¥ ì„ ë‚˜ì˜¤ê²Œ ë§Œë“ ë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427103609832.png" alt="" /></p>

<h3 id='Post-processing'>Post-processing</h3>

<p><strong>ë¶ˆê°€ëŠ¥í•œ ë‹µ ì œê±°</strong></p>

<ul>
  <li>End positionì´ start positionë³´ë‹¤ ì•ì— ìˆëŠ” ê²½ìš° ì œê±° (ì˜ˆìƒ ë‹µë³€ ë¶€ë¶„ì˜ ì•ë¶€ë¶„ì´ ë’·ë¶€ë¶„ ë³´ë‹¤ ë’¤ì— ìˆì„ ê²½ìš°)</li>
  <li>
    <p>ì˜ˆì¸¡í•œ ìœ„ì¹˜ê°€ contextë¥¼ ë²—ì–´ë‚œ ê²½ìš° ì œê±°(ex) questionì´ ìˆëŠ” ê³³ì— ë‹µì´ íƒœê¹…)</p>
  </li>
  <li>ë¯¸ë¦¬ ì„¤ì •í•œ max_answer_length ë³´ë‹¤ ê¸¸ì´ê°€ ë” ê¸´ ê²½ìš°</li>
</ul>

<p><strong>ìµœì ì˜ ë‹µ ì°¾ê¸°</strong></p>

<ol>
  <li>
    <p>Start/end position predictionì—ì„œ score(logits)ê°€ ê°€ì¥ ë†’ì€ Nê°œë¥¼ ê°ê° ì°¾ëŠ”ë‹¤.</p>
  </li>
  <li>
    <p>ë¶ˆê°€ëŠ¥í•œ start/end ì¡°í•© ì œê±°</p>
  </li>
  <li>
    <p>ê°€ëŠ¥í•œ ì¡°í•©ë“¤ ì¤‘ scoreì˜ í•©ì´ í° ìˆœì„œëŒ€ë¡œ ì •ë ¬</p>
  </li>
  <li>
    <p>Scoreê°€ ê°€ì¥ í° ì¡°í•©ì„ ìµœì¢… ì˜ˆì¸¡ìœ¼ë¡œ ì„ ì •</p>
  </li>
  <li>
    <p>Top-k ê°€ í•„ìš”í•œ ê²½ìš° ì°¨ë¡€ëŒ€ë¡œ ë‚´ë³´ë‚¸ë‹¤.</p>
  </li>
</ol>

<h2 id='Generation-based-MRC'>Generation-based MRC</h2>

<h3 id='Generation-based-MRC'>Generation-based MRC</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427104025265.png" alt="" /></p>

<p>ì£¼ì–´ì§„ ì§€ë¬¸ê³¼ ì§ˆì˜(question)ì„ ë³´ê³ , ë‹µë³€ì„ ìƒì„±í•˜ëŠ” Generation ë¬¸ì œ</p>

<p>ì§€í‘œëŠ” ë™ì¼í•˜ê²Œ EMê³¼ F1ì„ ì“¸ ìˆ˜ ìˆë‹¤, ì¶”ê°€ì ìœ¼ë¡œ ulgi? blue? ê°™ì€ ë‹¤ë¥¸ ì§€í‘œë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427150536911.png" alt="" /></p>

<p>Extraction baseì™€ ë‹¬ë¦¬ seq 2seq êµ¬ì¡°ë¥¼ ì´ìš©í•˜ë©°, outputì˜ í˜•íƒœ ë˜í•œ ë‹µì˜ ìœ„ì¹˜ê°€ ì•„ë‹Œ ìƒì„±ëœ ë‹µì„ ì‚¬ìš©í•˜ê²Œ ëœë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427154709478.png" alt="" /></p>

<h3 id='Pre-processing'>Pre-processing</h3>

<p>ì˜¤íˆë ¤ Extraction base ë³´ë‹¤ ë”ìš± ì‰¬ì›Œì¡Œë‹¤.</p>

<p>ì…ë ¥ì˜ ê²½ìš°, ë™ì¼í•˜ê²Œ WordPiece Tokenizerë¥¼ í™œìš©í•˜ë©°, Special Token ì‚¬ìš©ì´ ì¡°ê¸ˆ ë‹¤ë¥´ë‹¤.</p>

<p>Extraction-based MRCì—ì„  CLS, SEP, PAD í† í°ì„ ì‚¬ìš© í–ˆì§€ë§Œ</p>

<p>Generation-based MRCì—ì„œëŠ” í† í°ì„ ìì—°ì–´ë¥¼ ì´ìš©í•œ í…ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427163156309.png" alt="" /></p>

<p>Attention maskëŠ” ì´ì „ BERTì™€ ê°™ì§€ë§Œ ìš°ë¦¬ê°€ ì‚¬ìš©í•  Generation-based MRCë¥¼ ìœ„í•œ BART ëª¨ë¸ì˜ ê²½ìš° ì…ë ¥ì— token_type_idsê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤, ì¦‰, ì—¬ëŸ¬ ì…ë ¥ sequence ê°„ì˜ êµ¬ë¶„ì´ ì—†ìŒ.</p>

<ul>
  <li>ì§ì ‘ ì œê³µí•˜ì§€ ì•Šì•„ë„ ëª¨ë¸ì´ ì¶©ë¶„íˆ êµ¬ë¶„ ê°€ëŠ¥í•˜ê³ , ì„±ëŠ¥ ì°¨ì´ê°€ ì—†ì–´ì„œ ì§€ì›Œì§.</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427221135106.png" alt="" /></p>

<h3 id='Model'>Model</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427224631617.png" alt="" /></p>

<p><strong>BART</strong></p>

<p>ê¸°ê³„ ë…í•´, ê¸°ê³„ ë²ˆì—­, ìš”ì•½, ëŒ€í™” ë“± sequence to sequence ë¬¸ì œì˜ pre-trainingì„ ìœ„í•œ denoising autoencoder (noise(mask)ë¥¼ ì—†ì• ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒ)</p>

<p>BARTì˜ ì¸ì½”ë”ëŠ” BERTì²˜ëŸ¼ bi-directionalì´ë©°, BARTì˜ ë””ì½”ë”ëŠ” GPTì²˜ëŸ¼ uni-directional (autoregressive)</p>

<ul>
  <li>ì•„ë˜ 1ì¼ ê²½ìš° ì •ë³´ê°€ ì£¼ì›Œì§„ë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427224423080.png" alt="" /></p>

<p><strong>Pre-training BART</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427231032326.png" alt="" /></p>

<p>BARTëŠ” í…ìŠ¤íŠ¸ì— ë…¸ì´ì¦ˆë¥¼ ì£¼ê³  ì›ë˜ í…ìŠ¤íŠ¸ë¥¼ ë³µêµ¬í•˜ëŠ” ë¬¸ì œë¥¼ í‘¸ëŠ” ê²ƒìœ¼ë¡œ Pre-trainingí•¨</p>

<h3 id='Post-processing'>Post-processing</h3>

<p><strong>Decoding</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427231613878.png" alt="" /></p>

<p>ë””ì½”ë”ì—ì„œ ì´ì „ ìŠ¤í…ì—ì„œ ë‚˜ì˜¨ ì¶œë ¥ì´ ë‹¤ìŒ ìŠ¤í…ì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°, ì´ë¥¼ autoregressiveë¼ê³  í•¨</p>

<p>ë§¨ ì²« ì…ë ¥ì€ ë¬¸ì¥ ì‹œì‘ì„ ëœ»í•˜ëŠ” ìŠ¤í˜ì…œ í† í°</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210427231721860.png" alt="" /></p>

<p>outputì„ ìƒì„±í•  ë•ŒëŠ” ëŒ€ë¶€ë¶„ Beam Search ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤.</p>

<h2 id='Passage-Retrieval-Sparse-Embedding'>Passage Retrieval - Sparse Embedding</h2>

<h3 id='Introduction-to-Passage-Retrieval'>Introduction to Passage Retrieval</h3>

<p><strong>Passage Retrieval</strong></p>

<p>Database ë“±ì—ì„œ ì§ˆë¬¸(query)ì— ë§ëŠ” ë¬¸ì„œ(Passage)ë¥¼ ì°¾ëŠ” ê²ƒ</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210428213559640.png" alt="" /></p>

<p>ì´ë¥¼ MRCì™€ ê²°í•©í•˜ì—¬ Open-domain Question Answering ê°™ì€ 2-stage ì§ˆë¬¸ ë‹µ ì°¾ê¸° ë“±ì´ ê°€ëŠ¥í•˜ë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210428213802514.png" alt="" /></p>

<p>Query(ì‹¤ì‹œê°„)ì™€ Passage(ë˜ëŠ” ë¬¸ì„œ, ë¯¸ë¦¬ í•´ë†“ìŒ)ë¥¼ ì„ë² ë”©í•œ ë’¤ ìœ ì‚¬ë„ë¡œ ë­í‚¹ì„ ë§¤ê¸°ê³ , ìœ ì‚¬ë„(inner product ë˜ëŠ” ê³µê°„ìƒì˜ ê±°ë¦¬)ê°€ ê°€ì¥ ë†’ì€ Passageë¥¼ ì„ íƒ</p>

<h3 id='Passage-Embedding-and-Sparse-Embedding'>Passage Embedding and Sparse Embedding</h3>

<p><strong>Passage Embedding Space</strong></p>

<p>Passage Embeddingì˜ ë²¡í„° ê³µê°„ì´ë©°, ë²¡í„°í™”ëœ Passageë¥¼ ì´ìš©í•˜ì—¬ Passage ê°„ ìœ ì‚¬ë„ ë“±ì„ ì•Œê³ ë¦¬ì¦˜ ê³„ì‚° ê°€ëŠ¥</p>

<p><strong>Sparse Embedding</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210428231630498.png" alt="" /></p>

<p>Denseí•˜ì§€ ì•Šê³  0ì´ ì•„ë‹Œ ìˆ«ìê°€ ë“œë¬¸ embedding ë°©ë²•, Bag-of-Words(BoW)ê°€ ì˜ˆì‹œì´ë‹¤.</p>

<p>ìœ„ì˜ ê²½ìš°ê°€ BoWì˜ ë°©ë²•ìœ¼ë¡œ, ë‹¨ì–´ì˜ ì¢…ë¥˜ë§Œí¼ì˜ ì°¨ì›ì„ ê°€ì§„ ë²¡í„°ì—ì„œ ë‹¨ì–´ê°€ ì¡´ì¬í•  ê²½ìš° í•´ë‹¹ ë‹¨ì–´ì˜ ì°¨ì›ì„ 1ë¡œ ë†“ì•„ ë¬¸ì„œë¥¼ í‘œí˜„í•˜ëŠ” ë°©ë²•ì´ë‹¤.</p>

<p>ë‹¨ì–´ë‚˜ ë¬¸ì„œì˜ ê¸¸ì´ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ì°¨ì›ì˜ ìˆ˜ê°€ ì—„ì²­ ì»¤ì§„ë‹¤.</p>

<ol>
  <li>BoWë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ë²• -&gt;  n-gram ë°©ë²•</li>
</ol>

<ul>
  <li>unigram(1-gram): It was the best of times =&gt; It, was, the, best, of, time</li>
  <li>bigram(2-gram): It was the best of times =&gt; It was, was the, the best, best of, of times(2ê°œì”© ì§ì§€ì–´ ë‹¨ì–´ë¡œ, ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ vocab ì‚¬ì´ì¦ˆ(ì°¨ì› ìˆ˜)ê°€ í¬ì§€ë§Œ, ë”ìš± ì •í™•í•œ Embedding ê°’ì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤. )</li>
</ul>

<ol>
  <li>Term valueë¥¼ ê²°ì •í•˜ëŠ” ë°©ë²•(ex)TF-IDF)</li>
</ol>

<ul>
  <li>Termì´ documentì— ë“±ì¥í•˜ëŠ”ì§€ (binary)</li>
  <li>Termì´ ëª‡ë²ˆ ë“±ì¥í•˜ëŠ”ì§€ (term frequency), ë“±</li>
</ul>

<p>íŠ¹ì§•ìœ¼ë¡œ,</p>

<ol>
  <li>Dimension of embedding Vector = number of terms</li>
</ol>

<ul>
  <li>ë“±ì¥í•˜ëŠ” ë‹¨ì–´ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ì°¨ì› ìˆ˜ ì¦ê°€</li>
  <li>N-Gramì˜ nì´ ì»¤ì§ˆìˆ˜ë¡ ì¦ê°€</li>
</ul>

<ol>
  <li>Term overlapì„ ì •í™•í•˜ê²Œ ì¡ì•„ ë‚´ì•¼ í•  ë•Œ ìœ ìš©(ì¦‰, ì •í™•íˆ í•´ë‹¹ ë‹¨ì–´ê°€ í•„ìš”í•˜ë‹¤ë©´ ì¡ì•„ë‚¼ ìˆ˜ ìˆìŒ).</li>
  <li>ë°˜ë©´, ì˜ë¯¸(semantic)ê°€ ë¹„ìŠ·í•˜ì§€ë§Œ ë‹¤ë¥¸ ë‹¨ì–´ì¸ ê²½ìš° ë¹„êµê°€ ë¶ˆê°€(ì¦‰, ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ëŠ” ì°¾ì„ ìˆ˜ ì—†ìŒ)</li>
</ol>

<h3 id='TF-IDF-Term-Frequency-Inverse-Document-Frequency'>TF-IDF (Term Frequency - Inverse Document Frequency)</h3>

<p>TFì™€ IDFë¥¼ ê³ ë ¤í•˜ì—¬ Embedding í•˜ëŠ” ë°©ë²•</p>

<p><strong>TF(Term Frequency)</strong></p>

<p>í•´ë‹¹ ë¬¸ì„œ ë‚´ ë‹¨ì–´ì˜ ë“±ì¥ ë¹ˆë„, ë§ì´ ë“±ì¥í•  ìˆ˜ë¡ ë†’ë‹¤.</p>

<p>ë³´í†µ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì¸¡ì •í•œë‹¤.</p>

<ol>
  <li>Raw count, ê·¸ëƒ¥ ë“±ì¥ ìˆ«ì ì„¸ê¸°, ì˜ ì•ˆì‚¬ìš©í•œë‹¤.</li>
  <li>Adjusted for doc lengh: raw count/ num words (TF), ë¹„ìœ¨ë¡œ ì¸¡ì •</li>
  <li>OTher variants: binary, log normalization, etc.</li>
</ol>

<p><strong>IDF (Inverse Document Frequency)</strong></p>

<p>ë‹¨ì–´ê°€ ì œê³µí•˜ëŠ” ì •ë³´ì˜ ì–‘, ì£¼ë¡œ ëª…ì‚¬ë‚˜ í˜•ìš©ì‚¬ê°€ í¬í•¨ë˜ë©°, ì •ë³´ë¥¼ ë§ì´ ê°€ì§€ëŠ” ë‹¨ì–´ì¼ ìˆ˜ë¡ í¬ë‹¤.</p>

<p>ë¡œê·¸(ëª¨ë“  ë‹¤íë¨¼íŠ¸ ê°¯ìˆ˜/ë“±ì¥í•œ ë‹¤íë©˜í„° ìˆ˜)ë¡œ êµ¬í•œë‹¤</p>

<p>í•œ ë¬¸ì„œì˜ ë“±ì¥ ë¹ˆë„ì¸ TFì™€ ë¬´ê´€í•˜ë‹¤.<br />
\(IDF(t) = log\frac{N}{DF(t)}\\
Document\ Frequency (DF) : Term\ tê°€\ ë“±ì¥í•œ\ documentì˜\ ê°œìˆ˜\\
N: ì´\ documentì˜\ ê°œìˆ˜\)</p>

<p><strong>Combine TF &amp; IDF</strong></p>

<p>TFì™€ IDFë¥¼ ê³±í•œ ê°’, ë†’ì„ ìˆ˜ë¡ ì •ë³´ë¥¼ ë§ì´ ë‹´ê³  ìˆëŠ” ë‹¨ì–´ì´ë‹¤.</p>

<p>TF-IDF(t, d): TF-IDF for term t in document d,<br />
\(TF(t,d)\times IDF(t)\)<br />
a, the ê°™ì€ ê´€ì‚¬ëŠ” TFê°€ ë†’ì•„ë„ IDFê°€ 0ì— ê°€ê¹Œìš°ë¯€ë¡œ ë‚®ê²Œ ëœë‹¤.</p>

<p>ê³ ìœ ëª…ì‚¬ ë“±ì€ IDFê°€ ì•„ì£¼ ì»¤ì§€ë©´ì„œ TF-IDF ê°’ì´ í¬ê²Œ ëœë‹¤.</p>

<p><strong>TF-IDFë¥¼ ì´ìš©í•´ ìœ ì‚¬ë„ êµ¬í•˜ê¸°</strong></p>

<p><strong>Lab.[MRC-2]TF-IDF ì°¸ì¡°</strong></p>

<p>ëª©í‘œ: ê³„ì‚°í•œ TF-IDFë¥¼ ê°€ì§€ê³  ì‚¬ìš©ìê°€ ë¬¼ì–´ë³¸ ì§ˆì˜ì— ëŒ€í•´ ê°€ì¥ ê´€ë ¨ìˆëŠ” ë¬¸ì„œë¥¼ ì°¾ì.</p>

<ol>
  <li>ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆì˜ë¥¼ í† í°í™”</li>
  <li>ê¸°ì¡´ì— ë‹¨ì–´ ì‚¬ì „ì— ì—†ëŠ” í† í°ë“¤ì€ ì œì™¸</li>
  <li>ì§ˆì˜ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ ìƒê°í•˜ê³ , ì´ì— ëŒ€í•œ TF-IDF ê³„ì‚°</li>
  <li>ì§ˆì˜ TF-IDF ê°’ê³¼ ê° ë¬¸ì„œë³„ TF-IDF ê°’ì„ ê³±í•˜ì—¬ ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°</li>
</ol>

\[Score(D,Q)=\sum_{term\in Q}TFIDF(term,Q)*TFIDF(term,D)\]

<ol>
  <li>ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§€ëŠ” ë¬¸ì„œ ì„ íƒ</li>
</ol>

<p><strong>BM25</strong></p>

<p>TF-IDFì˜ ê°œë…ì„ ë°”íƒ•ìœ¼ë¡œ, ë¬¸ì„œì˜ ê¸¸ì´ê¹Œì§€ ê³ ë ¤í•˜ì—¬ ì ìˆ˜ë¥¼ ë§¤ê¹€</p>

<ul>
  <li>TF ê°’ì— í•œê³„ë¥¼ ì§€ì •í•´ë‘ì–´ ì¼ì •í•œ ë²”ìœ„ë¥¼ ìœ ì§€í•˜ë„ë¡ í•¨</li>
  <li>í‰ê· ì ì¸ ë¬¸ì„ì˜ ê¸¸ì´ë³´ë‹¤ ë” ì‘ì€ ë¬¸ì„œì—ì„œ ë‹¨ì–´ê°€ ë§¤ì¹­ëœ ê²½ìš° ê·¸ ë¬¸ì„œì— ëŒ€í•´ ê°€ì¤‘ì¹˜ë¥¼ ë¶€ì—¬</li>
  <li>ì‹¤ì œ ê²€ìƒ‰ ì—”ì§„, ì¶”ì²œ ì‹œìŠ¤í…œ ë“±ì—ì„œ ì•„ì§ê¹Œì§€ë„ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜</li>
</ul>

\[Score(D,Q)=\sum_{term\in Q}IDF\cdot\frac{TFIDF(term,D)\cdot(k_1+1)}{TFIDF(term,D)+k_1\cdot(1-b+b\cdot\frac{|D|}{avgdl})}\]

<h2 id='Passage-Retrieval-Dense-Embedding'>Passage Retrieval -Dense Embedding</h2>

<h3 id='Introduction-to-Dense-Embedding'>Introduction to Dense Embedding</h3>

<p><strong>Passage Embedding</strong>ì€ êµ¬ì ˆ(Passage)ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì„ ì˜ë¯¸í•˜ë©°,</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429100257478.png" alt="" /></p>

<p><strong>Sparse Embedding</strong>ì€ TF-IDFê°€ ëŒ€í‘œ ì˜ˆì‹œë¡œ, ë‹¨ì ìœ¼ë¡œ ì°¨ì›ì˜ ìˆ˜ê°€ í¬ê³  ë¹„ìŠ·í•œ ë‹¨ì–´ì˜ ìœ ì‚¬ì„±ì„ ê³ ë ¤í•˜ì§€ ëª»í•œë‹¤.</p>

<p>(Compressed formatìœ¼ë¡œ ì°¨ì›ì˜ ìˆ˜ ë¬¸ì œëŠ” í•´ê²°ê°€ëŠ¥ í•˜ë‹¤)<img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429100507584.png" alt="" /></p>

<p><strong>Dense Embedding</strong></p>

<p>Sparse Embeddingì˜ ë‹¨ì ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ë‚˜íƒ€ë‚¨</p>

<ul>
  <li>ë” ì‘ì€ ì°¨ì›ì˜ ê³ ë°€ë„ ë²¡í„° (length = 50 - 1000)</li>
  <li>ê° ì°¨ì›ì´ íŠ¹ì • termì— ëŒ€ì‘ë˜ì§€ ì•ŠìŒ</li>
  <li>ëŒ€ë¶€ë¶„ì˜ ìš”ì†Œê°€ non-zero</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429101541847.png" alt="" /></p>

<p>DenseëŠ” Sparseì— ë¹„í•´ vectorë“¤ì˜ ìœ ì‚¬ì„±ì„ íŒŒì•…í•˜ê¸° ì‰½ê³ , ì•Œê³ ë¦¬ì¦˜ ë˜í•œ ë”ìš± ë§ì€ ê²ƒì„ ì ìš©í•  ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210430065838321.png" alt="" /></p>

<p>ê°ìì˜ ì¥ì ì„ ê³ ë ¤í•´ì„œ ë‘˜ë‹¤ ë™ì‹œì— ì‚¬ìš©í•˜ê±°ë‚˜ ì„œë¡œ ë³´ì™„í•œë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210430070002242.png" alt="" /></p>

<p>ì£¼ë¡œ ë‘ê°€ì§€ ëª¨ë¸ì„ ì´ìš©í•´ Contextì˜ ë²¡í„°ë¥¼ êµ¬í•˜ëŠ” ëª¨ë¸ê³¼ questionì˜ ë²¡í„°ë¥¼ êµ¬í•˜ëŠ” ëª¨ë¸ì„ ì´ìš©í•´ dot product, space similarity ë“±ì„ ê³„ì‚°í•˜ì—¬ ìœ ì‚¬ë„ë¥¼ ë¹„êµí•´ ê²°ì •í•œë‹¤.</p>

<h3 id='Training-Dense-Encoder'>Training Dense Encoder</h3>

<p>contextë¥¼ Dense Embeddingìœ¼ë¡œ Encoding í•˜ëŠ” Dense Encoderì˜ ëª¨ë¸ë¡œ, BERT, ELMoì™€ ê°™ì€ Pre-trained language model(PLM)ì´ ìì£¼ ì‚¬ìš©í•˜ë©°, [CLS] tokenì´ encodingëœ outputì´ í•´ë‹¹ contextì˜ ìµœì¢… Embedding outputìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429103127071.png" alt="" /></p>

<p>ì—°ê´€ëœ questionê³¼ passage dense embedding(ë˜ëŠ” inner product) ê°„ì˜ ê±°ë¦¬ì˜ ì¢ìŒ, ì¦‰, similarityë¥¼ ë†’ì´ëŠ” ê²ƒì´ ëª©í‘œì´ë©°, ì´ë¥¼ í†µí•´ question/passageì˜ ì—°ê´€ì„±ì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429105211929.png" alt="" /></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429110249854.png" alt="" /></p>

<p>1) ì—°ê´€ëœ questionê³¼ passage ê°„ì˜ dense embedding ê±°ë¦¬ë¥¼ ì¢íˆëŠ” ê²ƒ (higher similarity) -&gt; positive</p>

<p>2) ì—°ê´€ ë˜ì§€ ì•Šì€ questionê³¼ passage ê°„ì˜ embedding ê±°ë¦¬ëŠ” ë©€ì–´ì•¼ í•¨ -&gt; Negative</p>

<ul>
  <li>ì´ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ Negative samplingì„ í†µí•´ í•™ìŠµí•œë‹¤
    <ul>
      <li>Corpus ë‚´ì—ì„œ ëœë¤í•˜ê²Œ ë½‘ê±°ë‚˜, ë†’ì€ TF-IDF ìŠ¤ì½”ì–´ë¥¼ ê°€ì§€ì§€ë§Œ ë‹µì„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ìƒ˜í”Œ ê°™ì€ í—·ê°ˆë¦¬ëŠ” ìƒ˜í”Œì„ ë½‘ëŠ”ë‹¤.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429111147957.png" alt="" /></p>

<p>ì´ë•Œ lossë¡œ Positive passageì— ëŒ€í•´ì„œ negative log likelihood (NLL) lossë¥¼ ì‚¬ìš©í•œë‹¤.</p>

<p>ë¶„ëª¨ì—ëŠ” ëª¨ë“  passageì˜ similarity score, ë¶„ìì—ëŠ” positive sampleì˜ scoreë¥¼ ë†“ì€ ë’¤, negative logë¥¼ ì·¨í•˜ì—¬ ê³„ì‚°ëœë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429111702628.png" alt="" /></p>

<p>ë˜í•œ Top-k retrieval accuracy(retrieveëœ passage ì¤‘ì— ë‹µì„ í¬í•¨í•˜ëŠ” passageì˜ ë¹„ìœ¨)ì„ ê³„ì‚°í•´ì„œ ì„±ëŠ¥ì„ ì¸¡ì •í•œë‹¤.</p>

<h3 id='Passage-Retrieval-with-Dense-Encoder'>Passage Retrieval with Dense Encoder</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429112721737.png" alt="" /></p>

<ol>
  <li>From dense encoding to retrieval</li>
</ol>

<p>Inference: Passage(ë¯¸ë¦¬ embeddingë˜ìˆìŒ)ì™€ queryë¥¼ ê°ê° embeddingí•œ í›„, queryë¡œë¶€í„° ê°€ê¹Œìš´ ìˆœì„œëŒ€ë¡œ passageì˜ ìˆœìœ„ ë§¤ê¹€</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429112748573.png" alt="" /></p>

<ol>
  <li>From retrieval to open-domain question answering</li>
</ol>

<p>Retrieverë¥¼ í†µí•´ ì°¾ì•„ë‚¸ Passageì„ í™œìš©, MRC ëª¨ë¸ë¡œ ë‹µì„ ì°¾ìŒ.</p>

<p>ì´ëŸ¬í•œ ê³¼ì •ì„ í•™ìŠµ ë°©ë²• ê°œì„ (DPR ë“±)ì´ë‚˜ ì¸ì½”ë” ëª¨ë¸ ê°œì„  (ë” ì¢‹ì€ ëª¨ë¸), ë°ì´í„° ê°œì„  ë“±ìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚¬ ìˆ˜ ìˆë‹¤.</p>

<h2 id='Passage-Retrieval-Scaling-Up'>Passage Retrieval - Scaling Up</h2>

<h3 id='Passage-Retrieval-and-Similarity-Search'>Passage Retrieval and Similarity Search</h3>

<p><strong>MIPS(Maximum Inner Product Search)</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429191418027.png" alt="" /></p>

<p>ì£¼ì–´ì§„ ì§ˆë¬¸(query) ë²¡í„° qì— ëŒ€í•´ Passage ë²¡í„° vë“¤ ì¤‘ ê°€ì¥ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë²¡í„°ë¥¼ ì°¾ì•„ì•¼í•¨</p>

<p>ì´ë•Œ í˜„ì—…ì—ì„œëŠ” ì£¼ë¡œ inner productë¡œ êµ¬í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ.(ì¢€ë” íš¨ìœ¨ì ì„)<br />
\(argmax_{vi\in V}q^T_{v_i}\\
argmax:ê²€ìƒ‰(search),\ ì¸ë±ì‹±ëœ\ ë²¡í„°ë“¤\ ì¤‘\ ì§ˆë¬¸\ ë²¡í„°ì™€\\ ê°€ì¥\ ë‚´ì ê°’ì´\ í°\ ìƒìœ„\ kê°œì˜\ ë²¡í„°ë¥¼\ ì°¾ëŠ”\ ê³¼ì • \\
q^T_{v_i}:ì¸ë±ì‹±(indexing),\ ë°©ëŒ€í•œ\ ì–‘ì˜\ passage\ ë²¡í„°ë“¤ì„\ ì €ì¥í•˜ëŠ”\ ë°©ë²•\)<br />
ì´ì „ì— ë°°ìš´ ë°©ë²•ì€ brutre-force(exhaustive) search ë°©ë²•ìœ¼ë¡œ, ì €ì¥í•´ë‘” ëª¨ë“  Sparse/Dense ì„ë² ë”©ì— ëŒ€í•´ ì¼ì¼ì´ ë‚´ì ê°’ì„ ê³„ì‚°í•˜ì—¬ ê°€ì¥ ê°’ì´ í° Passageë¥¼ ì¶”ì¶œ</p>

<p>ë¬¸ì œëŠ” ê²€ìƒ‰í•´ì•¼í•  ë°ì´í„°ê°€ ë°©ëŒ€(ìœ„í‚¤í”¼ë””ì•„ë§Œ 500ë§Œê°œ, ê·¸ì´ìƒ ìˆ˜ì‹­ì–µ, ì¡°ë‹¨ìœ„ ê¹Œì§€ ì»¤ì§ˆ ìˆ˜ ìˆìŒ)</p>

<p>ì¦‰, ë”ì´ìƒ ëª¨ë“  ë¬¸ì„œ ì„ë² ë”©ì„ ì¼ì¼íˆ ë³´ë©´ì„œ ê²€ìƒ‰í•  ìˆ˜ ì—†ìŒ</p>

<p><strong>Tradeoffs of similarity search</strong></p>

<p>ì¦‰, ëª¨ë‘ ì™„ë²½í•˜ê²Œ í•  ìˆœ ì—†ê³  ë‹¤ìŒ 3ê°€ì§€ ì¤‘ì— Trade-off í•´ì•¼í•œë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429191821405.png" alt="" /></p>

<p>1) Search Speed : ì¿¼ë¦¬ ë‹¹ ìœ ì‚¬í•œ ë²¡í„°ë¥¼ kê°œ ì°¾ëŠ”ë° ê±¸ë¦¬ëŠ” ì‹œê°„, Pruningìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>ì¼ë°˜ì ìœ¼ë¡œ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•˜ë©´ ì •í™•ë„ê°€ ë–¨ì–´ì§„ë‹¤.</li>
</ul>

<p>2) Memory Usage : ë²¡í„°ë¥¼ ì €ì¥í•  ê³µê°„, Compressionìœ¼ë¡œ ê°œì„ í•  ìˆ˜ ìˆë‹¤.</p>

<p>3) Accuracy : ê²€ìƒ‰ê²°ê³¼ì˜ ì§ˆ, Exhaustive searchë¡œ ê°œì„ í•  ìˆ˜ ìˆë‹¤.</p>

<p>ë˜í•œ, ì½”í¼ìŠ¤(corpus)ì˜ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ íƒìƒ‰ ê³µê°„ì´ ì»¤ì§€ê³  ê²€ìƒ‰ì´ ì–´ë ¤ì›Œì§€ë©°, Memory space ë˜í•œ ë§ì´ ìš”êµ¬ ë¨</p>

<ul>
  <li>ê·¸ë˜ë„ Dense Embeddingì˜ ê²½ìš° Sparse Embedding ë³´ë‹¨ ë‚«ë‹¤.</li>
</ul>

<h3 id='Approximating-Similarity-Search'>Approximating Similarity Search</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429213855108.png" alt="" /></p>

<p><strong>Compression - Scalr Quantization(SQ)</strong></p>

<p>Vectorë¥¼ ì••ì¶•í•˜ì—¬, í•˜ë‚˜ì˜ Vectorê°€ ì ì€ ìš©ëŸ‰ì„ ì°¨ì§€í•˜ë„ë¡ í•¨,</p>

<p>ì••ì¶•ëŸ‰ì´ í´ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ ì¤„ê³  ì •ë³´ ì†ì‹¤ì„ ëŠ˜ì–´ë‚œë‹¤.</p>

<p>ìƒë‹¨ ê·¸ë¦¼ì˜ 4byteì˜ float pointë¥¼ 1-byteì˜ unsigned integerë¡œ ì••ì¶•í•˜ëŠ” Scalar quantizationì´ ì˜ˆì‹œ</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429214225135.png" alt="" /></p>

<p><strong>Pruning - Inverted File (IVF)</strong></p>

<p>Search spaceë¥¼ ì¤„ì—¬ search ì†ë„ ê°œì„ (datasetì˜ subsetë§Œ ë°©ë¬¸)</p>

<p>=&gt; Clustering + Inverted fileì„ í™œìš©í•œ search</p>

<p>1) Clustering: ì „ì²´ vector spaceë¥¼ k ê°œì˜ clusterë¡œ ë‚˜ëˆ” (ex. k-means clustering)</p>

<p>2) Inverted file (IVF) : Vectorì˜ index = inverted list structure</p>

<p>=&gt; (ê° clusterì˜ centroid id)ì™€ (í•´ë‹¹ clusterì˜ vectorë“¤)ì´ ì—°ê²°ë˜ì–´ìˆëŠ” í˜•íƒœ</p>

<p>ì¦‰,</p>

<ol>
  <li>ì£¼ì–´ì§„ query vectorì— ëŒ€í•´ ê·¼ì ‘í•œ centroid ë²¡í„°ë¥¼ ì°¾ìŒ</li>
  <li>ì°¾ì€ clusterì˜ inverted list ë‚´ vectorë“¤ì— ëŒ€í•´ ì„œì¹˜ ìˆ˜í–‰</li>
</ol>

<h3 id='Introduction-to-FAISS'>Introduction to FAISS</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429222428177.png" alt="" /></p>

<p>FAISSë€, similarity searchì™€ dense vectorì˜ clusteringì— ì‚¬ìš©ë˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë‹¤.</p>

<p><strong>Passage Retrieval with FAISS</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429222651432.png" alt="" /></p>

<p>1) Train index and map vectors</p>

<ul>
  <li>Train phaseê³¼ add phaseë¡œ ë‚˜ë‰œë‹¤.</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210429222739709.png" alt="" /></p>

<p>2) Search based on FAISS index</p>

<h3 id='Scaling-up-with-FAISS'>Scaling up with FAISS</h3>

<p>ì‹¤ìŠµ</p>

<h2 id='Linking-MRC-and-Retrieval'>Linking MRC and Retrieval</h2>

<h3 id='Introduction-to-Open-domain-Question-Answert-ODQA'>Introduction to Open-domain Question Answert (ODQA)</h3>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501103607834.png" alt="" /></p>

<p>ODQAëŠ” ì§€ë¬¸ì´ ë”°ë¡œ ì£¼ì–´ì§€ì§€ ì•Šìœ¼ë©° ë°©ëŒ€í•œ World Knowledgeì— ê¸°ë°˜í•´ì„œ ì§ˆì˜ ì‘ë‹µ</p>

<p>Question processing + Passage retrieval + Answer processing ì´ í•©ì³ì§„ í˜•íƒœ</p>

<p>1) Question processing</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501103647390.png" alt="" /></p>

<p>Query formulation: ì§ˆë¬¸ìœ¼ë¡œë¶€í„° í‚¤ì›Œë“œë¥¼ ì„ íƒ / Answer type selection (ex. LOCATION : country)</p>

<p>2) Passage retrieval</p>

<p>ê¸°ì¡´ì˜ IR ë°©ë²•ì„ í™œìš©í•´ì„œ ì—°ê´€ëœ documentë¥¼ ë½‘ê³ , passage ë‹¨ìœ„ë¡œ ìë¥¸ í›„ ì„ ë³„ (Named entity/Passage ë‚´ question ë‹¨ì–´ì˜ ê°œìˆ˜ ë“±ê³¼ ê°™ì€ hand-crafted feature í™œìš©)</p>

<p>3) Answer processing</p>

<p>Hand-crafted featuresì™€ heuristicì„ í™œìš©í•œ classifier, ì£¼ì–´ì§„ questionê³¼ ì„ ë³„ëœ passageë“¤ ë‚´ì—ì„œ ë‹µì„ ì„ íƒ</p>

<h3 id='Retriever-Reader-Approach'>Retriever-Reader Approach</h3>

<p>Retriever-Reader ì ‘ê·¼ ë°©ì‹ì€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ìˆëŠ” ë¬¸ì„œë¥¼ ê²€ìƒ‰í•œ ë’¤, ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ì— í•´ë‹¹í•˜ëŠ” ë‹µì„ ì°¾ì•„ë‚´ëŠ” ë°©ì‹</p>

<p>ì¦‰ Retrieverì˜ ì…ë ¥ì€ ë¬¸ì„œì…‹(Document corpus)ì™€ ì§ˆë¬¸(qeury)ì´ë©° ì¶œë ¥ì€ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ(document)ì´ë‹¤.</p>

<ul>
  <li>ì´ë•Œ TF-DF, BM25ë¥¼ í™œìš©í•˜ë©´ í•™ìŠµí•˜ì§€ ì•Šê³ , Dense embeddingì¼ ê²½ìš° í•™ìŠµì´ í•„ìš”í•˜ë‹¤.</li>
</ul>

<p>Readerì˜ ì…ë ¥ì€ Retrievedëœ ë¬¸ì„œ(document)ê³¼ ì§ˆë¬¸(query)ì´ë©°, ì¶œë ¥ì€ ë‹µë³€(answer)ì´ë‹¤.</p>

<ul>
  <li>sQuADì™€ ê°™ì€ MRC ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•˜ë©°, í•™ìŠµë°ì´í„° ì¶”ê°€ë¥¼ ìœ„í•´ Distant supervisionì„ í™œìš©í•œë‹¤.</li>
</ul>

<p><strong>Distant supervision</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501110717171.png" alt="" /></p>

<p>ì§ˆë¬¸-ë‹µë³€ë§Œ ìˆëŠ” ë°ì´í„°ì…‹ (CuratedTREC, WebQuestions, WikiMovies)ì—ì„œ MRC í•™ìŠµ ë°ì´í„° ë§Œë“¤ê¸°, Supporting documentê°€ í•„ìš”í•¨.</p>

<ol>
  <li>ìœ„í‚¤í”¼ë””ì•„ì—ì„œ Retrieverë¥¼ ì´ìš©í•´ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ê²€ìƒ‰</li>
  <li>ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë¬¸ì„œ, ì§ˆë¬¸ì˜ ê³ ìœ ëª…ì‚¬ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ” ë“± ë¶€ì í•©í•œ ë¬¸ì„œ ì œê±°</li>
  <li>answerê°€ exact matchë¡œ ë“¤ì–´ìˆì§€ ì•Šì€ ë¬¸ì„œ ì œê±°</li>
  <li>ë‚¨ì€ ë¬¸ì„œ ì¤‘ì— ì§ˆë¬¸ê³¼ (ì‚¬ìš© ë‹¨ì–´ ê¸°ì¤€) ì—°ê´€ì„±ì´ ê°€ì¥ ë†’ì€ ë‹¨ë½ì„ supporting evidenceë¡œ ì‚¬ìš©í•¨</li>
</ol>

<p><strong>Inference</strong></p>

<ul>
  <li>Retrieverê°€ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ 5ê°œ ë¬¸ì„œ ì¶œë ¥</li>
  <li>ReaderëŠ” 5ê°œ ë¬¸ì„œë¥¼ ì½ê³  ë‹µë³€ ì˜ˆì¸¡</li>
  <li>ReaderëŠ” ì˜ˆì¸¡í•œ ë‹µë³€ ì¤‘ ê°€ì¥ scoreê°€ ë†’ì€ ê²ƒì„ ìµœì¢… ë‹µìœ¼ë¡œ ì‚¬ìš©í•¨</li>
</ul>

<h3 id='Issues-and-Recent-Approaches'>Issues and Recent Approaches</h3>

<p><strong>Different granularites of text at indexing time</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501111130589.png" alt="" /></p>

<p>ìœ„í‚¤í”¼ë””ì•„ì—ì„œ ê° Passageì˜ ë‹¨ìœ„ë¥¼ ë¬¸ì„œ, ë‹¨ë½, ë˜ëŠ” ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í• ì§€ ì •í•´ì•¼ í•¨. ì´ë ‡ê²Œ ì •í•œ ë‹¨ìœ„ ê¸°ì¤€ì„ Granularityë¼ê³  í•¨.</p>

<p>ë˜í•œ, Retriever ë‹¨ê³„ì—ì„œ ëª‡ ê°œì˜ ë¬¸ì„œë¥¼ ì •í• ì§€ ê³ ë ¤í•´ì•¼í•˜ë©°(top-k), Granulartyì— ë”°ë¼ kê°€ ë‹¬ë¼ì§.</p>

<p>(e.g article -&gt; k=5, paragraph -&gt; k=29, sentence -&gt; k=78)</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501111707546.png" alt="" /></p>

<blockquote>
  <p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501112518984.png" alt="" /></p>
</blockquote>

<p><strong>Single-passage training VS Multi-passage training</strong></p>

<p>Single-passage : í˜„ì¬ ìš°ë¦¬ëŠ” kê°œì˜ passagesë“¤ì„ readerì´ ê°ê° í™•ì¸í•˜ê³  íŠ¹ì • answer spanì— ëŒ€í•œ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„, ê·¸ë¦¬ê³  ì´ ì¤‘ ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ answer spanì„ ê³ ë¥´ë„ë¡ í•¨</p>

<p>ì´ ê²½ìš° ê° retrieved passagesë“¤ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë¹„êµë¼ ë³¼ ìˆ˜ ì—†ìœ¼ë©°, ì´ë¥¼ ë°©ì§€í•˜ê¸°ìœ„í•´ Multi-passageê°€ ë“±ì¥</p>

<p>Multi-passageëŠ” retrieved passages ì „ì²´ë¥¼ í•˜ë‚˜ì˜ passageë¡œ ì·¨ê¸‰í•˜ê³ , reader ëª¨ë¸ì´ ê·¸ ì•ˆì—ì„œ answer span í•˜ë‚˜ë¥¼ ì°¾ë„ë¡ í•˜ëŠ” ê²ƒ,</p>

<p>ë‹¨, ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ì–´ì§€ë¯€ë¡œ GPUì— ë§ì€ ë©”ëª¨ë¦¬ê°€ í• ë‹¹ë˜ì•¼ í•˜ë©°, ì²˜ë¦¬í•´ì•¼í•˜ëŠ” ì—°ì‚°ëŸ‰ì´ ë§ì•„ì§</p>

<p><strong>Importance of each passage</strong></p>

<p>Retriever ëª¨ë¸ì—ì„œ ì¶”ì¶œëœ top-k passageë“¤ì˜ retrieval scoreë¥¼ reader ëª¨ë¸ì— ì „ë‹¬, ë‹¨ìˆœíˆ readerê°€ spanë§Œ ë³´ê³  íŒë‹¨í•˜ì§€ ì•Šê³  contextì˜ ì ì ˆì„±ë„ ê³ ë ¤í•¨</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210501112432281.png" alt="" /></p>

<h2 id='Reducing-Training-Bias'>Reducing Training Bias</h2>

<h3 id='Definition-of-Bias'>Definition of Bias</h3>

<p><strong>Biasì˜ ì¢…ë¥˜</strong></p>

<ol>
  <li>í•™ìŠµì—ì„œì˜ Bias :
    <ul>
      <li>í•™ìŠµí•  ë•Œ ê³¼ì í•©ì„ ë§‰ê±°ë‚˜ ì‚¬ì „ ì§€ì‹ì„ ì£¼ì…í•˜ê¸° ìœ„í•´ íŠ¹ì • í˜•íƒœì˜ í•¨ìˆ˜ë¥¼ ì„ í˜¸í•˜ëŠ” ê²ƒ (inductive bias)</li>
      <li>ê²½í–¥ê³¼ ì˜ë„ë¥¼ ìœ„í•´ ì¼ë¶€ëŸ¬ ì§‘ì–´ë„£ëŠ” ê²½ìš°ê°€ ë§ìŒ</li>
    </ul>
  </li>
  <li>A Biased World :
    <ul>
      <li>í˜„ì‹¤ ì„¸ê³„ê°€ í¸í–¥ë˜ì–´ ìˆê¸° ë•Œë¬¸ì— ëª¨ë¸ì— ì›ì¹˜ ì•ŠëŠ” ì†ì„±ì´ í•™ìŠµë˜ëŠ” ê²ƒ (historical bias)</li>
      <li>ì„±ë³„ê³¼ ì§ì—… ê°„ ê´€ê³„ ë“± í‘œë©´ì ì¸ ìƒê´€ê´€ê³„ ë•Œë¬¸ì— ì›ì¹˜ ì•ŠëŠ” ì†ì„±ì´ í•™ìŠµë˜ëŠ” ê²ƒ (co-occurrence bias)
        <ul>
          <li>Gender Bias : íŠ¹ì • ì„±ë³„ê³¼ í–‰ë™ì„ ì—°ê´€ì‹œì¼œì„œ ì˜ˆì¸¡ ì˜¤ë¥˜ê°€ ë°œìƒ(ì˜ì‚¬ì˜ ì‚¬ì§„ì€ ë†’ì€ í™•ë¥ ë¡œ ì—¬ì„±ì„ ë‚¨ì„±ìœ¼ë¡œ ì˜ëª» íŒë‹¨í•¨.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Bias in Data Generation :
    <ul>
      <li>ì…ë ¥ê³¼ ì¶œë ¥ì„ ì •ì˜í•œ ë°©ì‹ ë•Œë¬¸ì— ìƒê¸°ëŠ” í¸í–¥ (specification bias)</li>
      <li>ë°ì´í„°ë¥¼ ìƒ˜í”Œë§í•œ ë°©ì‹ ë•Œë¬¸ì— ìƒê¸°ëŠ” í¸í–¥ (sampling bias)
        <ul>
          <li>ë¦¬í„°ëŸ¬ì‹œ ë‹¤ì´ì œìŠ¤íŠ¸ ì¡ì§€ì˜ ì •ë°˜ëŒ€ì˜ ì—¬ë¡  ì¡°ì‚¬ ê²°ê³¼ : ì¡ì§€ ì •ê¸° êµ¬ë…ì, ìë™ì°¨ ë“±ë¡ì, ì‚¬êµí´ëŸ½ ëª…ë‹¨ ë“±ì—ì„œ ìƒ˜í”Œ ì±„ì·¨-&gt; ë¶€ìë“¤ë§Œ ìƒ˜í”Œì„ ì±„ì·¨í•œ ê²ƒì´ ì›ì¸ìœ¼ë¡œ, ì˜ˆì¸¡ ì‹¤íŒ¨</li>
        </ul>
      </li>
      <li>ì–´ë…¸í…Œì´í„°ì˜ íŠ¹ì„± ë•Œë¬¸ì— ìƒê¸°ëŠ” í¸í–¥ (annotator bias)</li>
    </ul>
  </li>
</ol>

<h3 id='Bias-in-Open-domain-Question-Answering'>Bias in Open-domain Question Answering</h3>

<p>Retriever-Reader Pipelineì—ì„œ Reading Comprehension ë¶€ë¶„ì˜ biasì— ì§‘ì¤‘í•¨.</p>

<p>ë§Œì•½ reader ëª¨ë¸ì´ í•œì •ëœ ë°ì´í„°ì…‹ì—ì„œë§Œ í•™ìŠµëœë‹¤ë©´, ReaderëŠ” í•­ìƒ ì •ë‹µì´ ë¬¸ì„œ ë‚´ì— í¬í•¨ëœ ë°ì´í„°ìŒë§Œ(Positive)ì„ ë³´ê²Œ ë¨</p>

<p>íŠ¹íˆ SQuADì™€ ê°™ì€ (Context, Query, Answer)ì´ ëª¨ë‘ í¬í•¨ëœ ë°ì´í„°ëŠ” positiveê°€ ì™„ì „íˆ ê³ ì •ë˜ì–´ ìˆìŒ</p>

<p>ì˜ˆë¥¼ ë“¤ì–´ Inference ì‹œ ë§Œì•½ ë°ì´í„° ë‚´ì—ì„œ ì°¾ì•„ë³¼ ìˆ˜ ì—†ì—ˆë˜ ìƒˆë¡œìš´ ë¬¸ì„œë¥¼ ì£¼ë©´, Reader ëª¨ë¸ì„ ë¬¸ì„œì— ëŒ€í•œ ë…í•´ëŠ¥ë ¥ì´ ë–¨ì–´ì ¸ ì •ë‹µì„ ë‚´ì§€ ëª»í•¨(ex) í•™ìŠµì‹œì— ë¬¸í•™ê³¼ ê´€ë ¨ ì£¼ì œë§Œ ì£¼ì–´ì¡ŒëŠ”ë°, ì‹¤ì œ Inference ë•Œì—ëŠ” ê³µí•™ê´€ë ¨ ì§€ë¬¸ë“¤ì´ ë‚˜ì˜¨ë‹¤ë©´?)</p>

<p>ì´ë¥¼ ë§‰ê¸° ìœ„í•´</p>

<ol>
  <li>
    <p>Train negative examples</p>

    <p>í›ˆë ¨ ì‹œ, ì˜ëª»ëœ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤˜ì•¼ retrieverì´ negativeí•œ ë‚´ìš©ë“¤ì€ ë¨¼ ê³³ì— ë°°ì¹˜í•  ìˆ˜ ìˆìŒ, ë˜í•œ, negative sample ë˜í•œ ë‹¤ì–‘ì„±ì„ ê³ ë ¤í•´ì•¼ í•¨.</p>

    <p>Corpus ë‚´ì—ì„œ ëœë¤í•˜ê²Œ ë½‘ê±°ë‚˜ ì¢€ë” í—·ê°ˆë¦¬ëŠ” negative ìƒ˜í”Œë“¤ ë½‘ê¸° ìœ„í•´ ë†’ì€ BM25/ TF-IDF ë§¤ì¹­ ìŠ¤ì½”ì–´ë¥¼ ê°€ì§€ì§€ë§Œ, ë‹µì„ í¬í•¨í•˜ì§€ ì•ŠëŠ” ìƒ˜í”Œì„ ë½‘ê±°ë‚˜, ê°™ì€ ë¬¸ì„œì— ë‚˜ì˜¨ ë‹¤ë¥¸ Passage/Question ì„ íƒ</p>
  </li>
  <li>
    <p>Add no answer bias</p>

    <p>ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ê°€ Nì¼ ì‹œ, ì‹œí€€ìŠ¤ì˜ ê¸¸ì´ ì™¸ 1ê°œì˜ í† í°ì´ ë” ìˆë‹¤ê³  ìƒê°í•˜ê¸°,</p>

    <p>í›ˆë ¨ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ weightì— í›ˆë ¨ ê°€ëŠ¥í•œ biasë¥¼ í•˜ë‚˜ ë” ì¶”ê°€</p>

    <p>Softmaxë¡œ answer predictionì„ ìµœì¢…ì ìœ¼ë¡œ ìˆ˜í–‰í•  ë•Œ, start end í™•ë¥ ì´ í•´ë‹¹ bias ìœ„ì¹˜ì— ìˆëŠ” ê²½ìš°ê°€ ê°€ì¥ í™•ë¥ ì´ ë†’ìœ¼ë©´ ì´ëŠ” â€œëŒ€ë‹µ í•  ìˆ˜ ì—†ë‹¤â€ë¼ê³  ì·¨ê¸‰</p>
  </li>
</ol>

<h3 id='Annotation-Bias-from-Datasets'>Annotation Bias from Datasets</h3>

<p>Annotaion Biasë€, ODQA í•™ìŠµ ì‹œ ê¸°ì¡´ì˜ MRC ë°ì´í„°ì…‹ í™œìš©ì‹œ, ODQA ì„¸íŒ…ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŒ biasê°€ ë°ì´í„° ì œì‘ (annotation) ë‹¨ê²Œì—ì„œ ë°œìƒ ê°€ëŠ¥</p>

<p>ì˜ˆë¥¼ ë“¤ì–´ SQuADë‚˜ TriviaQAëŠ” ì§ˆë¬¸ì„ í•˜ëŠ” ì‚¬ëŒì´ ë‹µì„ ì•„ëŠ” ìƒíƒœë¡œ tagging í–ˆìœ¼ë¯€ë¡œ, ë„ˆë¬´ ì‰¬ìš´ í•™ìŠµì´ ëœë‹¤.</p>

<p>ë˜í•œ, SQuADëŠ” ê³ ì‘ 500ê°œì˜ articleì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí–ˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210503223157456.png" alt="" /></p>

<p>ë°ì´í„°ì…‹ ë³„ ì„±ëŠ¥ ì°¨ì´ê°€ annotation biasë¡œ ì¸í•´ ë°œìƒ ê°€ëŠ¥</p>

<p>(BM25 : Sparse embedding / DPR : dense embedding)</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210503223656493.png" alt="" /></p>

<p>ì´ë¥¼ ë§‰ê¸° ìœ„í•´, Annotation biasë¥¼ ê³ ë ¤í•˜ê³  ë°ì´í„°ë¥¼ ëª¨ì•„ì•¼ í•œë‹¤.</p>

<p>Natural Questions dataset : Supporting evidenceê°€ ì£¼ì–´ì§€ì§€ ì•Šì€, ì‹¤ì œ ìœ ì €ì˜ questionë“¤ì„ ëª¨ì•„ì„œ datasetì„ êµ¬ì„±</p>

<p>SQuAD : Passageê°€ ì£¼ì–´ì§€ê³ , ì£¼ì–´ì§„ passage ë‚´ì—ì„œ ì§ˆë¬¸ê³¼ ë‹µì„ ìƒì„±í•˜ë¯€ë¡œ, ODQAì— applicableí•˜ì§€ ì•Šì€ ì§ˆë¬¸ë“¤ì´ ì¡´ì¬í•œë‹¤(ë¯¸êµ­ì˜ ëŒ€í†µë ¹ì€ ëˆ„êµ¬ì¸ê°€? =&gt; ì–´ëŠ ì‹œê¸°ëƒì— ë”°ë¼ ë‹¤ë¦„).</p>

<h2 id='Closed-book-QA-with-T5'>Closed-book QA with T5</h2>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504091130622.png" alt="" /></p>

<h3 id='Closed-book-Question-Answering'>Closed-book Question Answering</h3>

<p>ì‚¬ì „í•™ìŠµì„ í†µí•´ ëŒ€ëŸ‰ì˜ ì§€ì‹ì„ í•™ìŠµ í•œ ë’¤, êµ³ì´ Retriever ë‹¨ê³„ë¥¼ ê±°ì¹˜ì§€ ì•Šê³  ëª¨ë¸ ë‚´ë¶€ì˜ Knowledge storageë¥¼ í†µí•´ Answering í•˜ëŠ” ê²ƒ</p>

<p>GPT-2ë¥¼ í†µí•´ Zero-shot QAë¥¼ í•´ë³´ë©´ ì–´ëŠ ì •ë„ ëŒ€ë‹µì´ ê°€ëŠ¥í•¨</p>

<table>
  <thead>
    <tr>
      <th>Â </th>
      <th>Open-book QA</th>
      <th>Closed-book QA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ì§€ì‹ì„ ì°¾ëŠ” ë°©ì‹</td>
      <td>ëŒ€ëŸ‰ì˜ ì§€ì‹ ì†ŒìŠ¤ë¥¼ íŠ¹ì • ë¬¸ì„œ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ Dense/Sparse í˜•íƒœë¡œ í‘œí˜„í•œ í›„, queryê°€ ë“¤ì–´ì˜¤ë©´ ê°€ì¥ ê·¸ì™€ ê´€ë ¨ëœ ë¬¸ì„œë¥¼ search</td>
      <td>ëŒ€ëŸ‰ì˜ ì§€ì‹ ì†ŒìŠ¤(ìœ„í‚¤í”¼ë””ì•„ ë“±)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì´ ê·¸ ì§€ì‹ì„ ê¸°ì–µí•˜ê³  ìˆì„ ê²ƒì´ë¼ ê°€ì •í•¨. Search ê³¼ì • ì—†ì´ ë°”ë¡œ ì •ë‹µì„ ìƒì„±í•¨</td>
    </tr>
    <tr>
      <td>ë¬¸ì œì </td>
      <td>ì§€ì‹ ì†ŒìŠ¤ë¥¼ ì €ì¥í•˜ê¸° ì–´ë ¤ì›€, ê²€ìƒ‰í•˜ëŠ” ì‹œê°„ ì†Œìš”</td>
      <td>ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì§€ì‹ì„ ì˜ ê¸°ì–µí•˜ê³  ìˆëŠ”ì§€ê°€ ë§¤ìš° ì¤‘ìš”í•¨, í•™ìŠµ ì‹œê°„ì´ ê¸¸ê³  parameterìˆ˜ê°€ í¼, í•´ì„í•˜ê¸° ì–´ë ¤ì›€</td>
    </tr>
  </tbody>
</table>

<h3 id='Text-to-Text-Format'>Text-to-Text Format</h3>

<p>Text-to-Text format : ëª¨ë“  ì¢…ë¥˜ì˜ ë¬¸ì œë¥¼ Text ëŒ€ Textë¡œ ë§¤í•‘ë˜ëŠ” ë¬¸ì œë¡œ ë°”ê¿ˆ</p>

<p><strong>Closed-book QA as Text-to-Text Format</strong></p>

<p>Generation-based MRCì™€ ìœ ì‚¬í•˜ì§€ë§Œ Contextê°€ ì—†ì´ ì§ˆë¬¸ë§Œ ë“¤ì–´ê°€ë©°, Retriever ë‹¨ê³„ê°€ ì—†ë‹¤.</p>

<p>ì‚¬ì „í•™ìŠµëœ ì–¸ì–´ ëª¨ë¸ì€ BARTì™€ ê°™ì€ seq-to-seq í˜•íƒœì˜ Transformer ëª¨ë¸ì„ ì‚¬ìš©í•¨</p>

<p>Text-to-Text formatì—ì„œëŠ” ê° ì…ë ¥ê°’(ì§ˆë¬¸)ê³¼ ì¶œë ¥ê°’(ë‹µë³€)ì— ëŒ€í•œ ì„¤ëª…ì„ ë§¨ ì•ì— ì¶”ê°€í•¨.</p>

<p><strong>Text-to-Text Format</strong></p>

<p>Text-to-text problemì€ inputìœ¼ë¡œ textë¥¼ ë°›ì•„ì„œ, outputìœ¼ë¡œ ìƒˆë¡œìš´ textë¥¼ ìƒí—í•˜ëŠ” ë¬¸ì œì´ë©°, ë‹¤ì–‘í•œ text processing problemì´ text-to-text ë¬¸ì œë¡œ ë³€í˜•ë  ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504092457445.png" alt="" /></p>

<p>Text-to-Text format ë¬¸ì œì˜ ì˜ˆì‹œ</p>

<ol>
  <li>Task-specific prefixë¥¼ ì¶”ê°€í•˜ì—¬ íŠ¹ì • taskì— ì•Œë§ì€ output textë¥¼ ìƒì„±í•˜ë„ë¡ í•¨</li>
</ol>

<ul>
  <li>Machine translationì˜ ê²½ìš°, prefixë¡œ translate A to B (A: source language/ B: target language)ë¥¼ í†µí•´ ê°€ëŠ¥
    <ul>
      <li>â€œtranslate English to German: That is goodâ€ =&gt; â€œDas ist gut.â€</li>
    </ul>
  </li>
</ul>

<ol>
  <li>Text classification(MNLI)</li>
</ol>

<ul>
  <li>ë‘ê°œì˜ sentenceê°€ ì£¼ì–´ì§€ê³  ì´ ë‘˜ì˜ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•˜ëŠ” task (neutral, contradiction, entailment)
    <ul>
      <li>Input: â€œmnli hypothesis: <sent1> premise: <sent2>"</sent2></sent1></li>
      <li>Output: â€œneutralâ€ or â€œcontradictionâ€ or â€œentailmentâ€</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504093605992.png" alt="" /></p>

<p><strong>T5</strong></p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504093738892.png" alt="" /></p>

<p>Text-to-Text formatì´ë¼ëŠ” í˜•íƒœë¡œ ë°ì´í„°ì˜ ì…ì¶œë ¥ì„ ë§Œë“¤ì–´ ê±°ì˜ ëª¨ë“  ìì—°ì–´ì²˜ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ í•™ìŠµëœ seq-to-seq í˜•íƒœì˜ Transformer ëª¨ë¸</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504094037419.png" alt="" /></p>

<p>T5ì˜ Pre-training ëª¨ë¸ì˜ ê²½ìš° ë‹¤ì–‘í•œ ëª¨ë¸ êµ¬ì¡°, ì‚¬ì „í•™ìŠµ ëª©í‘œ, ì‚¬ì „í•™ìŠµìš© ë°ì´í„°, Fine-tuning ë°©ë²• ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì‹¤í—˜í•¨, ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì€ ë°©ì‹ë“¤ì„ ì„ íƒí•˜ì—¬ ë°©ëŒ€í•œ ê·œëª¨ì˜ ëª¨ë¸ì„ í•™ìŠµ ì‹œí‚´</p>

<p>T5-xlargeì˜ ê²½ìš° parameterìˆ˜ê°€ 11Bë¼ëŠ” ë°©ëŒ€í•œ í¬ê¸°ë¥¼ ìë‘í•¨</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504105614705.png" alt="" /></p>

<p>pre-trained ëœ T5ë¥¼ í™œìš© ì‹œ, Fine-tuningëœ MRC ë°ì´í„°ì…‹(TriviaQA, WebQuestions, Natural Questions)ì˜ QA pairë§Œ(context ì œì™¸)ë¥¼ í™œìš©í•˜ê³ , Task-specific prefix(ì–´ëŠ ë°ì´í„°ì…‹, ì¦‰ ì–´ëŠ taskì¸ê°€?)ì„ ì¶”ê°€ í•œë’¤, ë‹µì´ ì—¬ëŸ¬ê°œì¼ ê²½ìš°ë„ ê³ ë ¤í•´ì„œ í•™ìŠµ ì‹œí‚´</p>

<p>ex) Input: trivia question :how many legs does a ladybird have? Trget: six</p>

<h3 id='Experiment-Results-amp-Analysis'>Experiment Results &amp; Analysis</h3>

<p>Dataset : Open-domain QA ë°ì´í„°ì…‹ ë˜ëŠ” MRC ë°ì´í„°ì…‹ì—ì„œ ì§€ë¬¸ì„ ì œê±°í•˜ê³  ì§ˆë¬¸ê³¼ ë‹µë³€ë§Œ ë‚¨ê¸´ ë°ì´í„°ì…‹ì„ í™œìš©</p>

<p>Salient Span Masking : ê³ ìœ  ëª…ì‚¬, ë‚ ì§œ ë“± ì˜ë¯¸ë¥¼ ê°–ëŠ” ë‹¨ìœ„ì— ì†í•˜ëŠ” í† í° ë²”ìœ„ë¥¼ ë§ˆìŠ¤í‚¹í•œ ë’¤ í•™ìŠµ</p>

<p>Fine-tuning : Pre-trained T5 ì²´í¬í¬ì¸íŠ¸ë¥¼ Open-domain QA í•™ìŠµ ë°ì´í„°ì…‹ìœ¼ë¡œ ì¶”ê°€ í•™ìŠµ</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210504111047154.png" alt="" /></p>

<p>ëŒ€ë¶€ë¶„ Open-book ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë©°, ëª¨ë¸ í¬ê¸°ê°€ ì»¤ì§ˆìˆ˜ë¡ ì„±ëŠ¥ì´ ì¦ê°€í–ˆìœ¼ë©°, íŠ¹íˆ Salient Span Maskingì´ ì„±ëŠ¥ì„ í¬ê²Œ ëŒì–´ì˜¬ë¦¼</p>

<p>ë˜í•œ, ì˜¤ë‹µì˜ 62% ê°€ëŸ‰ì´ ì‹¤ì œ ì˜¤ë‹µì´ë©°, ë‚˜ë¨¸ì§€ 38%ëŠ” ì¤‘ë³µ ë‹µì•ˆ(Incomplete Annotation), ê°ê¸° ë‹¤ë¥¸  ì‹œê¸°, ê´€ì , ì§ˆë¬¸ì˜ í•´ì„ì— ë”°ë¼ ì •ë‹µì´ ë  ìˆ˜ ìˆê±°ë‚˜(Unanswerable), ì •ë‹µì˜ ë‹¤ë¥¸ í‘œí˜„ì„ ë‚¸ ê²½ìš°(Phrasing Mismatch)ì´ë¯€ë¡œ ì‹¤ì œ ì„±ëŠ¥ì€ ë”ìš± ì¦ê°€í•œë‹¤.</p>

<p>Closed-book QAì˜ í•œê³„ë¡œ,</p>

<ol>
  <li>ëª¨ë¸ì˜ í¬ê¸°ê°€ ë„ˆë¬´ ì»¤ì„œ ê³„ì‚°ëŸ‰ì´ ë§ê³  ì†ë„ê°€ ëŠë¦¼ -&gt; ë” íš¨ìœ¨ì ì¸ ëª¨ë¸ í•„ìš”</li>
  <li>ëª¨ë¸ì´ ì–´ë–¤ ë°ì´í„°ë¡œ ë‹µì„ ë‚´ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ìŒ -&gt; ê²°ê³¼ì˜ í•´ì„ ê°€ëŠ¥ì„±(interpretability)ë¥¼ ë†’ì´ëŠ” ì—°êµ¬ í•„ìš”</li>
  <li>ëª¨ë¸ì´ ì°¸ì¡°í•˜ëŠ” ì§€ì‹ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì œê±°í•˜ê¸° ì–´ë ¤ì›€</li>
</ol>

<h2 id='QA-with-Phrase-Retrieval'>QA with Phrase Retrieval</h2>

<h3 id='Phrase-Retrieval-in-Open-Domain-Question-Answering'>Phrase Retrieval in Open-Domain Question Answering</h3>

<p>ê¸°ì¡´ì˜ Retriever-Reader ë°©ì‹ì€ ë‹¤ìŒê³¼ ê°™ì€ í•œê³„ë¥¼ ê°–ëŠ”ë‹¤.</p>

<ol>
  <li>Error Propagation: 5-10ê°œì˜ ë¬¸ì„œë§Œ readerì—ê²Œ ì „ë‹¬</li>
  <li>Query-dependent encoding: queryì— ë”°ë¼ ì •ë‹µì´ ë˜ëŠ” answer spanì— ëŒ€í•œ encodingì´ ë‹¬ë¼ì§</li>
</ol>

<p>2ë‹¨ê³„ë¡œ ì´ë£¨ì§€ ë§ê³  ë°”ë¡œ contextì—ì„œ ì •ë‹µì„ searchí•˜ëŠ” ë°©ë²•ì¸ Phrase Indexing ê³ ì•ˆ</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506094451910.png" alt="" /></p>

<p>ë¯¸ë¦¬ ê³„ì‚°ëœ key vectorì™€ Query vectorë¥¼ ë¹„êµí•˜ì—¬ ë‹µì„ êµ¬í•˜ê²Œ ëœë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506095646964.png" alt="" /></p>

<p>ê¸°ì¡´ì˜ a,q,d ì¡°í•© ì¤‘ ê°€ì¥ ì ìˆ˜ê°€ ë†’ì€ ê²ƒì„ ì°¾ëŠ” ë°©ë²•(F í•¨ìˆ˜)ì—ì„œ ì•„ë˜ì˜  Queryë§Œ(G í•¨ìˆ˜) ë‹¤ì‹œ ê³„ì‚°í•˜ëŠ” ë°©ë²•ì˜¬ ë°”ê¾¸ì–´ ë”ìš± íš¨ìœ¨ì ì´ë‹¤.</p>

<p>ë‹¤ë§Œ ì‹¤ì œë¡œ F í•¨ìˆ˜ë¥¼ Gì™€ H í•¨ìˆ˜ë¡œ ì •í™•íˆ ëŒ€ì²´í•  ìˆ˜ ì—†ì–´ Approximation í•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•˜ë©°, ì´ë•Œ ì‹¤ì œ F í•¨ìˆ˜ê°’ê³¼ G, H  í•¨ìˆ˜ ê°’ì˜ ì°¨ì´ì¸ Decomposition Gapì´ ì„±ëŠ¥ í•˜ë½ì˜ ì£¼ìš” ì›ì¸ì´ ëœë‹¤.</p>

<p>ì´ë•Œ, ê° phraseë¥¼ vector space ìƒì— ì˜ mapping í•˜ê¸° ìœ„í•´ Denseì™€ Sparse ì„ë² ë”©ì„ ë‘˜ë‹¤ ì´ìš©í•˜ê²Œ ëœë‹¤.</p>

<h3 id='Dense-sparse-Representation-for-Phrases'>Dense-sparse Representation for Phrases</h3>

<p>Dense vectorsëŠ” í†µì‚¬ì , ì˜ë¯¸ì  ì •ë³´ë¥¼ ë‹´ëŠ” ë° íš¨ê³¼ì ì´ë©°,(ìœ ì—°í•¨)</p>

<p>Sparse vectorsëŠ” ì–´íœ˜ì  ì •ë³´ë¥¼ ë‹´ëŠ” ë° íš¨ê³¼ì ì´ë¯€ë¡œ, (ëª…í™•í•¨)</p>

<p>ì´ ë‘˜ì„ ì „ë¶€ ì´ìš©í•˜ì—¬ phrase (and question) embeddingì„ í•  ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506100447565.png" alt="" /></p>

<p>Dense vectorë¥¼ ë§Œë“œëŠ” ë°©ë²•</p>

<ul>
  <li>Pre-trained LM (e.g. BERT)ë¥¼ ì´ìš©</li>
  <li>Start vectorì™€ end vectorë¥¼ ì¬ì‚¬ìš©í•´ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¤„ì„</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506101357044.png" alt="" /></p>

<p>Coherency vector ìƒì„±ë²•</p>

<ul>
  <li>phraseê°€ í•œ ë‹¨ìœ„ì˜ ë¬¸ì¥ êµ¬ì„± ìš”ì†Œì— í•´ë‹¹í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„</li>
  <li>êµ¬ë¥¼ í˜•ì„±í•˜ì§€ ì•ŠëŠ” phraseë¥¼ ê±¸ëŸ¬ë‚´ê¸° ìœ„í•´ ì‚¬ìš©í•¨</li>
  <li>Start vectorì™€ end vectorë¥¼ ì´ìš©í•˜ì—¬ ê³„ì‚°</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506101600118.png" alt="" /></p>

<p>Question embedding ìƒì„±ë²•</p>

<ul>
  <li>Questionì„ ì„ë² ë”©í•  ë•ŒëŠ” [CLS] í† í° (BERT)ì„ í™œìš©</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506101649648.png" alt="" /></p>

<p>Sparse vectorë¥¼ ë§Œë“œëŠ” ë°©ë²•</p>

<ul>
  <li>ë¬¸ë§¥í™”ëœ ì„ë² ë”©(contextualized embedding)ì„ í™œìš©í•˜ì—¬ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ n-gramìœ¼ë¡œ sparse vector êµ¬ì„±</li>
</ul>

<p><img src="/assets/img/ê¸°ê³„ ë…í•´ ê¸°ë³¸/image-20210506101836990.png" alt="" /></p>

<p><strong>Scalability Challenge</strong></p>

<p>Wikipedia ê°™ì€ ëŒ€ëŸ‰ì˜ phrasesë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•´, Storage, indexing, searchì˜ scalabiltyê°€ ê³ ë ¤ë˜ì–´ì•¼ í•˜ë©°,</p>

<p>Storageì˜ ê²½ìš° Pointer, filter, scalar quantizationì„ í™œìš©í•˜ì—¬ 1/130 ìˆ˜ì¤€ ê¹Œì§€ ì¤„ì¼ ìˆ˜ ìˆìŒ</p>

<p>Search ì†ë„ì˜ ê²½ìš° FAISSë¥¼ í™œìš©í•´ dense vectorì— ëŒ€í•œ searchë¥¼ ë¨¼ì € ìˆ˜í–‰ í›„, sparse vectorë¡œ reranking</p>

<h3 id='Experiment-Results-amp-Analysis'>Experiment Results &amp; Analysis</h3>

<p>Phrase retrieval ë°©ì‹ì€ ë°œí‘œ ë‹¹ì‹œì—ëŠ” ì•½ê°„ì˜ ì„±ëŠ¥ ìƒìŠ¹ê³¼ ëŒ€ë‹¨íˆ í° inference speedë¥¼ ìë‘í–ˆì—ˆì§€ë§Œ, Decomposability gapì´ ë¶ˆëŸ¬ì˜¤ëŠ” íš¨ê³¼ë¡œ ìµœê·¼ ë°œí‘œëœ Retrieval-Reader ë°©ì‹ì˜ ì—°êµ¬ë“¤ ë³´ë‹¤ ì„±ëŠ¥ì´ ë’¤ì³ì§€ë©°, Storage ìš©ëŸ‰ì„ í¬ê²Œ í•„ìš”ë¡œ í•œë‹¤ëŠ” ë‹¨ì ì„ ê°€ì§€ê²Œ ëœë‹¤.</p>


</div>

  </div><a class="u-url" href="/articles/AI/NLP/%EA%B8%B0%EA%B3%84%20%EB%8F%85%ED%95%B4%20%EA%B8%B0%EB%B3%B8.html" hidden></a>
  <p class="u-path" hidden>_articles/AI/NLP/ê¸°ê³„ ë…í•´ ê¸°ë³¸.md</p>
  <script type="module" src="/assets/scripts/utils/update_recents.js"></script>
</article>

    </div>
  </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">The Digital garden of Nurgle.</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="a-name">The Digital garden of Nurgle.</li><li><a class="u-email" href="mailto:roadvirushn@gmail.com">roadvirushn@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li>
    <a href="https://github.com/RoadVirusHN"><svg class="svg-icon">
        <use xlink:href="/assets/svg/social-icons.svg#github"></use>
      </svg>
      <span class="username">RoadVirusHN</span></a>
  </li><!---->
</ul></div>

      <div class="footer-col footer-col-3">
        <p>ì´ê²ƒì´ ë””ì§€í„¸ ë™ë¬¼ì˜ ìˆ²ì´ë‹¤!! íŒŒë©¸í¸ (This is the Digital Animal Crossing!! Bad Ending.01)</p>
      </div>
    </div>

  </div>

</footer>
</body>

<script src="/assets/scripts/bundle/common.bundle.js"></script>

</html>