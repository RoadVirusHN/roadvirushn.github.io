<!DOCTYPE html>
<html lang="kr"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸ | ğŸ§ SUBBRAIN</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸" />
<meta property="og:locale" content="kr" />
<meta name="description" content="style: number min_depth: 2 max_depth: 3 varied_style: true" />
<meta property="og:description" content="style: number min_depth: 2 max_depth: 3 varied_style: true" />
<link rel="canonical" href="http://localhost:4000/articles/AI/CV/%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:url" content="http://localhost:4000/articles/AI/CV/%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84%20%EA%B8%B0%EB%B3%B8.html" />
<meta property="og:site_name" content="ğŸ§ SUBBRAIN" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-12-14T13:41:08+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-12-14T13:41:08+09:00","datePublished":"2022-12-14T13:41:08+09:00","description":"style: number min_depth: 2 max_depth: 3 varied_style: true","headline":"ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/articles/AI/CV/%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84%20%EA%B8%B0%EB%B3%B8.html"},"url":"http://localhost:4000/articles/AI/CV/%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84%20%EA%B8%B0%EB%B3%B8.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="ğŸ§ SUBBRAIN" /><link rel="icon" type="image/x-icon" href="/assets/img/common/favicon.ico">
</head>
<div class="scrollWrapper">
  <div class="scrollbar"></div>
  <div class="progressbar"></div>
  <div class="scrollbarButton"></div>
</div>

<link rel="stylesheet" href="/assets/css/obsidian/obs-scrollbar.css" />

<!--<div class="redirection">
  <h1 class="name">Redirection for full experience.</h1>
  <br>
  Move to <br /> <a class="to" href="#">netlify url</a><br />
  <div>after <span class="counter">10</span>secs.</div>
  press <button class="cancle">here</button> to cancle.
</div>
<div class="overlay"></div>
<script type="module" src="/assets/scripts/common/components/init_redirection.js"></script>

<link rel="stylesheet" href="/assets/css/common/redirection.css" />-->

<body><header class="site-header" role="banner">

  <div class="wrapper" style="display: flex; justify-content: space-between;"><div id="header-wrapper">
    <a class="site-title" rel="author" href="/blog">ğŸ§ SUBBRAIN</a>

    </div><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><script src="https://unpkg.com/lunr/lunr.js"></script>
<link rel="stylesheet" href="/assets/css/common/searchbar.css" />

<form id="search-form" method="get">
  <span id="search-wrapper">
    <span id="tag-holder" ></span>
    <input type="text" id="search-box" placeholder='Prefix "#" to add Tag.' autocomplete="off">
    <span class="inner-search" >ğŸ”</span>
  </span>
</form><a class="page-link" href="/">ABOUT ME</a><a class="page-link" href="/blog">ALL ARTICLES</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
    <link rel="stylesheet" href="/assets/css/common/drawer.css" />
<button class="drawer-button open">â–¶ï¸</button>
<div id="drawer" class="close">
  <button class="drawer-button close">
    â—€ï¸
  </button>
  <div class="drawer-content">
    <div class="my-description">
      <div class="avatar-section" style="display: flex; flex-direction: row;">

        <img src="/assets/img/common/avatar.png" alt="avatar" class="avatar">
        <div style="display: flex; flex-direction: column; margin-left: 5px;">
          <a href="/about/">
            <h3 class="name">ROADVIRUSHN</h3>
          </a>
          <div class="stack-list" style="margin: 5px 0 0 5px;">
            <a title="My github page" href="https://github.com/RoadVirusHN">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#github"></use>
  </svg>
</a>
<a title="My G-mail" href="mailto:roadvirushn@gmail.com">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#gmail"></use>
  </svg>
</a>
<a title="My Blog" href="https://luminous-bubblegum-8e9be4.netlify.app">
  <svg class="svg-icon" width="16" height="16" viewBox="0 0 16 16">
    <use xlink:href="/assets/svg/social-icons.svg#blog"></use>
  </svg>
</a>
          </div>
        </div>
        <!-- <h4 class="name">(JUNSEOK YUN)</h4> -->
      </div>
      <p style="margin: 5px 0 0 0;">
        í’€ìŠ¤íƒ ì›¹ğŸŒ ê°œë°œì ì§€ë§ìƒ ğŸ§‘ğŸ½â€ğŸ’»
        <br>
        â• ì¸ê³µì§€ëŠ¥ ê´€ì‹¬ ğŸ¤–
      </p>
    </div>
      <hr>
      <div class="categories">
        <h3 style="margin: 0;"><a href="/">Categories</a></h3>
        <ul class="category-list">
  
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/COMPUTER_SCIENCE/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">COMPUTER_SCIENCE</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 6
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/DATABASE/">DATABASE</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ALGORITHM/">ALGORITHM</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 16 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/OS/">OS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/NETWORK/">NETWORK</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 8 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/ETC/">ETC</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            ğŸ“‚: 1
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/COMPUTER_SCIENCE/OSSU/">OSSU</a>
        </h4>
          <span style="font-size: xx-small;">
             
            ğŸ“‚: 1
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/WEB/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">WEB</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 3
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/FRONTEND/">FRONTEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/BACKEND/">BACKEND</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 2
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/WEB/CI,CD/">CI,CD</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            ğŸ“‚: 2
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”£ </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/ETC/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">ETC</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 2
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/ETC/ETCS/">ETCS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 10 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          â”ƒ  
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/ETC/SUBBRAIN ê°œë°œê¸°/">SUBBRAIN ê°œë°œê¸°</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 5 
            
          </span>
      </li>
      
    </ul>
  </li>
  
  
  <li>
    <strong style="font-size: larger;">â”— </strong>
    <h3 style="display: inline;">
      
      <a href="/categories/AI/" class="category-drop-down">â–¶</a>
      
      <span class="category-link">AI</span>
    </h3>
    <span style="font-size: xx-small;">
       
      ğŸ“‚: 9
    </span>
    <ul class="child-category-list">
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/AITOOLS/">AITOOLS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/CV/">CV</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DEEP_LEARNING/">DEEP_LEARNING</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/DATA_VIS/">DATA_VIS</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/GRAPH/">GRAPH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/LIGHTWEIGHT/">LIGHTWEIGHT</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/MATH/">MATH</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 1 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”£ 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/NLP/">NLP</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 3 
            
          </span>
      </li>
      
      <li>
        <strong style="font-size: larger;">
          &nbsp;&nbsp;&nbsp;
          â”— 
        </strong>
        <h4 style="display: inline; background-color: lightgray; padding: 0px 1px; border-radius: 2px;">
          <a class="category-link" href="/categories/AI/STRUCTURED_DATA/">STRUCTURED_DATA</a>
        </h4>
          <span style="font-size: xx-small;">
            ğŸ“„: 2 
            
          </span>
      </li>
      
    </ul>
  </li>
  
</ul>
      </div>
      <hr>
      <div class="recent-view">
        <h3 style="margin: 0;">Recent views</h3>
        <ul style="margin: 0;">
          <li>
            <strong style="color:rgb(219, 219, 12);">1 <a id="recent-1"></a></strong>
          </li>
          <li>
            2 <a id="recent-2"></a>
          </li>
          <li>
            3 <a id="recent-3"></a>
          </li>
          <li>
            4 <a id="recent-4"></a>
          </li>
          <li>
            5 <a id="recent-5" style="overflow: hidden;"></a>
          </li>
        </ul>
      </div>
    </div>
    <hr>
  <div style="height: 7vh;"></div>
</div>
    <div class="wrapper">
      <article class="article h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="article-header">
    <h1 class="article-title a-name" itemprop="name headline">ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸</h1>
    <p class="article-meta">
      <time class="dt-published" datetime="2022-12-14T13:41:08+09:00" itemprop="datePublished">Dec 14, 2022
      </time></p>
  </header>

  <div class="article-content e-content" itemprop="articleBody">
     
  
<script>
  MathJax = {
    tex: {
      inlineMath: [
        ["$", "$"],
        ["\\(", "\\)"],
      ],
    },
    svg: {
      fontCache: "global",  
     // scale: 1.5,
    },
    chtml: {
     // scale: 1.5,
    },
  };
</script>
<script
  type="text/javascript"
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>
 
 


<script src="/assets/scripts/bundle/obsidian.bundle.js"></script>
<link rel="stylesheet" href="/assets/css/obsidian/callout.css" />
<link rel="stylesheet" href="/assets/css/obsidian/image.css" />
<link rel="stylesheet" href="/assets/css/obsidian/link-warning.css" />
<link rel="stylesheet" href="/assets/css/obsidian/preview.css" />

<div class="content-section">
  <html><head></head><body><ol id="markdown-toc-0"><li lvl="2"><a id="markdown-toc-0-0" href="#Image-Classification-1">Image Classification 1</a><ul><li lvl="3"><a id="markdown-toc-0-1" href="#Course-overview">Course overview</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-2" href="#Image-classification-ì˜ìƒ-ë¶„ë¥˜">Image classification(ì˜ìƒ ë¶„ë¥˜)</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-3" href="#CNN-architectures-for-image-classification-1">CNN architectures for image classification 1</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-4" href="#Annotation-data-efficient-learning">Annotation data efficient learning</a><ul><li lvl="3"><a id="markdown-toc-0-5" href="#Data-augmentation">Data augmentation</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-6" href="#Leveraging-pre-trained-information">Leveraging pre-trained information</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-7" href="#Leveraging-unlabled-dataset-for-training">Leveraging unlabled dataset for training</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-8" href="#Image-classification-2">Image classification 2</a><ul><li lvl="3"><a id="markdown-toc-0-9" href="#Problems-with-deeper-layers">Problems with deeper layers</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-10" href="#CNN-architectures-for-image-classification-2">CNN architectures for image classification 2</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-11" href="#Summary-of-image-classification">Summary of image classification</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-12" href="#Semantic-segmentation">Semantic segmentation</a><ul><li lvl="3"><a id="markdown-toc-0-13" href="#Semantic-segmentation">Semantic segmentation</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-14" href="#Semantic-segmentation-architectures">Semantic segmentation architectures</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-15" href="#Object-detection">Object detection</a><ul><li lvl="3"><a id="markdown-toc-0-16" href="#Object-detection">Object detection</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-17" href="#Two-stage-detector-R-CNN-family">Two-stage detector(R-CNN family)</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-18" href="#Single-stage-detector">Single-stage detector</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-19" href="#Single-stage-detector-vs-two-stage-detector">Single-stage detector vs. two-stage detector</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-20" href="#Detection-with-Transformer">Detection with Transformer</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-21" href="#CNN-Visualization">CNN Visualization</a><ul><li lvl="3"><a id="markdown-toc-0-22" href="#Visualizing-CNN">Visualizing CNN</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-23" href="#Analysis-of-model-behaviors">Analysis of model behaviors</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-24" href="#Model-decision-explanation">Model decision explanation</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-25" href="#Instance-panoptic-segmentation-and-landmark-localization">Instance/panoptic segmentation and landmark localization</a><ul><li lvl="3"><a id="markdown-toc-0-26" href="#Instance-segmentation">Instance segmentation</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-27" href="#Panoptic-segmentation">Panoptic segmentation</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-28" href="#Landmark-localization">Landmark localization</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-29" href="#Detecting-objects-as-keypoints">Detecting objects as keypoints</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-30" href="#Conditional-Generative-Model-cGAN">Conditional Generative Model(cGAN)</a><ul><li lvl="3"><a id="markdown-toc-0-31" href="#Conditional-generative-model-cGAN">Conditional generative model(cGAN)</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-32" href="#Image-translation-GANs">Image translation GANs</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-33" href="#Various-GAN-applications">Various GAN applications</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-34" href="#Multi-modal-learning-Captioning-and-Speaking">Multi-modal learning: Captioning and Speaking</a><ul><li lvl="3"><a id="markdown-toc-0-35" href="#Overview-of-multi-modal-learning">Overview of multi-modal learning</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-36" href="#Multi-modal-tasks-1-Visual-data-Text">Multi-modal tasks (1) - Visual data &amp; Text</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-37" href="#Multi-modla-tasks-2-Visual-data-Audio">Multi-modla tasks(2) - Visual data &amp; Audio</a><ul></ul></li></ul></li><li lvl="2"><a id="markdown-toc-0-38" href="#3D-undersanding">3D undersanding</a><ul><li lvl="3"><a id="markdown-toc-0-39" href="#Seeing-the-world-in-3D-perspective">Seeing the world in 3D perspective</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-40" href="#3D-tasks">3D tasks</a><ul></ul></li><li lvl="3"><a id="markdown-toc-0-41" href="#3D-application-example-Photo-refocusing">3D application example- Photo refocusing</a><ul></ul></li></ul></li></ol>
<h1 id="ì»´í“¨í„°ë¹„ì „-Computer-Vision-CV-ê¸°ë³¸">ì»´í“¨í„°ë¹„ì „(Computer Vision, CV) ê¸°ë³¸</h1>

<blockquote>
  <p>ë„¤ì´ë²„ AI ë¶€ìŠ¤íŠ¸ ìº í”„ì˜ CV ê°•ì˜ë¥¼ ì •ë¦¬í•œ ë‚´ìš©ì…ë‹ˆë‹¤.</p>
</blockquote>

<h2 id="Image-Classification-1">Image Classification 1</h2>

<h3 id="Course-overview">Course overview</h3>

<p>Artificial Intelligence(AI) : ì‚¬ëŒì˜ ì§€ëŠ¥ì„ ì»´í“¨í„° ì‹œìŠ¤í…œìœ¼ë¡œ êµ¬í˜„í•˜ëŠ” ê²ƒ</p>

<p>ì‚¬ëŒì˜ í•™ìŠµì€ ì˜¤ê°ì„ ì¡°í•©í•´ì„œ ì‚¬ìš©í•˜ëŠ” multi-modal perceptionê³¼ ë¹„ìŠ·í•˜ë‹¤.</p>

<p>ë¿ë§Œ ì•„ë‹ˆë¼ ì‚¬íšŒì  ê°ê°(í‘œì • ì‚´í”¼ê¸°, ê´€ê³„ ë§ºê¸°, ì˜ë„ íŒŒì•…í•˜ê¸°) ë“±ì˜ ë³µí•©ì  ê°ê°ì´ ì¡´ì¬</p>

<p>ì´ì¤‘ ì‹œê°ì  ëŠ¥ë ¥ì´ ê¸°ì´ˆì ì´ê³  ì¤‘ìš”í•œ ëŠ¥ë ¥ì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308093803218.png" alt=""></p>

<p><strong>[img. ë³µì¡í•œ ì¸ê°„ì˜ ì¸ì§€]</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ì¸ê°„ì˜ ì‹œê°ì  ì²˜ë¦¬ VS ì»´í“¨í„°ì˜ ì‹œê°ì  ì²˜ë¦¬</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308093956611.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308093950605.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[fig. ì‚¬ì§„ì˜ representation(ìë£Œêµ¬ì¡°, ì—¬ê¸°ì„œëŠ” ì²˜ë¦¬ ê²°ê³¼) êµ¬í•˜ê¸°]</strong></p>

<p>ë˜í•œ, ìš°ë¦¬ì˜ ì‹œê°ì  ëŠ¥ë ¥ ë˜í•œ ì´ëŸ° ë¨¸ì‹ ëŸ¬ë‹ êµ¬ì¡°ì˜ CVì™€ ë¹„ìŠ·í•˜ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308094608496.png" alt=""></p>

<p><strong>[img. ëŒ€ì²˜ í™˜ê°, ê±°ê¾¸ë¡œ ëœ ì‚¬ëŒì€ ë§ì´ ë³´ì§€ ëª»í•˜ê¸° ë•Œë¬¸(= í•™ìŠµ í¸í–¥)ì— ì–´ìƒ‰í•¨ì„ ëŠë¼ì§€ ëª»í•œë‹¤.]</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Machine Learning vs Deep Learning</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308094749066.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308094810716.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[img. íŠ¹ì§• ì¶”ì¶œê¹Œì§€ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•´ì§„ Deep Learning ë¶„ì•¼]</strong></p>

<p>íŠ¹ì§• ì¶”ì¶œì„ ì‚¬ëŒì´ ì„¤ê³„í•˜ì§€ì•Šê³  Gradient-Descendë¥¼ í†µí•´ End-to-Endë¡œ í•™ìŠµí•¨ìœ¼ë¡œ, í¸í–¥ê³¼ ì˜¤ë¥˜ë¥¼ ì¤„ì—¬ ìµœê·¼ CVê¸°ìˆ ì´ ê³ ë„í™” ë¨</p>

<p>ì´ë²ˆ ê°•ì˜ì—ì„œ</p>

<ul>
  <li>ê¸°ë³¸ì ì¸ CV Task</li>
  <li>CVì˜ ë”¥ëŸ¬ë‹ ê¸°ìˆ </li>
  <li>ì‹œê° ì •ë³´ + ë‹¤ë¥¸ ê°ê° ë°ì´í„°ì˜ ìœµí•©</li>
  <li>Conditional generative model</li>
  <li>Visualization Tool</li>
</ul>

<p>ë“±ì„ ë°°ìš¸ ê²ƒì´ë‹¤.</p>

<h3 id="Image-classification-ì˜ìƒ-ë¶„ë¥˜">Image classification(ì˜ìƒ ë¶„ë¥˜)</h3>

<p>Classifier (ë¶„ë¥˜ê¸°) ì—…ë¬´ëŠ” ì…ë ¥ëœ ì˜ìƒì˜ ì¹´í…Œê³ ë¦¬, í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” mapping ì—…ë¬´ì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308095502653.png" alt=""></p>

<p><strong>[img. Classifier ì˜ˆì‹œ]</strong></p>

<p>ë§Œì•½, ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ ë°ì´í„°ê°€ ìˆë‹¤ë©´, ë¹„ìŠ·í•œ ì‚¬ì§„ë¼ë¦¬ ëª¨ì•„ êµ¬ë³„í•˜ëŠ” <em>k-Nearest Neighbors(k-NN)</em>ë¥¼ í†µí•˜ì—¬ êµ¬ë³„í•  ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>query data pointì˜ ì£¼ë³€ reference pointë¥¼ ì´ìš©í•´ êµ¬ë¶„í•˜ëŠ” ë°©ë²•</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308100000964.png" alt=""></p>

<p><strong>[img. K-NN ì˜ˆì‹œ ì´ë¯¸ì§€]</strong></p>

<p>í•˜ì§€ë§Œ, ë°ì´í„° ìˆ˜ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë§ì€ ë§Œí¼ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ê²Œ ëœë‹¤.</p>

<p>ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ Neural Networksë¥¼ ì´ìš©í•´ Compress ëœ ëª¨ë¸ì„ í†µí•´ êµ¬ë³„í•˜ê²Œ ëœë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308100345559.png" alt=""></p>

<p><strong>[img. 1ì¸µì˜ fully-connected layerì„ ì´ìš©í•œ êµ¬ë¶„]</strong></p>

<p>ì˜ìƒì˜ ëª¨ë“  í”½ì…€ì„ Inputìœ¼ë¡œ ë„£ì–´ êµ¬ë¶„í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì´ ì—­ì‹œ ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ ì†Œëª¨ê°€ í¬ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308101409313.png" alt=""></p>

<p><strong>[img. FCNê³¼ CNNì˜ ë¹„êµ]</strong></p>

<p>CNNì€ ì „ì²´ pixelì´ ì•„ë‹Œ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¥¼ ì§€ì—­ì ìœ¼ë¡œ Window Sliding ë°©ì‹ìœ¼ë¡œ í•˜ë‚˜ì˜ featureë¡œ ì¶”ì¶œí•˜ê³ (Local feature learning), íŒŒë¼ë¯¸í„° ê³µìœ ë¥¼ í†µí•˜ì—¬</p>

<ol>
  <li>ì„±ëŠ¥ê³¼ ë©”ëª¨ë¦¬ì˜ ìš”êµ¬ë¥¼ ì¤„ì´ê³ </li>
  <li>ì˜¤ë²„í”¼íŒ…ì„ ì¤„ì¼ê³ </li>
  <li>ì‚¬ì§„ ì¼ë¶€ë§Œìœ¼ë¡œë„ ì‚¬ì§„ì„ êµ¬ë³„í•  ìˆ˜ ìˆê²Œ ë¬ë‹¤.</li>
</ol>

<p>ì´ëŸ¬í•œ ì¥ì  ë•ë¶„ì— ë§ì€ Computer Vision ì—…ë¬´ì— ê¸°ë³¸ì´ ë¨.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308102242021.png" alt=""></p>

<p><strong>[img. CNNì˜ ì—¬ëŸ¬ ì‚¬ìš©]</strong></p>

<h3 id="CNN-architectures-for-image-classification-1">CNN architectures for image classification 1</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308104319839.png" alt=""></p>

<p><strong>[img. AlexNetê³¼ VGGNetì˜ ë“±ì¥]</strong></p>

<ul>
  <li>ë”¥ëŸ¬ë‹ CVì˜ ë“±ì¥ì„ ì•Œë¦° ë‘ ëª¨ë¸</li>
</ul>

<ol>
  <li>AlexNet</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308104438510.png" alt=""></p>

<p><strong>[img. AlexNetì˜ êµ¬ì¡°]</strong></p>

<ul>
  <li>ìµœì´ˆì˜ ì‹¬í”Œí•œ CNN êµ¬ì¡°ì¸ LeNet-5ì˜ êµ¬ì¡°ì—ì„œ ë” ê¹Šì€ ì¸µ, ë” ë§ì€ ë°ì´í„°ì…‹, ReLU í™œì„± í•¨ìˆ˜ì™€ drop outê³¼ ê°™ì€ regularization ê¸°ìˆ ì„ ì´ìš©í•œ ëª¨ë¸</li>
  <li>ë‹¹ì‹œ GPU ë©”ëª¨ë¦¬ì˜ í•œê³„ë¡œ ì¸í•´ 2ê°ˆë˜ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµí•œ ë’¤ ì¤‘ê°„ì— Activation mapìœ¼ë¡œ Cross Communication í•´ì¤Œ</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">11</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 11x11 Conv(96), stride 4 Layer
# ì´ë¯¸ì§€ í¬ê¸°ê°€ ì»¤ì§€ë©´ì„œ, Receptive fieldë¥¼ í¬ê²Œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•´ 11x11ë¡œ ì‹œì‘, ìµœê·¼ì—ëŠ” ë”ì´ìƒ ì‚¬ìš© ì•ˆí•¨
</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="c1"># 3x3 MaxPool, stride 2 Layer
</span>
<span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="mi">96</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 5x5 Conv(256), stride 2 Layer
</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="c1"># 3x3 Conv(384), pad 1 Layer
</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">nn</span><span class="p">.</span><span class="n">conv2d</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">torch</span><span class="p">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># Fully connected Layerì— ë„£ê¸° ì „ì— ë‹¤ì°¨ì›ì˜ Tensorë¥¼ 1ì°¨ì› Tensorìœ¼ë¡œ ê¸¸ì´ë¥¼ ê¸¸ê²Œ ëŠ˜ì–´ ëœ¨ë¦¬ê¸°(ë²¡í„°í™”)
# AlexNetì—ì„œ ì‚¬ìš©í•œ ë°©ë²•
</span>
<span class="c1"># nn.AdaptiveAvgPool2d((6,6))
# ë¹„ìŠ·í•œ ë°©ë²•ì´ì§€ë§Œ, ê¸¸ê²Œ ëŠ˜ì–´ëœ¨ë¦¬ì§€ ì•Šê³  í‰ê· ì„ ë‚´ì–´ ê°™ì€ ê¸¸ì´ì˜ 1ì°¨ì›ìœ¼ë¡œ ë°”ê¿ˆ
</span>
<span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">()</span> <span class="c1"># Dense(4096)
</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">256</span><span class="o">*</span><span class="mi">6</span><span class="o">*</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span> <span class="c1"># 2stream êµ¬ì¡°ê°€ ì•„ë‹ˆë¼ 1ê°œë¡œ í†µí•©í–ˆìœ¼ë¯€ë¡œ 2048 *2 = 4096
</span><span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">Dropout</span><span class="p">()</span>
<span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">)</span>
<span class="n">nn</span><span class="p">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

</code></pre></div></div>
<p><strong>[code. AlexNetì˜ ì½”ë“œêµ¬í˜„]</strong></p>

<ul>
  <li>ì‹œê°„ì´ í˜ëŸ¬ GPU ë©”ëª¨ë¦¬ê°€ ëŠ˜ì–´ë‚˜ 2 stream êµ¬ì¡°ë¡œ êµ¬í˜„í•˜ì§€ ì•ŠìŒ</li>
  <li>LRN(Local Response Normalization) êµ¬í˜„ ì•ˆí•¨
    <ul>
      <li>ë”ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë°©ë²•, Batch normalizationìœ¼ë¡œ ëŒ€ì²´ë¨</li>
      <li>Activation map ì´í›„, ëª…ì•”ì„ normalization í•´ì£¼ëŠ” ì—­í• </li>
    </ul>
  </li>
</ul>

<p>Receptive fieldë€?</p>

<p>layer output ê°’ì„ ë§Œë“¤ê¸°ìœ„í•´ Input imageì—ì„œ CNN layerê°€ ì°¸ì¡°í•œ ê³µê°„, í´ ìˆ˜ë¡ ì´ë¯¸ì§€ì˜ ë§ì€ ë¶€ë¶„ì„ ì°¸ì¡°í•œ ê²ƒì´ë‹¤.</p>

<p>ì—¬ëŸ¬ ì¸µì´ ì¤‘ì²©ë˜ë„ ì²˜ìŒ imageì—ì„œ í™•ì¸í•œ ë¶€ë¶„ì´ Receptive fieldì´ë‹¤.</p>

<p>ìœ„ êµ¬ì¡°ì—ì„œëŠ” ì „ì²´ë¥¼ 11x11 convë¡œ Input ì´ë¯¸ì§€ ì „ë¶€ë¥¼ Receptive fieldë¡œ ì‚¼ì•˜ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308111832639.png" alt=""></p>

<p><strong>[img. Receptive Field ë„ì‹í™”]</strong></p>

<p>KxK conv stride 1 layerì™€ PxP pooling layerë¥¼ í†µê³¼í•œ ê²½ìš°ì˜ Receptive fieldì˜ í¬ê¸°ëŠ”</p>

<p>(P+K-1)x(P+K-1)ì´ë‹¤.</p>

<ol>
  <li>VGGNet</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308112229605.png" alt=""></p>

<p><strong>[img. VGGNetì˜ êµ¬ì¡°]</strong></p>

<ul>
  <li>AlexNetë³´ë‹¤ ê¹Šê³ (16, 19Layer)</li>
  <li>ë”ìš± ì‹¬í”Œí•œ êµ¬ì¡°ì´ë©°
    <ul>
      <li>Loca Response Normalization(LRN) ì‚¬ìš© ì•ˆí•¨</li>
      <li>conv filter layerì™€ max pooling layerì˜ í¬ê¸°ë¥¼ ê°ê° 3x3, 2x2ë§Œ í•œí•˜ì—¬ ì‚¬ìš©(ê°€ì¥ í° íŠ¹ì§•)
        <ul>
          <li>ì´ë¥¼ stackí•˜ì—¬ í° Receptive Sizeë¥¼ ì–»ìœ¼ë©´ì„œ ë” ê¹Šê³  ë³µì¡í•˜ë©´ì„œ íŒŒë¼ë¯¸í„° ìˆ˜ëŠ” ì¤„ì—¬ ì„±ëŠ¥ê³¼ ì •í™•ë„ë¥¼ ë™ì‹œì— ì¡ì„ ìˆ˜ ìˆë‹¤.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>ë”ìš± ì¢‹ì€ ì„±ëŠ¥ê³¼ ì¼ë°˜í™”(Generlization)ì„ ë‚´ëŠ” ëª¨ë¸</li>
</ul>

<p>ì´ì™¸ì—ëŠ” AlexNetê³¼ ë¹„ìŠ·í•˜ë‹¤.</p>

<ul>
  <li>ReLU ì‚¬ìš©,  Inputì—ì„œ 224x224 RGB ì´ë¯¸ì§€ë¥¼ Normalization(RGB í‰ê· ê°’ì„ RGB ê°’ì—ì„œ ë¹¼ì¤Œ)í•˜ì—¬ ë„£ì–´ì¤Œ</li>
</ul>

<h2 id="Annotation-data-efficient-learning">Annotation data efficient learning</h2>

<ul>
  <li>ì§ˆì¢‹ì€ ë°ì´í„°ì…‹ì€ ì„±ëŠ¥ì— í° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ë§Œ í™•ë³´í•˜ê±°ë‚˜ ë§Œë“œëŠ”ë° í° ì–´ë ¤ì›€ì´ ë”°ë¥¸ë‹¤.</li>
  <li>CVì—ì„œì˜ ë°ì´í„° ë¶€ì¡± ì™„í™” ë°©ë²•ì„ ì•Œì•„ë³´ì.</li>
</ul>

<h3 id="Data-augmentation">Data augmentation</h3>

<p>ì†ì‰½ê²Œ ë°ì´í„°ì…‹ì„ ëŠ˜ë¦´ ìˆ˜ ìˆëŠ” ë°©ë²•</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th style="text-align: center">ì—¬ëŸ¬ ë¬¼ì²´</th>
      <th style="text-align: center">ì¥ì†Œ</th>
      <th style="text-align: center">ê³µì›</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ê·¸ë¦¼</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308133559123.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308133608690.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308133615833.png" alt=""></td>
    </tr>
    <tr>
      <td>í¸í–¥</td>
      <td style="text-align: center">ê²¹ì³ ë³´ë©´ ì •ë©´ì— íŠ¹ì • ê°ë„ë¡œ ë¬¼ì²´ë“¤ì´ ìœ„ì¹˜</td>
      <td style="text-align: center">ì¥ì†Œ ì‚¬ì§„ë“¤ì„ ê²¹ì³ë³´ë©´ í•´ì•ˆì„ , ë¬¼ì²´, ê±´ë¬¼ ë“±ì˜ ìœ„ì¹˜ê°€ ê²¹ì¹¨</td>
      <td style="text-align: center">ì‚¬ëŒì„ ìœ„ì£¼ë¡œ ì°ê²Œ ë˜ì–´ ì¤‘ì•™ì— ì‚¬ëŒì´ ìœ„ì¹˜</td>
    </tr>
  </tbody>
</table>

<p><strong>[fig. í¸í–¥ì˜ ì˜ˆì‹œ]</strong></p>

<p>Datasetë“¤ì€ ì¸ê°„ì˜ í•„ìš”ì— ì˜í•´ í¸í–¥ëœ ì±„ë¡œ ì´¬ì˜ë˜ê²Œ ë˜ë©°, ì´ëŠ” í˜„ì‹¤ì˜ ë°ì´í„°ì™€ ê´´ë¦¬ë¥¼ ì¤€ë‹¤.</p>

<table>
  <thead>
    <tr>
      <th>Samples in the training set</th>
      <th>Real data distribution</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308133924729.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308133920291.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p>ì• ë§¤í•œ ë°ì´í„°ë“¤ì´ ì—¬ëŸ¬ classì™€ ê²¹ì¹˜ëŠ” ë°©ì‹ì¸ í˜„ì‹¤ ë°ì´í„°ì™€ ë‹¬ë¦¬ sample dataë“¤ì€ í™•ì‹¤í•˜ê³  ëª…í™•í•œ ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ ì´ë¡œ ì¸í•´ ëª¨ë¸ì— í˜¼ë€ì´ ì˜¬ ìˆ˜ ìˆë‹¤.</p>

<p>ì˜ˆë¥¼ ë“¤ë©´, ë§ì€ ì‚¬ëŒë“¤ì´ ë°ì€ ì¡°ëª… ì•„ë˜ì—ì„œ ì‚¬ì§„ì„ ì°ëŠ”ë‹¤, ê·¸ë¦¬ê³  ë‹¬ì€ ì–´ë‘ìš´ ë°¤í•˜ëŠ˜ì—ë§Œ ì°íŒë‹¤. ë§Œì•½ ì´ë¥¼ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµí•œ ëª¨ë¸ì´ ì–´ë‘ìš´ ê³³ì— ì°íŒ ì‚¬ëŒì„ ë³´ë©´, ë‹¬ë¡œ ì°©ê°í•  ìˆ˜ë„ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308134801650.png" alt=""></p>

<p><strong>[img. Augmenationì˜ ì˜ˆì‹œ]</strong></p>

<p>ì´ë¥¼ ë§‰ê¸°ìœ„í•´, ë°ê¸° ë°”ê¾¸ê¸°, íšŒì „, crop, ì¼ë¶€ ê°€ë¦¬ê¸°, ì±„ë„ ë³€ê²½ ë“±ì˜ ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ë°”ê¾¸ì–´ í˜„ì‹¤ ë°ì´í„°ì™€ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ë©´ì„œ ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤.</p>

<p>OpenCV, NumPy ë“±ì—ì„œ libraryë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">&nbsp;</th>
      <th style="text-align: center">&nbsp;</th>
      <th style="text-align: center">&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140744851.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140858344.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140807904.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">Rotate, Flip</td>
      <td style="text-align: center">Brightness adjustment</td>
      <td style="text-align: center">Crop</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140751671.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140824819.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308140830735.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">Rotate, Flip</td>
      <td style="text-align: center">Affine transformation</td>
      <td style="text-align: center">CutMix</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. ì—¬ëŸ¬ ì¢…ë¥˜ì˜ augmentation ì¢…ë¥˜]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">brightness_augmentation</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="c1"># numpy array img has RGB value(0~255) for each pixel
</span>    <span class="n">img</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">100</span> <span class="c1"># add 100 to R value
</span>    <span class="n">img</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">100</span> <span class="c1"># add 100 to G value
</span>    <span class="n">img</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">+</span><span class="mi">100</span> <span class="c1"># add 100 to B value
</span>    
    <span class="n">img</span><span class="p">:[:,:,</span><span class="mi">0</span><span class="p">][</span><span class="n">img</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">]</span><span class="o">&amp;</span><span class="c1">#38;#62;255] = 255 # clip R values over 255
</span>    <span class="n">img</span><span class="p">:[:,:,</span><span class="mi">1</span><span class="p">][</span><span class="n">img</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">]</span><span class="o">&amp;</span><span class="c1">#38;#62;255] = 255 # clip G values over 255
</span>    <span class="n">img</span><span class="p">:[:,:,</span><span class="mi">2</span><span class="p">][</span><span class="n">img</span><span class="p">[:,:,</span><span class="mi">2</span><span class="p">]</span><span class="o">&amp;</span><span class="c1">#38;#62;255] = 255 # clip B values over 255
</span>    <span class="k">return</span> <span class="n">img</span>

</code></pre></div></div>
<p><strong>[code. ë°ê¸° ì¡°ì ˆ Augmentation ì½”ë“œ]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">img_rotated</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">ROTATE_90_CLOCKWISE</span><span class="p">)</span>
<span class="n">img_flipped</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">ROTATE_180</span><span class="p">)</span>

</code></pre></div></div>
<p><strong>[code. íšŒì „, ë’¤ì§‘ê¸° Augmentation ì½”ë“œ]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_start</span> <span class="o">=</span> <span class="mi">500</span> <span class="c1"># y pixel to start cropping
</span><span class="n">crop_y_size</span> <span class="o">=</span> <span class="mi">400</span> <span class="c1"># cropped image&amp;#39;s height
</span><span class="n">x_start</span> <span class="o">=</span> <span class="mi">300</span> <span class="c1"># x_pixel to start cropping
</span><span class="n">crop_x_size</span> <span class="o">=</span> <span class="mi">800</span> <span class="c1"># cropped image&amp;#39;s width
</span><span class="n">img_cropped</span> <span class="o">=</span> <span class="n">image</span><span class="p">[</span><span class="n">y_start</span><span class="p">:</span><span class="n">y_start</span><span class="o">+</span><span class="n">crop_y_size</span><span class="p">,</span> <span class="n">x_start</span> <span class="p">:</span> <span class="n">x_start</span> <span class="o">+</span> <span class="n">crop_x_size</span><span class="p">,</span> <span class="p">:]</span>

</code></pre></div></div>
<p><strong>[code. Crop Augmentation ì½”ë“œ]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">ch</span> <span class="o">=</span> <span class="n">image</span><span class="p">.</span><span class="n">shape</span>
<span class="n">pts1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">([[</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">],[</span><span class="mi">200</span><span class="p">,</span><span class="mi">50</span><span class="p">],[</span><span class="mi">50</span><span class="p">,</span><span class="mi">200</span><span class="p">]])</span>
<span class="n">pts2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">([[</span><span class="mi">10</span><span class="p">,</span><span class="mi">100</span><span class="p">],[</span><span class="mi">200</span><span class="p">,</span><span class="mi">50</span><span class="p">],[</span><span class="mi">100</span><span class="p">,</span><span class="mi">250</span><span class="p">]])</span>
<span class="n">M</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">getAffineTransform</span><span class="p">(</span><span class="n">pts1</span><span class="p">,</span> <span class="n">pts2</span><span class="p">)</span>
<span class="n">shear_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">warpAffine</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="p">(</span><span class="n">cols</span><span class="p">,</span><span class="n">rows</span><span class="p">))</span>

</code></pre></div></div>
<p><strong>[code. Affine Transformation Augmentation]</strong></p>

<p>Affine Transformation : ì‚¬ê°í˜• ì´ë¯¸ì§€ë¥¼, ê¸°ìš¸ì–´ì§„ í‰í–‰ ì‚¬ë³€í˜•(parallelogram)ì˜ í˜•íƒœë¡œ ë°”ê¿ˆ + rotation í•¨</p>

<ul>
  <li>shear transformation ì´ë¼ê³ ë„ í•¨</li>
</ul>

<p>RandAugment</p>

<ul>
  <li>Augmenationì˜ ì¢…ë¥˜, ê°•ë„(ì–¼ë§ˆë‚˜ ë°ì€ê°€, ì–¼ë§ˆë‚˜ ê¸°ìš¸ì–´ì¡ŒëŠ”ê°€ ë“±)ì— ë”°ë¼ ëª¨ë¸ ì„±ëŠ¥ì´ ë‹¬ë¼ì§€ë¯€ë¡œ, ì´ë¥¼ parameterë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.</li>
  <li>ëœë¤ìœ¼ë¡œ Augmentationì„ ì ìš©í•œ ë’¤, í‰ê°€í•˜ëŠ” ê³¼ì •ì„ ê±°ì¹¨</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308144014875.png" alt=""></p>

<p><strong>[img. ShearX &amp; AutoContrast 9 Randaug ì˜ˆì‹œ]</strong></p>

<ul>
  <li>ì ìš©í•  Augmentation, ì ìš© ê°•ë„, 2ê°€ì§€ê°€ Parameterë¡œ ì ìš©</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308144310891.png" alt=""></p>

<p><strong>[img. RandAugmentation ì‚¬ìš©ì— ì˜í•œ ì„±ëŠ¥ í–¥ìƒ]</strong></p>

<h3 id="Leveraging-pre-trained-information">Leveraging pre-trained information</h3>
<p>pre-trained ëœ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” ë°©ë²•</p>

<h4 id="Transfer-learning">Transfer learning</h4>

<p>Transfer learning: í•œ ë°ì´í„°ì…‹ì—ì„œ ë°°ìš´ ì§€ì‹ì„ ë‹¤ë¥¸ ë°ì´í„°ì…‹, ë‹¤ë¥¸ Taskì—ì„œ í™œìš©í•˜ëŠ” ê¸°ìˆ </p>

<ul>
  <li>ì´ë¥¼ í†µí•˜ì—¬ ì‘ì€ ë°ì´í„°ì…‹ìœ¼ë¡œë„ ë†’ì€ ì •í™•ë„ë¥¼ ìë‘í•œë‹¤.</li>
</ul>

<ol>
  <li>Transfer knowledge from a pre-trained task to a new task(ê°™ì€ Layer, ë‹¤ë¥¸ Taskì— í™œìš©)</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308153411813.png" alt=""></p>

<p><strong>[img. Transfer model(ì¢Œ)ë¥¼ ì›í•˜ëŠ” ì—…ë¬´ì— ë§ê²Œ FCLì„ ë³€ê²½]</strong></p>

<ul>
  <li>ë§ˆì§€ë§‰ Fully connected Layerë§Œ ë°”ê¾¼ ë’¤, ì´ì „ Convolution Layerì˜ WeightëŠ” ê·¸ëŒ€ë¡œ ë‘”ì±„ ë°”ê¾¼ ì¸µë§Œ í•™ìŠµ ì‹œì¼œ í™œìš©í•˜ëŠ” ë°©ë²•</li>
  <li>pre-trained ëª¨ë¸ì˜ featureê°€ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨</li>
</ul>

<ol>
  <li>Fine-tuning the whole model</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308153626775.png" alt=""></p>

<p><strong>[img. FCLì„ ë³€ê²½ í›„ Convolution Layerë„ Low lrë¡œ í•™ìŠµ]</strong></p>

<ul>
  <li>ë§ˆì§€ë§‰ ì¸µì„ ë°”ê¾¼ ë’¤, ê¸°ì¡´ ì¸µì€ ë‚®ì€ Learnig rate, ìƒˆë¡œìš´ ì¸µì€ High learning rateë¥¼ ìœ ì§€í•˜ë©° í•™ìŠµ</li>
  <li>ìì‹ ì˜ Taskì— ë§ê²Œ ê¸°ì¡´ ëª¨ë¸ì„ ì¡°ê¸ˆ ìˆ˜ì •ê°€ëŠ¥</li>
</ul>

<h4 id="Knowledge-distillation">Knowledge distillation</h4>

<p>pre-trained ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ í™œìš©í•´ ë‹¤ë¥¸ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•</p>

<p>Teacher-student learning</p>

<p>ë³´í†µ ë‘ê°€ì§€ ëª©ì ìœ¼ë¡œ ì“°ì„</p>

<ol>
  <li>ë” ê²½ëŸ‰í™”ëœ ëª¨ë¸ì„ ë§Œë“¤ì–´, ê¸°ì¡´ ëª¨ë¸ ë³´ë‹¤ ê²½ëŸ‰í™”ì— ì‚¬ìš©</li>
  <li>unlabeld datasetì˜ pseudo-labellingì— ì‚¬ìš©(ë ˆì´ë¸”ë§ ì•ˆëœ ë°ì´í„°ì…‹ì— ë¼ë²¨ë§)</li>
</ol>

<p>í•™ìŠµ êµ¬ì¡°ì— ë”°ë¼ 2ê°€ì§€ë¡œ ë‚˜ë‰œë‹¤.</p>

<ol>
  <li>Teacher-student network structure</li>
</ol>

<ul>
  <li>student ëª¨ë¸(ë³´í†µ, Teacher Modelë³´ë‹¤ ê²½ëŸ‰í™”ë˜ì–´ ìˆë‹¤.)ì´ Teacher ëª¨ë¸ì˜ outputì„ ë”°ë¼í•˜ê²Œë” í•™ìŠµì‹œí‚´</li>
  <li>Unsupervised learningìœ¼ë¡œ, label ë˜ì§€ ì•Šì€ datasetì„ ì‚¬ìš©í•œë‹¤.</li>
  <li>ë‘ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ KL divergence Lossë¥¼ í†µí•´ Loss ê°’ì„ êµ¬í•œë’¤, student modelë¡œë§Œ backpropagationì´ ì§„í–‰ë˜ê²Œ ëœë‹¤.
    <ul>
      <li>KL div Loss: 2ê°œì˜ ë¶„í¬ì˜ ê±°ë¦¬(=ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œê°€)ë¥¼ ì¸¡ì •</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308155338677.png" alt=""></p>

<p><strong>[img. Teacher-student network structure]</strong></p>

<ol>
  <li>Knowledge distillation</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308155357681.png" alt=""></p>

<p><strong>[img. Knowledge distillation structure]</strong></p>

<ul>
  <li>Labeledëœ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•  ë•Œ ì‚¬ìš©í•˜ëŠ” êµ¬ì¡°</li>
  <li>Student Modelê³¼ Teacher Modelì˜ ì°¨ì´ë¥¼ Distillation Loss, Student Modelê³¼ Ground Truth(Label)ê³¼ì˜ ì°¨ì´ë¥¼ Student  Lossë¼ ì •ì˜ í•œë‹¤.</li>
  <li>ì´ë•Œ Student ëª¨ë¸ì€ Soft labelì„ ì´ìš©í•œ Soft Predictionì„ ì´ìš©í•œë‹¤.
    <ul>
      <li>Hard label(One-hot vector) : datasetì˜ labelê°’ì²˜ëŸ¼, í•˜ë‚˜ì˜ ëª…í™•í•œ ì •ë‹µì„ ê°€ì§</li>
      <li>Soft label: modelì˜ softmaxë¥¼ í†µê³¼í•œ ë’¤ ê¸°ë³¸ ì¶œë ¥ê°’, ì—¬ëŸ¬ ì •ë‹µì— float ê°’ì„ ê°€ì§€ëŠ” ê°€ì¤‘ì¹˜ê°™ì€ í˜•íƒœ</li>
      <li>ì´ë¥¼ ì´ìš©í•´ ë‹¨ìˆœ ì •ë‹µì´ ì•„ë‹Œ, ì–´ëŠ ì •ë„ë¡œ ì •ë‹µì— ê·¼ì ‘í–ˆëŠ”ê°€ ë“±ì˜ ì¶”ê°€ì ì¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.</li>
    </ul>
  </li>
</ul>

<p>\(Hard\ label:\begin{pmatrix}Bear\\Cat\\Dog\end{pmatrix}=\begin{pmatrix}0\\1\\0\end{pmatrix}\\
Soft\ label:\begin{pmatrix}Bear\\Cat\\Dog\end{pmatrix}=\begin{pmatrix}0.14\\0.8\\0.06\end{pmatrix}\)<br>
<strong>[math. Hard labelê³¼ Soft labelì˜ ì˜ˆì‹œ]</strong></p>

<ul>
  <li>ë˜í•œ Knowledge distilationì—ì„œì˜ Distillation Lossë¥¼ êµ¬í•  ë•Œ, Softmax í•¨ìˆ˜ì— temperature(T)ë¥¼ ì´ìš©í•˜ì—¬ ê¸°ì¡´ì˜ outputë³´ë‹¤ Smoothingí•œ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
    <ul>
      <li>ì´ë¥¼ ì´ìš©í•´ ì¢€ë” ê²°ê³¼ê°’ì— ë§ì€ ì •ë³´ë¥¼ í¬í•¨í•  ìˆ˜ ìˆë‹¤.</li>
      <li>ì˜ˆë¥¼ ë“¤ì–´ ê¸°ì¡´ì˜ softmax(5,10) = (0.0067, 0.9933)ì´ë¼ë©´</li>
      <li>t=100ì¸ softmax(5,10) = ( 0.4875, 0.5125)ë¡œ ë¹„ìŠ·í•œ ê°’ì„ smoothing ëœë‹¤.</li>
      <li>ì „ìì˜ ê²°ê³¼ì˜ 0,0067ì€ ë¬´ì‹œë  ì •ë„ë¡œ ì‘ì€ ì •ë³´ì§€ë§Œ í›„ìì˜ ê²½ìš°ëŠ” ë¬´ì‹œëª»í•  ì •ë³´ê°€ ëœë‹¤.</li>
    </ul>
  </li>
</ul>

<p>\(Normal\ Softmax(=Hard\ Prediction):\frac{\exp(z_i)}{\sum_j\exp(z_j)}\\
Softmax\ with\ temperature\ T(=Soft\ Prediction):\frac{\exp(z_i/T)}{\sum_j\exp(z_j/T)}\)<br>
<strong>[math. softmax with temperature]</strong></p>

<ul>
  <li>Distillation Lossë¥¼ êµ¬í•  ë•Œ, Teacher Modelì˜ soft Labelì˜ ì„¸ë¶€ì •ë³´(Semantic information)ì€ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.
    <ul>
      <li>êµìœ¡ë°›ê³  ë°”ê¿”ì•¼í•  ëª¨ë¸ì€ Student Model ì´ê¸° ë•Œë¬¸ì—</li>
    </ul>
  </li>
</ul>

<p>Distillation Lossì˜ ê²½ìš°, Teacher model vs Student modelì˜ ì°¨ì´ë¥¼ ì˜ë¯¸</p>

<ul>
  <li>KL divergence loss ì‚¬ìš©: ë¹„êµ í•˜ëŠ” ë‘ ê°’ì´ 0~1ì‚¬ì´ì˜ ê°’ë“¤ì˜ ë¶„í¬ì´ë¯€ë¡œ</li>
</ul>

<p>Student Lossì˜ ê²½ìš°, ì‹¤ì œ ë‹µê³¼ student modelì˜ ì •ë‹µì„ ë¹„êµ</p>

<ul>
  <li>CrossEntropy ì‚¬ìš©: True labelì˜ ê²½ìš° one-hot vector í˜•íƒœì´ë¯€ë¡œ</li>
</ul>

<p>ë§ˆì§€ë§‰ìœ¼ë¡œ ìœ„ì—ì„œ êµ¬í•œ ë‘ lossë“¤ì˜ ê°€ì¤‘ì¹˜ í•©ì„ í†µí•´ lossë¥¼ êµ¬í•œ ë’¤, student modelë§Œ, Backpropationì„ í•œë‹¤.</p>

<h3 id="Leveraging-unlabled-dataset-for-training">Leveraging unlabled dataset for training</h3>

<h4 id="Semi-supervised-learning">Semi-supervised learning</h4>

<ul>
  <li>labeledëœ ì ì€ ìˆ˜ì˜ ë°ì´í„°ì™€, labelë˜ì§€ ì•Šì€ ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ë°©ë²•
    <ul>
      <li>ì¦‰ unsupervised + Fully supervised = semi-supervised</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308224613244.png" alt=""></p>

<p>1) ë ˆì´ë¸”ë§ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ í˜•ì„±</p>

<p>2) í˜•ì„±ëœ ëª¨ë¸ë¡œ ë ˆì´ë¸”ë§ë˜ì§€ ì•Šì€ ë°ì´í„°ì…‹ ë ˆì´ë¸”ë§</p>

<p>3) ê·¸ë ‡ê²Œ ë ˆì´ë¸”ë§ëœ ë°ì´í„°ì…‹ê³¼ ê¸°ì¡´ì˜ ë¼ë²¨ë§ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ìƒˆë¡œìš´ ëª¨ë¸ í˜•ì„±</p>

<h4 id="Self-training">Self-training</h4>

<p>ì•ì„œ ë°°ì› ë˜ Data Augmentation, Knowledge distillation, Semi-supervised learningì„ ì´ìš©í•œ ë°©ë²•</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308224943394.png" alt=""></p>

<p><strong>[img. self-trainingì˜ ë‹¨ê³„]</strong></p>

<ol>
  <li>lableëœ ë°ì´í„°ì…‹ìœ¼ë¡œ Teacher modelì„ í˜•ì„±í•œë‹¤.</li>
  <li>í•´ë‹¹ Teacher modelë¡œ unlabledëœ modelì„ Pseudo-labeled dataë¡œ ë§Œë“ ë‹¤.</li>
  <li>lableëœ ë°ì´í„°ì…‹ + pseudo-lableëœ ë°ì´í„°ì…‹ì„ augmentation í•œ ê²ƒì„ í†µí•˜ì—¬ ìƒˆë¡œìš´ Teacher modelì„ í˜•ì„±í•œë‹¤
    <ul>
      <li>ì´ë•Œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” augmentation  ë°©ë²•ì´ RandAugment</li>
    </ul>
  </li>
  <li>ìƒˆë¡œ í˜•ì„±ëœ Teacher ëª¨ë¸ë¡œ 2ë²ˆë¶€í„° 4ë²ˆê¹Œì§€ ë°˜ë³µí•œë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210308225809995.png" alt=""></p>

<p><strong>[img. ì••ë„ì ì¸ ì„±ëŠ¥ì„ ìë‘í•˜ëŠ” self-training ëª¨ë¸(ë¹¨ê°„ìƒ‰)]</strong></p>

<h2 id="Image-classification-2">Image classification 2</h2>

<h3 id="Problems-with-deeper-layers">Problems with deeper layers</h3>

<p>ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ ë”¥ëŸ¬ë‹ layerì˜ ì¸µì„ ë†’ê²Œ ìŒ“ìœ¼ë©´ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¬¸ì œê°€ ìƒê²¼ë‹¤</p>

<ol>
  <li>Gradient vanishing/exploding ë¬¸ì œ</li>
  <li>Computationaly complex</li>
  <li>í•œë•Œ overfitting ë¬¸ì œë¡œ ì°©ê°í–ˆë˜ Degradation problem</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309100228831.png" alt=""></p>

<p><strong>[img. Vanishing gradient ë¬¸ì œì˜ ë„ì‹]</strong></p>

<h3 id="CNN-architectures-for-image-classification-2">CNN architectures for image classification 2</h3>

<h4 id="GoogLeNet">GoogLeNet</h4>

<p>2015ë…„ì— ë°œí‘œëœ Inception ëª¨ë“ˆì„ í™œìš©í•œ CV ëª¨ë¸</p>

<p>Inception moduleì´ë€?</p>

<ul>
  <li>
    <p>ì´ì „ ì¸µì—ì„œì˜ ê²°ê³¼ê°’ì— ì—¬ëŸ¬ê°œì˜ í•„í„°ë¥¼ ì ìš©í•œ ë’¤, Concatenateí•˜ëŠ” layer</p>

    <ul>
      <li>1x1, 3x3, 5x5 Convolution filter, 3x3 max pooling layerë¥¼ ì ìš©</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309112126930.png" alt=""></p>

<p><strong>[img. Inception moduleì˜ ì˜ˆì‹œ]</strong></p>

<p>ì´ë•Œ, ì—¬ëŸ¬ í•„í„°ì˜ ì ìš©ì— ì˜í•´ parameterìˆ˜ê°€ ì¦ê°€í•˜ì, 1x1 convolution layer(Bottleneck layer)ì„ ì¶”ê°€í•˜ì—¬ íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ì¤„ì´ëŠ” ì‹œë„ë¥¼ í•¨</p>

<ul>
  <li>ìš°ì¸¡ì˜ Dimension Reduced versionì— ì¶”ê°€ëœ 1x1 convolution layerë¥¼ ì˜ë¯¸</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309112308655.png" alt=""></p>

<p><strong>[img. 1x1 convolution layerì˜ ì—°ì‚° ê²°ê³¼]</strong></p>

<p>GoogLeNetì˜ ì „ì²´ì ì¸ êµ¬ì¡°ë¥¼ ì‚´í´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<ol>
  <li>Stem network: ê¸°ë³¸ì ì¸ convolution network</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309115934238.png" alt=""></p>

<p><strong>[img. Stem network ë¶€ë¶„]</strong></p>

<ol>
  <li>Stacked inception modules: ìœ„ì— ì„¤ëª…í•œ Inception ëª¨ë“ˆì„ ìŒ“ì•„ë†“ì€ ë¶€ë¶„</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309120018533.png" alt=""></p>

<p><strong>[img. Stacked inception modules ë¶€ë¶„]</strong></p>

<ol>
  <li>Auxiliary classifiers</li>
</ol>

<ul>
  <li>Vanishing gradient ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë¶€ë¶„</li>
  <li>ì¤‘ê°„ì˜ ê²°ê³¼ê°’ì„ í•œë²ˆ ì˜ˆì¸¡ê°’ìœ¼ë¡œ ì‚¼ê³ , loss ê°’ì„ ê³„ì‚°í•˜ì—¬ ì¤‘ê°„ë¶€í„° backpropagationì„ ì§„í–‰í•œë‹¤</li>
  <li>trainingì—ì„œë§Œ ì‚¬ìš©í•˜ê³  testing ë‹¨ê³„ì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309120037565.png" alt=""></p>

<p><strong>[img. Auxiliary classifiers ë¶€ë¶„]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309120621091.png" alt=""></p>

<p><strong>[img. ë”ìš± ìì„¸í•œ Auxiliary classifier]</strong></p>

<h4 id="ResNet">ResNet</h4>

<p>í˜„ì¬ê¹Œì§€ ê¸°ë³¸ backboneìœ¼ë¡œ ì“°ì´ê³¤ í•˜ëŠ” ì¢‹ì€ ëª¨ë¸</p>

<ul>
  <li>ìµœì´ˆë¡œ ì¸ê°„ ë³´ë‹¤ ë‚˜ì€ ì„±ëŠ¥ì„ ë‹¬ì„±(ì—ëŸ¬ìœ¨ ê¸°ì¤€)</li>
  <li>ê¸°ì¡´ì˜ ëª¨ë¸ë³´ë‹¤ ì••ë„ì ìœ¼ë¡œ ê¹Šì€ ì¸µì˜ ê°¯ìˆ˜(152 Layer)</li>
</ul>

<p>ê¸°ì¡´ì˜ ì—°êµ¬ì—ì„œëŠ” ì¸µì´ ê¹Šì„ ìˆ˜ë¡ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ë¬¸ì œë¥¼ Overfitting ë¬¸ì œë¼ê³  ì˜¤íŒí•˜ì˜€ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309122016623.png" alt=""></p>

<p><strong>[img. ì¸µì˜ ê°¯ìˆ˜ì— ë”°ë¥¸ ì—ëŸ¬ìœ¨, ë†’ì„ ìˆ˜ë¡ ì•ˆì¢‹ìŒ]</strong></p>

<p>Overfittingì˜ ë¬¸ì œì˜€ë‹¤ë©´, training errorëŠ” ì ì  ë‚˜ì•„ì ¸ì•¼í•˜ê³ , test errorê°€ ë‚˜ë¹ ì ¸ì•¼ í•˜ì§€ë§Œ, ë‘˜ë‹¤ ì„±ëŠ¥ì´ ë‚˜ë¹ ì¡Œê¸° ë•Œë¬¸ì´ë‹¤.</p>

<p>ë”°ë¼ì„œ Resnetì—ì„œëŠ” ì´ë¥¼ Overfittingì´ ì•„ë‹Œ Optimization(ìµœì í™”)ì˜ ë¬¸ì œë¼ê³  ë³´ì•˜ë‹¤.</p>

<p>ResNetì˜ ì—°êµ¬ ê°€ì„¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309123313947.png" alt=""></p>

<p><strong>[img. Residual blockê³¼ Plain layerì˜ ì°¨ì´]</strong></p>

<p>ê¸°ì¡´ì˜ Plain layerì˜ ê²½ìš° ì¸µì´ ê¹Šì–´ì§ˆ ìˆ˜ë¡ ë³µì¡í•´ì§„ H(x)ì— Xë¥¼ ë³´ì¡´í•˜ë©´ì„œ í•™ìŠµí•˜ê¸° í˜ë“¤ì—ˆë‹¤.</p>

<p>í•˜ì§€ë§Œ Residual blockì—ì„œëŠ” identity Xë¥¼ F(X)ì— ë”í•œ ê²ƒì„ H(X)ë¡œ ì‚¼ìœ¼ë©´ì„œ, Xì˜ ì •ì²´ì„±ì´ ëšœë ·íˆ ë‚¨ì€ ìƒíƒœì—ì„œ, ë¶„í• ì •ë³µ í†µí•´ ìµœì í™”ëœ í•™ìŠµì„ í•  ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>ë¶„í• ì •ë³µ-&gt; (F(x), Xì˜ weightë¥¼ ë”°ë¡œ êµ¬í•´ì„œ ë”í•˜ë©´ ë˜ë‹ˆê¹Œ?)</li>
  <li>Target function : $H(x)=F(x)+x$</li>
  <li>Residual function : $F(x)=H(x)-x$</li>
</ul>

<p>ì´ë¥¼ ìœ„í•´ <em>Shortcut connection ë˜ëŠ” Skip connection</em>ì„ í†µí•´ xë¥¼ layerì„ ë„˜ì–´ ë”í•´ì£¼ì–´ Backpropagation ì‹œ ë›°ì–´ë„˜ì–´ gradeintë¥¼ êµ¬í•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤.</p>

<ul>
  <li>ì´ë¥¼ í†µí•´ Gradient vanishing ë¬¸ì œë¥¼ í•´ê²°í•¨</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Residual êµ¬ì¡°</th>
      <th style="text-align: center">ê²½ë¡œë¥¼ í’€ì–´ë³¸ êµ¬ì¡°</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309124015987.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309124032924.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[img. ê°™ì€ Residual êµ¬ì¡°ì˜ ê²½ë¡œ í’€ì´]</strong></p>

<p>ì´ë¡ ìƒ, Residual êµ¬ì¡°ë¥¼ í†µí•˜ì—¬ ìƒê¸°ëŠ” ê²½ë¡œëŠ” ì¸µì´ ê¹Šì´ nì— ë”°ë¼ $O(2^n)$ê°œ ë§Œí¼ ì¦ê°€í•œë‹¤.</p>

<p>ì´ ê²½ë¡œë¥¼ í†µí•´ backpropagationì´ ê°€ëŠ¥í•˜ë¯€ë¡œ ë³µì¡í•œ í•™ìŠµì„ í•´ê²° ê°€ëŠ¥í•˜ë‹¤.</p>

<p>ResNetì˜ ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<ol>
  <li>He initialization conv layer</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309130058413.png" alt=""></p>

<p><strong>[img. Resnetì˜ ì²« ì‹œì‘ ë¶€ë¶„]</strong></p>

<ul>
  <li>ì²« layerì˜ outputì€ ì•ìœ¼ë¡œ ê³„ì† identity connectionì„ í†µí•˜ì—¬ ë”í•´ì§ˆ ê²ƒì´ë¯€ë¡œ, ìµœì í™”ë¥¼ ìœ„í•´ ë‹¨ìˆœí•˜ê³  ì‘ì€ í¬ê¸°ì˜ outputì„ ë‚´ë†“ì•„ì•¼ í•œë‹¤.</li>
  <li>ë”°ë¼ì„œ He initializationì´ë¼ëŠ” ê°„ë‹¨í•˜ê³  ResNetì„ ìœ„í•´ ê³ ì•ˆëœ initializationì„ ì´ìš©í•œë‹¤.</li>
</ul>

<ol>
  <li>Stacked residual blocks ë¶€ë¶„</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309130304826.png" alt=""></p>

<p><strong>[img. Stack residual blocks]</strong></p>

<ul>
  <li>ëª¨ë‘ 3x3 conv layerë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, Batch normalizationì´ ë§¤ layer ëì— ì´ë£¨ì–´ì§„ë‹¤</li>
  <li>ì¼ì • ë¸”ë¡ ì´í›„(ìƒ‰ì´ ë°”ë€ŒëŠ” ë¶€ë¶„), ì±„ë„ ìˆ˜ëŠ” 2ë°°ë¡œ ëŠ˜ë¦¬ê³ , ì±„ë„ í•´ìƒë„ëŠ” strideë¥¼ 2ë¡œ ì¡ì•„ ì¤„ì´ëŠ” êµ¬ê°„ì´ ì¡´ì¬í•¨</li>
</ul>

<ol>
  <li>Output FC layer</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309130815026.png" alt=""></p>

<p><strong>[img. Sing FC layer]</strong></p>

<ul>
  <li>í•˜ë‚˜ì˜ average poolingê³¼  Fully connected layerì„ í†µí•˜ì—¬ classficationì„ ì§„í–‰</li>
</ul>

<p><strong>ResNet ì½”ë“œ</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309214256499.png" alt=""></p>

<p><strong>[img. ResNet code stack ìˆ˜ ì •ì˜ ë¶€ë¶„ ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309214240250.png" alt=""></p>

<p><strong>[img. ResNet code ì²«ì‹œì‘, He initialization ë¶€ë¶„ ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309214221377.png" alt=""></p>

<p><strong>[img. ResNet code, stacked residual ë¶€ë¶„ ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309214208739.png" alt=""></p>

<p><strong>[img. ResNet code, Layer ìƒì„± ì½”ë“œ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309214151827.png" alt=""></p>

<p><strong>[img. ResNet code, ë§ˆì§€ë§‰ FCì¸µ ë¶€ë¶„]</strong></p>

<h4 id="Beyond-ResNets">Beyond ResNets</h4>

<ol>
  <li>DenseNet</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309135815464.png" alt=""></p>

<p><strong>[img. DenseNet ì´ë¯¸ì§€]</strong></p>

<ul>
  <li>ResNetê³¼ ë‹¬ë¦¬ layerì˜ outputì´ ì´í›„ì˜ ëª¨ë“  layerì˜ ê²°ê³¼ê°’ì— Channel ì¶•ì„ ì¤‘ì‹¬ìœ¼ë¡œ Concatenateë˜ì„œ í•©í•´ì§„ë‹¤.</li>
  <li>Cocatenateí•˜ë¯€ë¡œ ê¸°ì¡´ì˜ ê°’ë“¤ì´ ë³´ì¡´ëœë‹¤
    <ol>
      <li>SENet</li>
    </ol>
  </li>
  <li>Activationì˜ ê²°ê³¼ê°€ ëª…í™•í•´ì§€ë„ë¡ ouputì˜ ì±„ë„ì¶•ì— ê°€ì¤‘ì¹˜ë¥¼ ì£¼ëŠ” Attention across channel ë°©ì‹</li>
  <li>featureì˜ ì¤‘ìš”ë„ì™€ ê´€ê³„ê°€ ëª…í™•í•´ì§</li>
  <li>Squeeze: global average poolingì„ í†µí•˜ì—¬ ì±„ë„ì˜ ê³µê°„ì •ë³´ë¥¼ ì—†ì• ê³ (ì¶•ì˜ ì •ë³´ ë“±) ë¶„í¬ë¥¼ êµ¬í•¨</li>
  <li>Excitation: FC layer í•˜ë‚˜ë¡œ ì±„ë„ê°„ì˜ ì—°ê´€ì„±(Weight=attention score)ë¥¼ êµ¬í•¨</li>
  <li>ì¤‘ìš”ë„ê°€ ë–¨ì–´ì§€ë©´ 0ì— ê°€ê¹ê²Œ ì¤‘ìš”í•œ ê²ƒì€ í¬ê²Œ í•˜ì—¬ featureì˜ ê°•ì¡°ì™€ ë¬´ì‹œë¥¼ í•¨
    <ol>
      <li>EfficientNet</li>
    </ol>
  </li>
  <li>ê¸°ì¡´ì˜ Network ì•Œê³ ë¦¬ì¦˜ì„ ì •ë¦¬í•¨</li>
</ul>

<table>
  <thead>
    <tr>
      <th>ê¸°ë³¸ Network</th>
      <th>Width Scailing</th>
      <th>Depth Scailing</th>
      <th>Resolution Scaling</th>
      <th>Compound Scailing</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309140728124.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309140741008.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309140753841.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309140806358.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309140821739.png" alt=""></td>
    </tr>
    <tr>
      <td>ê¸°ì¤€</td>
      <td>ì±„ë„ì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ë°©ì‹</td>
      <td>ì¸µì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ëŠ” ë°©ì‹</td>
      <td>Inputì˜ í•´ìƒë„ë¥¼ ë†’ê²Œ ì£¼ëŠ” ë°©ì‹</td>
      <td>ì•ì˜ ë°©ë²•ë“¤ì„ ë³µí•©í•œ ë°©ì‹</td>
    </tr>
    <tr>
      <td>_</td>
      <td>GoogLeNet ë“±</td>
      <td>DenseNet ë“±</td>
      <td>_</td>
      <td>EfficientNet</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. ê¸°ì¡´ì˜ Networkì˜ ë¶„ë¥˜]</strong></p>

<ul>
  <li>
    <p>ê° Scailingë“¤ì€ íŒŒë¼ë¯¸í„° ìˆ˜, í•™ìŠµ epoch, ë°ì´í„°ì…‹ì˜ ìˆ˜ì— ë”°ë¼ ì„±ëŠ¥ì´ ì˜¤ë¥´ì§€ì•ŠëŠ” êµ¬ê°„ì´ ë‚˜ì˜¤ëŠ”ë°(saturation), ì´ë¥¼ ëª¨ë‘ íŒ©í„°(ì–´ëŠ ì •ë„ ë¹„ìœ¨ë¡œ ë³µí•©í•˜ëŠ”ê°€)ë¥¼ ì£¼ê³  ë³µí•©í•˜ì—¬ ì„±ëŠ¥ì„ í¬ê²Œ ìƒìŠ¹ì‹œí‚´</p>
  </li>
  <li>
    <p>ì‚¬ëŒì´ ì°¾ì€ íš¨ìœ¨ì ì¸ ë‹¤ë¥¸ êµ¬ì¡°ë“¤, NAS ì•Œê³ ë¦¬ì¦˜ êµ¬ì¡°(Neural Architecture Search, ì»´í“¨í„°ê°€ íš¨ìœ¨ì ì¸ êµ¬ì¡°ë¥¼ ì°¾ëŠ” ì•Œê³ ë¦¬ì¦˜)ë³´ë‹¤ ì„±ëŠ¥ì´ ì••ë„ì ìœ¼ë¡œ ì¢‹ë‹¤.</p>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309141007253.png" alt=""></p>

<ul>
  <li>ì ì€ ì—°ì‚°ìœ¼ë¡œë„ ì„±ëŠ¥ì´ í¬ê²Œ ì˜¬ë¼ EfficientNetì´ë‹¤.</li>
</ul>

<ol>
  <li>Deformable convolution</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309141016999.png" alt=""></p>

<ul>
  <li>ë™ë¬¼, ì‚¬ëŒ, ë“±ì˜ í˜•íƒœê°€ ë³€í•  ìˆ˜ ìˆëŠ” ì‚¬ë¬¼ì— íš¨ìœ¨ì ì¸ êµ¬ì¡°</li>
  <li>featureë¥¼ ë‚˜íƒ€ë‚´ëŠ” weightì™€, ì´ weightì˜ ìœ„ì¹˜ë¥¼ ì–´ë– í•œ ë°©í–¥ìœ¼ë¡œ, ì–´ë–»ê²Œ ë³€í˜•ì‹œí‚¬ ì§€ ê²°ì •í•˜ëŠ” offsetsë¥¼ í•™ìŠµí•˜ëŠ” í˜•ì‹</li>
  <li>ê¸°ì¡´ì˜ ì •ì‚¬ê°í˜• í˜•íƒœì˜ Receptive fieldì™€ ë‹¬ë¦¬ ë¬¼ì²´ì˜ í˜•íƒœì— ë”°ë¼ì„œ Receptive field ëª¨ì–‘ì´ ë³€í•¨</li>
</ul>

<h3 id="Summary-of-image-classification">Summary of image classification</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309142638948.png" alt=""></p>

<p><strong>[img. ì•ì„œ ë°°ìš´ ëª¨ë¸ë“¤ì˜ ë¹„êµ, ë©´ì ì€ ëª¨ë¸ì˜ í¬ê¸°]</strong></p>

<ul>
  <li>AlexNetì€ ì‹¬í”Œí•˜ì§€ë§Œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í¬ê³  ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤</li>
  <li>VGGNetì€ ì„±ëŠ¥ì´ ë‚«ì§€ë§Œ ë©”ëª¨ë¦¬ì™€ ì—°ì‚°ì„ ë§ì´ ì¡ì•„ ë¨¹ëŠ”ë‹¤</li>
  <li>GoogLeNetì˜ ìµœì‹  êµ¬ì¡°ëŠ” í¬ê¸°ë„ ì ê³  ì„±ëŠ¥ë„ ì¢‹ì§€ë§Œ, êµ¬ì¡°ê°€ ë³µì¡í•˜ë‹¤</li>
  <li>ResNetì€ íŠ¹ì¶œë‚œ ê²ƒì´ ì—†ë‹¤</li>
  <li>GoogLeNetì´ ì—¬ëŸ¬ëª¨ë¡œ ì¢‹ì§€ë§Œ êµ¬ì¡°ê°€ ë„ˆë¬´ ë³µì¡í•˜ì—¬ VGGNet, ResNetì„ ê¸°ë³¸ ëª¨ë¸ë¡œ ë§ì´ ì‚¬ìš©í•œë‹¤.</li>
</ul>

<h2 id="Semantic-segmentation">Semantic segmentation</h2>

<h3 id="Semantic-segmentation">Semantic segmentation</h3>

<p>ì´ë¯¸ì§€ ê° í”½ì…€ì˜ ì–´ë– í•œ categoryì— ì†í•˜ëŠ”ì§€ êµ¬ë¶„í•˜ëŠ” ë¬¸ì œ(ex) ì‚¬ëŒ ì˜ì—­, ìë™ì°¨ ì˜ì—­)</p>

<p>ê°™ì€ classì˜ ë‹¤ë¥¸ instanceì—ëŠ” ê´€ê³„ê°€ ì—†ìœ¼ë©° ì´ë¥¼ ìœ„í•œ instance segmentationê°€ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309155939051.png" alt=""><br>
<strong>[img. Semantic segmentationì˜ ì˜ˆì‹œ]</strong></p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309155947015.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309155953911.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[table. ì˜ë£Œ ì‚¬ì§„, ììœ¨ ì£¼í–‰, ì˜ìƒ í•©ì„± ë“±ì—ì„œ í™œìš©]</strong></p>

<h3 id="Semantic-segmentation-architectures">Semantic segmentation architectures</h3>

<h4 id="Fully-Convolutional-Networks-FCN">Fully Convolutional Networks(FCN)</h4>

<p>Semantic segmentationì„ ìœ„í•œ ì²« End-to-End architecture</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309160418715.png" alt=""></p>

<p><strong>[img. FCN êµ¬ì¡°]</strong></p>

<ul>
  <li>End-to-End êµ¬ì¡°: ì…ë ¥ì¸µë¶€í„° ì¶œë ¥ì¸µê¹Œì§€ ëª¨ë‘ ë¯¸ë¶„ê°€ëŠ¥í•˜ì—¬ ì…ë ¥ê³¼ ì¶œë ¥ pairë§Œ ìˆìœ¼ë©´ ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¥¼ ì˜ë¯¸. ì…ë ¥ ì‚¬ì´ì¦ˆ ë“±ì˜ ì œí•œì´ ì—†ìŒ</li>
  <li>ì´ì „ì—ëŠ” ì™„ì „í•™ìŠµ í•˜ê¸°ì— ì œí•œì´ ìˆì—ˆìŒ
    <ul>
      <li>ex) AlexNetì„ ì´ìš©í•œ semantic segmentationì˜ ê²½ìš°, í•™ìŠµ ì‹œì˜ ì´ë¯¸ì§€ í•´ìƒë„ì™€ test ì‹œì˜ ì´ë¯¸ì§€ í•´ìƒë„ê°€ ë‹¤ë¥´ë©´ ì•ˆë¬ìŒ.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309200905809.png" alt=""></p>

<p><strong>[img. Fully connected layer vs Fully convolutional layer êµ¬ì¡° ë¹„êµ]</strong></p>

<table>
  <thead>
    <tr>
      <th>Fully connected layer(FCL)</th>
      <th>Fully convolutional layer</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309201512441.png" alt=""><br>ê³µê°„ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ëª¨ìŠµ</td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309201522327.png" alt=""></td>
    </tr>
    <tr>
      <td>fixed dimensional vectorë¥¼ ë°›ì•„ fixed dimensional vector ì¶œë ¥, ë³´í†µ í•˜ë‚˜ë¡œ ì •í•´ì§„ feature vectorë¥¼ ì¶œë ¥</td>
      <td>activation mapì„ ë°›ì•„ activation map ì¶œë ¥, ë³´í†µ 1x1 conv layerë¡œ êµ¬í˜„í•˜ë©°, feature vectorë“¤ì´ í¬í•¨ëœ convolutional feature map ì¶œë ¥</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Fully connected layer vs Fully convolutional layer ì„¸ë¶€ ë¹„êµ]</strong></p>

<p>ë‹¤ë§Œ Receptive fieldë¥¼ ì‚´í•€ ë’¤ featureë¥¼ ì°¾ì•„ ì‘ì€ í¬ê¸°ì˜ ê²°ê³¼ë¥¼ ë‚´ëŠ” conv layerì™€ pooling layerë¡œ ì¸í•´ ì¶œë ¥ ì´ë¯¸ì§€ì˜ í•´ìƒë„ê°€ ì‘ì•„ì§ =&gt; ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Upsampling layerê°€ ë‚˜íƒ€ë‚¨</p>

<p>Upsampling layerì´ë€?</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309202323525.png" alt=""></p>

<p><strong>[img Upsamplingì´ ì¶”ê°€ëœ FCN]</strong></p>

<p>ì‘ì•„ì§„ ê²°ê³¼ë¬¼ì„ í¬ê²Œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•´ Upsampling layerì„ ì‚¬ìš©</p>

<p>3ê°€ì§€ ë°©ë²• ì¤‘ Unpooling ë°©ë²•ì„ ì œì™¸í•˜ê³  2ê°€ì§€ ë°©ë²•ì´ ì´ìš©ë¨</p>

<ol>
  <li>Transposed convolution</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309202812424.png" alt=""></p>

<p><strong>[img. Transpose convolutionì˜ ì›ë¦¬]</strong></p>

<p>ì¤„ì–´ë“  ì´ë¯¸ì§€ì˜ í”½ì…€ì„ í•„í„°ë§Œí¼ ê³±í•œ ë’¤, kernel ì‚¬ì´ì¦ˆì™€ strider í¬ê¸°ì— ë”°ë¼ ê³±ì—°ì‚°í•˜ì—¬ ë”í•œë‹¤, ì¤‘ì²© ë˜ëŠ” ë¶€ë¶„ì€ ë§ì…ˆì—°ì‚°ì´ ì¼ì–´ë‚œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309203617778.png" alt=""></p>

<p><strong>[img. Transpose convolutionì˜ ë¬¸ì œì ]</strong></p>

<p>kernel ì‚¬ì´ì¦ˆì™€ strider í¬ê¸°ì— ì£¼ì˜í•˜ì§€ ì•Šìœ¼ë©´, ê²¹ì³ì„œ ë§ì…ˆì´ ì¼ì–´ë‚˜ëŠ” ë¶€ë¶„ì— ì˜í•´ checker ë¬´ëŠ¬ê°€ ë‚˜íƒ€ë‚˜ê²Œ ëœë‹¤.</p>

<ol>
  <li>Upsample and convolution</li>
</ol>

<p>ìœ„ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ upsamplingê³¼ convolutionì„ ê°™ì´ ì‚¬ìš©í•˜ì—¬ ì¤‘ì²©í•˜ëŠ” ë¶€ë¶„ë¿ë§Œ ì•„ë‹ˆë¼ ê³¨ê³ ë£¨ ì˜í–¥ì„ ë°›ê²Œ í•´ì¤€ë‹¤.</p>

<p>Transposeì™€ ë‹¬ë¦¬ layerì„ í•˜ë‚˜ê°€ ì•„ë‹Œ 2ê°œë¡œ ë¶„ë¦¬í•˜ì—¬ ì£¼ë¡œ ì˜ìƒì²˜ë¦¬ì— ì‚¬ìš©í•˜ëŠ”interpolation ì•Œê³ ë¦¬ì¦˜(Nearest-neighbor(NN), Bilinear ë“±)ì„ ì‚¬ìš©í•˜ê³  convolutionì„ ì´ìš©í•˜ì—¬ í•™ìŠµ ê°€ëŠ¥í•˜ê²Œ ë§Œë“ ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309202959708.png" alt=""></p>

<p><strong>[img. ê°œì„ ëœ convolution]</strong></p>

<p>í•´ìƒë„ë¥¼ ë‚®ì¶”ë©° ì§„í–‰ë˜ëŠ” conv layer íŠ¹ì„±ìƒ, ì¸µì˜ ê¹Šì— ë”°ë¥¸ íŠ¹ì„±ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ë‚®ì€ ë ˆì´ì–´ì¸µ, í•´ìƒë„ ë†’ìŒ, Receptive field ì‘ìŒ &lt;====&gt; ë†’ì€ ë ˆì´ì–´ì¸µ, í•´ìƒë„ ë‚®ìŒ, Receptive field í¼</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309204744193.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>ë””í…Œì¼, ë¡œì»¬ ë³€í™”ì— ë¯¼ê°&lt;====&gt;ì „ë°˜ì  ì˜ë¯¸ì  ì •ë³´ë¥¼ í¬í•¨</strong></td>
    </tr>
  </tbody>
</table>

<p><strong>[table. ì¸µì˜ ê¹Šì´ì— ë”°ë¥¸ output ê°’ì˜ íŠ¹ì§•]</strong></p>

<p>ê²°êµ­ ìš°ë¦¬ê°€ í•„ìš”í•œê±´ êµ¬ì¡°ì˜ ê¹Šì€ ë¶€ë¶„ì˜ ì˜ë¯¸ì  ë¶€ë¶„(classify í•´ì•¼í•˜ë¯€ë¡œ)ê³¼ êµ¬ì¡°ì˜ ì–•ì€ ë¶€ë¶„ì˜ ë””í…Œì¼í•œ ë¶€ë¶„(ê³ í•´ìƒë„ë¡œ í”½ì…€ì„ ì„ ì •í•´ì•¼ í•˜ë¯€ë¡œ)ì´ ë‘˜ë‹¤ í•„ìš”í•˜ë¯€ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í•´ê²°í•˜ì˜€ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309211324579.png" alt=""></p>

<p><strong>[img. FCN-Ns ëª¨ë¸ë“¤ì˜ ë¹„êµ]</strong></p>

<p>ë§ˆì¹˜ DenseNetì´ë‚˜ ResNet ì²˜ëŸ¼,</p>

<ol>
  <li>ì¤‘ê°„ì˜ ê²°ê³¼ ê°’ì„ upsampling í•œ ë’¤,</li>
  <li>ìµœì¢…ê²°ê³¼ë¬¼ì„ upsamplingí•œ ê²ƒë“¤ì„</li>
  <li>Concatenateí•˜ì—¬ ì¶œë ¥í•˜ë©´ ì¢‹ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ë©°,</li>
</ol>

<p>ì–¼ë§ˆë‚˜ ë§ì€ ì¸µì—ì„œ ê²°ê³¼ê°’ì„ ê°€ì ¸ì˜¤ëŠëƒì— ë”°ë¼ FCN-32s, FCN-16s, FCN-8s ëª¨ë¸ë¡œ ë‚˜ëˆ„ì–´ì§„ë‹¤.</p>

<ul>
  <li>ìˆ«ìê°€ ì‘ì•„ì§ˆ ìˆ˜ë¡ ë” ë§ì€ ì¸µì˜ ê²°ê³¼ê°’ì„ ê°€ì ¸ì˜¨ ëª¨ë¸</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309211534377.png" alt=""></p>

<p><strong>[img. FCN-Ns ëª¨ë¸ë“¤ì˜ ë¹„êµ, ì¤‘ê°„ê°’ì„ ë§ì´ ê°€ì ¸ì˜¨ ëª¨ë¸ì¼ ìˆ˜ë¡ ì •í™•í•œ ê²°ê³¼ê°€ ë‚˜ì˜´]</strong></p>

<h4 id="Hypercolumns-for-object-segmentation">Hypercolumns for object segmentation</h4>

<table>
  <thead>
    <tr>
      <th><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309211717755.png" alt=""></th>
      <th><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309211729381.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>HyperColumnì´ë¼ëŠ” ëª¨ë“  Conv layerì˜ ê²°ê³¼ê°’ì„ ê° í”½ì…€ ë³„ë¡œ ìŒ“ì•„ ë§Œë“  vecotrë¥¼ ì´ìš©í•¨</td>
      <td>ë¬¼ì²´ì˜ bounding boxë¥¼ ì¶”ì¶œí•˜ê³  ì‚¬ìš©í•œë‹¤ëŠ” ì ì´ ë‹¤ë¦„</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. FCNê³¼ ë¹„ìŠ·í•œ ë‚´ìš©ì„ ë‹´ì€ HyperColumn ë…¼ë¬¸]</strong></p>

<h4 id="U-Net">U-Net</h4>

<p>ì˜ìƒì˜ ì¼ë¶€ë¶„ë§Œ ì“°ëŠ” ê´€ë ¨ëœ TASKì˜ ê²½ìš° ì•„ì§ë„ ë§ì´ í™œìš©ë˜ëŠ” network</p>

<p>Fullay convolutional networkê°€ ê¸°ë°˜ì´ë©°, skip connectionì„ í†µí•˜ì—¬ ì•ì„  network ë³´ë‹¤ ë”ìš± ì •êµí•œ ê²°ê³¼ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŒ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309212400739.png" alt=""></p>

<p><strong>[img. Uì ëª¨ì–‘ì´ë¼ U-Net]</strong></p>

<p>í¬ê²Œ 2ê°€ì§€ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ë‰œë‹¤.</p>

<ol>
  <li>Contracting path ë¶€ë¶„</li>
</ol>

<ul>
  <li>ì…ë ¥ ì˜ìƒì„ 3x3 convolutionì„ ì´ìš©í•´ max poolì„ ì´ìš©í•´ í•´ìƒë„ë¥¼ ë‚®ì¶”ê³  ëŒ€ì‹  2ë°°ì”© feature channelì„ ëŠ˜ë¦¼</li>
  <li>ì´ë¥¼ í†µí•´ ì „ì²´ì ì¸ ì˜ë¯¸, ë¬¸ë§¥(holistic context)ë¥¼ í™•ë³´í•˜ëŠ” ë¶€ë¶„ì´ë©° ì¼ë°˜ì ì¸ FCNê³¼ ë‹¤ë¥¼ë°” ì—†ìŒ</li>
</ul>

<ol>
  <li>Expanding(Upsampling, decoding) path ë¶€ë¶„</li>
</ol>

<ul>
  <li>
    <p>2x2 up-convolutionì„ í†µí•˜ì—¬ ë°˜ëŒ€ë¡œ ì ì§„ì ìœ¼ë¡œ ì±„ë„ ìˆ˜ëŠ” ì ˆë°˜ìœ¼ë¡œ, í•´ìƒë„ëŠ” 2ë°°ë¡œ ëŠ˜ë¦¼</p>
  </li>
  <li>
    <p>ì¶”ê°€ë¡œ ì´ì „ ë‚®ì€ ì¸µì˜ layerì˜ activation mapì„ Skip connectionìœ¼ë¡œ ê°€ì ¸ì™€ concatenatingí•˜ì—¬ ì‚¬ìš©í•¨</p>

    <ul>
      <li>
        <p>ì´ë¥¼ í†µí•´ detailí•˜ê³  localí•œ feature mapì„ ë°›ì•„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ</p>
      </li>
      <li>
        <p>ì´ë•Œ concatenateí•˜ë ¤ë©´ í•´ìƒë„ê°€ ë§ì•„ì•¼ í•˜ëŠ”ë°, í™€ìˆ˜ì´ë©´, Downsampleì‹œ, ì¼ë¶€ ê°’ì„ ë²„ë¦¬ê²Œ ë˜ë©°, ë‹¤ì‹œ Upsampleì‹œ í•´ìƒë„ê°€ ë‹¬ë¼ì§€ë¯€ë¡œ í•´ìƒë„ í¬ê¸°ê°€ í™€ìˆ˜ê°€ ì•ˆë˜ê²Œ í•´ì•¼í•¨.</p>
        <ul>
          <li>ex) 7x7 =DownSample(divide 2)=&gt; 3x3 (1ì€ ë²„ë¦¼) =UpSample(multiple 2)=&gt; 6x6</li>
          <li>7x7ê³¼ 6x6 í•´ìƒë„ê°€ ë§ì§€ ì•Šì•„ Concatenate ë¶ˆê°€</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>U-Net Pytorch ì½”ë“œ</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309213848432.png" alt=""></p>

<p><strong>[img. U-Net Contracting Path code]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309213905013.png" alt=""></p>

<p><strong>[img. U-Net Expanding Path code]</strong></p>

<h4 id="DeepLab">DeepLab</h4>

<p>ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” CRFs, Atrous Convolutionì˜ ì‚¬ìš©ì´ íŠ¹ì§•ì¸ network, Deeplab v3+ê°€ ìµœì‹ .</p>

<p><strong>CRFs(Conditional Random Fields)</strong></p>

<p>í›„ì²˜ë¦¬ë¡œ ì‚¬ìš©ë¨, í”½ì…€ ê°„ì˜ ê´€ê³„ë¥¼ ê·¸ë˜í”„ë¡œ í‘œí˜„í•œ ë’¤, ìµœì í™”í•˜ì—¬ ê²½ê³„ë¥¼ ì°¾ëŠ” ì›ë¦¬</p>

<p>score mapê³¼ ê²½ê³„ì„ ì´ ë§ë„ë¡ ê²½ê³„ì„  ë‚´ì™¸ë¶€ì˜ í™•ì‚°ì„ ë°˜ë³µí•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309221417567.png" alt=""></p>

<p><strong>[img. CRFs ì˜ˆì‹œ]</strong></p>

<p><strong>Atrous convolution(ë˜ëŠ” Dilated convolution)</strong></p>

<p>ì»¤ë„í¬ê¸°ë¥¼ ì •í•˜ê³ , ì •ì˜í•œ Dilation factor ë§Œí¼ ì»¤ë„ì„ ë„ì–´ ê³„ì‚°í•˜ëŠ” Convolution ë°©ë²•</p>

<p>ê°™ì€ parameter ìˆ˜ì™€ ì—°ì‚°ëŸ‰ìœ¼ë¡œ ë”ìš± í° Receptive sizeë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309221856422.png" alt=""></p>

<p><strong>[img. ì¢Œì¸¡ì´ ê¸°ì¡´ì˜ conv, ìš°ì¸¡ì´ astrous conv]</strong></p>

<p><strong>Depthwise separable convolution</strong></p>

<p>ì…ë ¥ ì´ë¯¸ì§€ í•´ìƒë„ê°€ í´ ê²½ìš°, ë„ˆë¬´ ì²˜ë¦¬ê°€ ì˜¤ë˜ ê±¸ë¦¬ì, Dilated convolution + Depthwise separable convolution = Astrous separable convolutionì„ ì´ìš©í•œë‹¤.</p>

<p>Depthwise separable convolutionëŠ” ì¼ë°˜ convoutionì„ 2ê°œì˜ ì ˆì°¨ë¡œ ë‚˜ëˆ„ì–´ ì§„í–‰í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309223426502.png" alt=""></p>

<p><strong>[img.Standard vs Depthwise separable convolutionì˜ ì°¨ì´]</strong></p>

<p>ì´ë¡œ ì¸í•´ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ $D_k^2MND_F^2$ì—ì„œ $D_k^2MD_F^2+ MND_F^2$ë¡œ ê°ì†Œí•˜ì˜€ë‹¤.</p>

<p><strong>DeepLab v3+ì˜ êµ¬ì¡°</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210309223952659.png" alt=""></p>

<p><strong>[img. ìµœì‹  DeepLab v3+ì˜ êµ¬ì¡° ]</strong></p>

<ol>
  <li>DCNN ë¶€ë¶„ì—ì„œ Dilated convolutionì„ í†µí•˜ì—¬ feature mapì„ êµ¬í•¨</li>
  <li>Encdoer ì¤‘ê°„ ë¶€ë¶„ì— ìˆëŠ” Astrous spatial pyramid poolingì„ ì´ìš©í•´ ë‹¤ì–‘í•œ scaleì˜ ì •ë³´ë¥¼ Dilated convë¡œ ì—¬ëŸ¬ featureë¥¼ ì¶”ì¶œí•œ í›„ í•˜ë‚˜ë¡œ í•©ì³ 1x1convolutionìœ¼ë¡œ í•˜ë‚˜ë¡œ í•©ì¹œë‹¤.</li>
  <li>Decoder ë¶€ë¶„ì—ì„œ Low-Level Featuresì™€ Upsamplingí•œ Pyramid pooling featureë¥¼ Concatí•œ ë’¤, ê²°ê³¼ê°’ì„ ë‚¸ë‹¤.</li>
</ol>

<p>Semantic segmentation ë¿ë§Œ ì•„ë‹ˆë¼, instance segmentation(Class ë¿ë§Œ ì•„ë‹ˆë¼ ê°ì²´ ë˜í•œ íƒì§€), panoptic segmentation(ë°°ê²½ ì •ë³´+ instance segmentation)ìœ¼ë¡œ ì„±ì¥í•˜ê³  ìˆë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094300040.png" alt=""><br>Original Image</th>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094309340.png" alt=""><br>Semantic segmentation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094320216.png" alt=""><br><strong>Instance segmentation</strong></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094328026.png" alt=""><br><strong>Panoptic segmentation</strong></td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Image ì¸ì‹ Tasks]</strong></p>

<h2 id="Object-detection">Object detection</h2>

<h3 id="Object-detection">Object detection</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095403945.png" alt=""></p>

<p><strong>[img. Object detectionì˜ ì˜ˆì‹œ]</strong></p>

<p>Classification + Box localizationì˜ Task</p>

<p>ì¦‰, ë°”ìš´ë”© ë°•ìŠ¤ì˜ ìœ„ì¹˜ + ë¬¼ì²´ì˜ ì†Œì†ê¹Œì§€ ì˜ˆì¸¡í•´ì•¼í•¨, ê³ ìˆ˜ì¤€ì˜ ë¬¸ì œ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095559874.png" alt=""></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095638069.png" alt=""></p>

<p><strong>[imgs. ììœ¨ ì£¼í–‰, OCR ë“±ì˜ ì‚°ì—…ì— ì‚¬ìš©ë¨]</strong></p>

<h3 id="Two-stage-detector-R-CNN-family">Two-stage detector(R-CNN family)</h3>

<h4 id="Traditional-methods-hand-crafted-techniques-1-Gradient-based-detector">Traditional methods- hand-crafted techniques 1. Gradient-based detector</h4>

<p>ê³¼ê±°ì—ëŠ” ê²½ê³„ì„ ì˜ íŠ¹ì§•ìœ¼ë¡œ ì‚¬ëŒì˜ ì§ê´€ê³¼ ì§ì ‘ ì„¤ê³„í•œ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Object Detectionì„ í•¨</p>

<table>
  <thead>
    <tr>
      <th>Average Gradient</th>
      <th>max (+) SVM weight</th>
      <th>max (-) SVM weight</th>
      <th>Original Image</th>
      <th>R-HOG descriptor</th>
      <th>R-HOG w/ (+) SVM</th>
      <th>R-HOG w/ (-) SVM</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095939961.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095949507.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310095956434.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100003591.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100009439.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100015857.png" alt=""></td>
      <td><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100022937.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[img. Gradient-based detector]</strong></p>

<ul>
  <li>HOG : histogram of Oriented Gradients</li>
  <li>SVM : Support Vector Machine, ì‹¬í”Œí•œ Linear ëª¨ë¸
    <ul>
      <li>ê²°ì • ê²½ê³„, ì¦‰ ê·¸ë˜í”„ ë‚´ì— ë¶„ë¥˜ë¥¼ ìœ„í•œ ê¸°ì¤€ì„ ì„ ì •ì˜í•˜ëŠ” ëª¨ë¸</li>
    </ul>
  </li>
</ul>

<h4 id="Traditional-methods-hand-crafted-techniques-2-Selective-search-Box-proposal-algorithm">Traditional methods- hand-crafted techniques 2. Selective search(Box-proposal algorithm)</h4>

<p>ìµœê·¼ì˜ ì´ˆê¸° Object Detectionì—ì„œ ìì£¼ ì‚¬ìš©í•œ ê¸°ìˆ ë¡œ, ë‹¤ì–‘í•œ ë¬¼ì²´ í›„ë³´êµ°ì— ëŒ€í•´ì„œ ì˜ì—­ì„ íŠ¹ì •í•˜ì—¬ Bounding-boxë¥¼ ì œì•ˆí•´ì¤Œ</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ìˆœë²ˆ</th>
      <th style="text-align: center">1</th>
      <th style="text-align: center">2</th>
      <th style="text-align: center">3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">êµ¬ë¶„</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100639654.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100646430.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100654360.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">ì˜ˆì‹œ</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100702507.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100708780.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310100716265.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">ì„¤ëª…</td>
      <td style="text-align: center">Over-segmentation<br>(ë¹„ìŠ·í•œ ìƒ‰, ë¶„í¬ë¼ë¦¬ ì˜ì—­ ë‚˜ëˆ”)</td>
      <td style="text-align: center">ë¹„ìŠ·í•œ ì˜ì—­ë¼ë¦¬ í•©ì¹¨</td>
      <td style="text-align: center">Bounding boxë¥¼ ì¶”ì¶œ</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Selective search ì˜ˆì‹œ]</strong></p>

<h4 id="R-CNN">R-CNN</h4>

<p>ë”¥ëŸ¬ë‹ ê¸°ë°˜, Alex Net ë³´ë‹¤ ì••ë„ì ì¸ ì„±ëŠ¥</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310101110334.png" alt=""></p>

<p><strong>[img. R-CNNì˜ ê³¼ì •]</strong></p>

<ol>
  <li>ì´ë¯¸ì§€ ì…ë ¥</li>
  <li>ìœ„ì˜ Selective search ë“±ì˜ bounding box ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ Region Proposal(ìµœëŒ€ 2ì²œê°œê¹Œì§€)ì„ êµ¬í•¨</li>
  <li>ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ëŠ˜ë ¤ì„œ í•´ìƒë„ë¥¼ ë§ì¶”ê³  ë¯¸ë¦¬ í•™ìŠµëœ(Pre-trained) CNNì— ì…ë ¥</li>
  <li>SVMì„ ì´ìš©í•´ Classification</li>
</ol>

<p>bounding box detectionì˜ ì„±ëŠ¥ì˜ í•œê³„ì™€ ê°ê° bounding box ì¼ì¼ì´ Classification í•˜ë¯€ë¡œ ì†ë„ê°€ ëŠë¦¼</p>

<h4 id="Fast-R-CNN">Fast R-CNN</h4>

<p>R-CNNê³¼ ë‹¬ë¦¬ ì´ë¯¸ì§€ì˜ í•™ìŠµëœ featureë¥¼ ì¬í™œìš©í•´ì„œ ì†ë„ë¥¼ í–¥ìƒ(ìµœëŒ€ ~18ë°° ë¹ ë¦„)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310101542959.png" alt=""></p>

<p><strong>[img. Fast R-CNNì˜ ê³¼ì •]</strong></p>

<ol>
  <li>CNNì„ í†µí•˜ì—¬ feature mapì„ ë¯¸ë¦¬ ë½‘ì•„ëƒ„
    <ul>
      <li>Fully Convolutional Networkë¥¼ ì´ìš©í•´ í•´ìƒë„ ê³ ì • ë¬¸ì œë¥¼ í•´ê²°í–ˆìœ¼ë¯€ë¡œ warping ì•ˆí•¨</li>
    </ul>
  </li>
  <li>ì´ë ‡ê²Œ ë½‘ì€ feature mapì„ RoI pooling layerì—ì„œ ê´€ì‹¬ì˜ì—­(RoI, Region of Interest)ë§Œ ë½‘ì•„ resizeí•¨</li>
  <li>FC layerì™€ í•¨ê»˜ ê²°í•©ëœ bbox regressorì™€ softmaxë¥¼ í†µí•´ ê°ê° ë”ìš± ì •êµí•œ ë°”ìš´ë”©ë°•ìŠ¤ì™€ classificationì„ í•¨</li>
</ol>

<p>ì—¬ì „íˆ ë°”ìš´ë”© ë°•ìŠ¤ ê²€ì¶œ(Region Proposal) ì„±ëŠ¥ì— í•œê³„ë¥¼ ê°€ì§.</p>

<h4 id="Faster-R-CNN">Faster R-CNN</h4>

<p>Region Proposal ë˜í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ìœ¼ë¡œ ë°”ê¾¼ ìµœì´ˆì˜ End-to-End Object Detection ëª¨ë¸, ì¦‰ ëª¨ë‘ í•™ìŠµ ê°€ëŠ¥í•¨</p>

<p><strong>Intersection over Union(IoU)</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310102211024.png" alt=""></p>

<p><strong>[img. IoUì˜ ì •ì˜]</strong></p>

<p>IoU (Intersection over Union) : ì–¼ë§ˆë‚˜ bounding boxê°€ ì˜ ì •í•©ë˜ì–´ìˆëŠ”ê°€ë¥¼ ì •ì˜</p>

<p><strong>Anchor Box</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310102328817.png" alt=""></p>

<p><strong>[img. Anchor Box ì˜ˆì‹œ]</strong></p>

<p>ê° ìœ„ì¹˜ì—ì„œ ë°œìƒí•  ë§Œí•œ ë°•ìŠ¤ í›„ë³´êµ°ë“¤ì„ í¬ê¸°ì™€ ë¹„ìœ¨ ë³„ë¡œ ë¯¸ë¦¬ ì •ì˜í•´ë†“ìœ¼ë©° ì´ë¥¼ Anchor Boxë¼ê³  í•¨</p>

<p>Faster R-CNNì—ì„œëŠ” ë³´í†µ 9ê°œë¡œ ì •ì˜ í•´ë†“ê³ , ë” ë§ì´ ì •ì˜ë„ ê°€ëŠ¥</p>

<p>ê°ê° Anchoer boxì™€ ì‹¤ì œ ê°’(Ground-Truth)ì˜ IoUë¥¼ ë¹„êµí•˜ì—¬ ì •ë‹µì¸ Positive sampleê³¼ negative sampleì„ ì •ì˜í•˜ì—¬ í•™ìŠµì‹œí‚´</p>

<ul>
  <li>ë³´í†µ IoUê°€ 0.7 ì´ìƒì´ë©´ +, 0.3 ì´í•˜ë©´ -</li>
</ul>

<p><strong>Region Proposal Network(RPN)</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310104207161.png" alt=""></p>

<p><strong>[img. Region Proposal Network(RPN)]</strong></p>

<p>íŠ¹íˆ, ê¸°ì¡´ì˜ ëŠë¦° Region proposal ì•Œê³ ë¦¬ì¦˜ì„ ë”¥ëŸ¬ë‹ ê¸°ë°˜ RPNìœ¼ë¡œ ë°”ê¿¨ìŒ</p>

<p>ê·¸ ì´ì™¸ì—ëŠ” ê¸°ì¡´ì˜ Fast R-CNNê³¼ ë¹„ìŠ·í•¨</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310104334050.png" alt=""></p>

<p><strong>[img. ìì„¸í•œ RPN ê³¼ì •]</strong></p>

<ol>
  <li>Sliding Door ë°©ì‹ìœ¼ë¡œ Window ë§ˆë‹¤ k ê°œì˜ anchor box ê³ ë ¤</li>
  <li>256 ì°¨ì› feature map ì¶”ì¶œ</li>
  <li>feature mapì—ì„œ Classificationì„ ìœ„í•´ 2kê°œì˜ score ë¥¼ ì¶”ì¶œ, ë™ì‹œì— ë°”ìš´ë”© ë°•ìŠ¤ì˜ í¬ê¸°, ìœ„ì¹˜ë¥¼ ìœ„í•´ 4kê°œì˜ ê°’ì„ ì¶”ì¶œ
    <ul>
      <li>ê³„ì‚°ì†ë„ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ Anchor boxë¡œ roughí•˜ê²Œ ì •ì˜í•œ í›„, ì •êµí•˜ê²Œ ë°”ìš´ë”©ë°•ìŠ¤ ì¶”ì¶œ</li>
      <li>Classificationì—ì„œëŠ” Cross Entropy loss, ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œì€ Regression loss ì‚¬ìš©</li>
      <li>Anchor box ì¢…ë¥˜ì— ë”°ë¥¸ Lossë„ ë”°ë¡œ ìˆìŒ</li>
    </ul>
  </li>
</ol>

<p><strong>Non-Maximum Suppressions (NMS)</strong></p>

<p>RPNì— ì˜í•´ ë§ì€ Bounding boxê°€ ì œì•ˆë˜ë©°, ì´í›„ NMSë¥¼ í†µí•´ ìµœì ì˜ Bounding boxë§Œ í•„í„°ë§í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310105725056.png" alt=""></p>

<p><strong>[img. NMS steps]</strong></p>

<ol>
  <li>ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ boxë¥¼ ì„ íƒ</li>
  <li>IoUë¥¼ ë‹¤ë¥¸ ë°•ìŠ¤ì™€ ë¹„êµ</li>
  <li>IoUê°€ 50 ì´ìƒì¸ ë°•ìŠ¤ë“¤ ì œê±°</li>
  <li>ê·¸ë‹¤ìŒ ë†’ì€ ì ìˆ˜ì˜ boxë¥¼ ì„ íƒ</li>
  <li>2~4 ë°˜ë³µ</li>
</ol>

<table>
  <thead>
    <tr>
      <th style="text-align: center">R-CNN</th>
      <th style="text-align: center">Fast R-CNN</th>
      <th style="text-align: center">Faster R-CNN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310105930699.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310105945570.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310105958162.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[table. R-CNN Family êµ¬ì¡° ë¹„êµ]</strong></p>

<p>R-CNN Familyì€ Two-stage Detectorì˜ ëŒ€í‘œ ëª¨ë¸ë“¤ì´ë‹¤.</p>

<h3 id="Single-stage-detector">Single-stage detector</h3>

<p>Single-stage detectorì€</p>

<p>ì •í™•ë„ê°€ ì¡°ê¸ˆ ë’¤ë–¨ì–´ì§€ì§€ë§Œ ë¦¬ì–¼ íƒ€ì„ Detection ê°€ëŠ¥í•  ì •ë„ë¡œ ë†’ì€ ì†ë„ì— ì¤‘ì ì„ ë‘ </p>

<p>RoI pooling layerë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ , ê°„ë‹¨í•œ êµ¬ì¡°ì™€  ë¹ ë¥¸ ì†ë„ë¥¼ ìë‘í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">One-stage detector</th>
      <th style="text-align: center">Two-stage detector</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310110424184.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310110436986.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[tables. one-stage vs two-stage]</strong></p>

<h4 id="YOLO-You-only-look-once">YOLO(You only look once)</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310110958657.png" alt=""></p>

<p><strong>[img. YOLO ê³¼ì •]</strong></p>

<ol>
  <li>Inputì„ S í¬ê¸°ì˜ ê·¸ë¦¬ë“œë¡œ ë‚˜ëˆ”</li>
  <li>ê° ë°•ìŠ¤ì— ëŒ€í•˜ì—¬ Boundig boxì™€ Confidenceë¥¼ ì˜ˆì¸¡
    <ul>
      <li>ì´ë•Œ, Ground truthì™€ IoUë¥¼ ë¹„êµí•˜ì—¬ í•™ìŠµí•¨</li>
    </ul>
  </li>
  <li>ë™ì‹œì— ê° ìœ„ì¹˜ì—ì„œì˜ Class Scoreë¥¼ ì¶”ê°€ë¡œ ì˜ˆì¸¡</li>
  <li>NMSë¥¼ í†µí•´ Bounding box ì¶”ì¶œ</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310111451684.png" alt=""></p>

<p><strong>[img. YOLOì˜ êµ¬ì¡°]</strong></p>

<p>ì¼ë°˜ CNN êµ¬ì¡°ì™€ ë¹„ìŠ·í•˜ë©° SxSx30ì˜ ì•„ì›ƒí’‹ì´ ë‚˜ì˜´</p>

<p>(ì±„ë„ìˆ˜ 30 = class probability 20 + x,y,w,h ê°ê° 2ì±„ë„)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310112122090.png" alt=""></p>

<p><strong>[img. YOLO ì„±ëŠ¥ë¹„êµ]</strong></p>

<p>Two-stageì— ë¹„í•´ ì„±ëŠ¥ì€ ë–¨ì–´ì§€ì§€ë§Œ í›¨ì”¬ ë¹ ë¥´ë‹¤.</p>

<ul>
  <li>ì„±ëŠ¥ì´ ë–¨ì–´ì§€ëŠ” ì´ìœ ëŠ” ë§¨ ë§ˆì§€ë§‰ Layerì—ì„œ í•œë²ˆë§Œ Prediction í•˜ë¯€ë¡œ</li>
</ul>

<p><strong>Single Shot Multibox Detector(SSD)</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310112652356.png" alt=""></p>

<p><strong>[img. SSD ì˜ˆì‹œ]</strong></p>

<p>feature mapë“¤ì˜ ë‹¤ë¥¸ í•´ìƒë„ë§ˆë‹¤ ì ì ˆí•œ í¬ê¸°ì˜ Bounding boxë¥¼ ì„¤ì •í•˜ê²Œ í•´ì¤Œ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310112951617.png" alt=""></p>

<p><strong>[img. SSDì˜ êµ¬ì¡°]</strong></p>

<p>VGG-16ì„ backboneìœ¼ë¡œ, ë‹¤ì–‘í•œ Scaleì˜ convë¥¼ í†µê³¼ì‹œì¼œ ì—¬ëŸ¬ í•´ìƒë„ì— ëŒ€ì‘í•¨</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310113138212.png" alt=""></p>

<p><strong>[img. SSD ì „ì²´ anchor box ê°¯ìˆ˜ ê³„ì‚°]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310113242498.png" alt=""></p>

<p><strong>[img. SSD ì„±ëŠ¥ ë¹„êµ]</strong></p>

<p>ì†ë„ì™€ ì„±ëŠ¥ì´ YOLO ë¿ë§Œ ì•„ë‹ˆë¼ R-CNN ê³„ì—´ ë³´ë‹¤ë„ ì¢‹ë‹¤.</p>

<h3 id="Single-stage-detector-vs-two-stage-detector">Single-stage detector vs. two-stage detector</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310113446418.png" alt=""></p>

<p><strong>[img. Class imbalance Problem ì˜ˆì‹œ]</strong></p>

<p>Class Imbalance Problem : Single stage detectorì˜ ë¬¸ì œ, ê²°ê³¼ê°’ì— í•„ìš”ì—†ëŠ” negative anchor boxê°€ positive anchor boxë³´ë‹¤ í›¨ì”¬ ë§ì€ ë¬¸ì œ</p>

<p><strong>Focal Loss</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310113638609.png" alt=""></p>

<p><strong>[img. Focal loss ê·¸ë˜í”„]</strong></p>

<p>ìœ„ì˜ Class Imbalance Problemë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì œì•ˆë¨</p>

<p>cross entropy lossì˜ ì—°ì¥ì„ ìœ¼ë¡œ, ì¶”ê°€ì ì¸ í™•ë¥  í…€ì´ ë¶™ê²Œ ëœë‹¤.</p>

<p>CEì™€ ë¹„êµí•˜ì—¬ $\gamma$ê°’ì— ë”°ë¼ ì •ë‹µì˜ ê²½ìš° Lossë¥¼ ë”ìš± ë‚®ê²Œ, ì˜¤ë‹µì˜ ê²½ìš° Lossì— ë”ìš± ê°€ì¤‘ì„ ì£¼ê²Œ  ëœë‹¤.<br>
\(Cross\ Entropy\ Loss:CE(p_t)=-log(p_t)\\
Focal\ Loss:FL(p_t)=(1-p_t)^\gamma CE(p_t)=-(1-p_t)^\gamma\)<br>
<strong>[math. Focal lossì˜ ìˆ˜ì‹]</strong></p>

<p><strong>RetinaNetê³¼ Feature Pyramid Networks(FPN)</strong></p>

<p>RetinaNet = FPN + class/box subnet</p>

<p>U-Netê³¼ ë¹„ìŠ·í•œ êµ¬ì¡°ë¡œ, low levelì˜ featureì™€ high levelì˜ featureë¥¼ í•©í•˜ì—¬ classì™€ box_boundingì„ ê° ìœ„ì¹˜ì—ì„œ ìˆ˜í–‰</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310114744367.png" alt=""></p>

<p><strong>[img. RetinaNet êµ¬ì¡°]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310115153737.png" alt=""></p>

<p><strong>[img. RetinaNet ì„±ëŠ¥]</strong></p>

<p>ë¹„ìŠ·í•œ ì†ë„ì— ë†’ì€ ì„±ëŠ¥ì„ ë³´ì´ë©°, ì†ë„ë¥¼ í¬ìƒì‹œí‚¤ë©´ ì„±ëŠ¥ì„ ë” ì˜¬ë¦´ ìˆ˜ ìˆìŒ</p>

<h3 id="Detection-with-Transformer">Detection with Transformer</h3>

<p><strong>DETR</strong>(DEtection TRansformer)</p>

<p>NLPì—ì„œ í° í˜ì‹ ì„ ë³´ì—¬ì¤€ Transformer êµ¬ì¡°ë¥¼ Object Detectionì— í™œìš©í•œ êµ¬ì¡°,</p>

<p>DETRì€ facebookì—ì„œ ê°œë°œ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310115306667.png" alt=""></p>

<p><strong>[img. Transformer êµ¬ì¡°]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310115459259.png" alt=""></p>

<p><strong>[img. DETR êµ¬ì¡°]</strong></p>

<p>CNNì˜ featureì™€ pixelì˜ positional encodingì„ í•©í•˜ì—¬ encoderì— ë„£ì–´ì¤€ í›„, Nê°œì˜ Object queriesì™€ í•¨ê»˜ decoderì— ë„£ì–´ì¤€ í›„, ê° í”½ì…€ì˜ class, bounding boxë¥¼ ì¶œë ¥í•´ì£¼ëŠ” êµ¬ì¡°</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310115803248.png" alt=""></p>

<p><strong>[img. bounding box ì´ì™¸ì˜ ë°©ë²•ë“¤]</strong></p>

<p>ì´ì™¸ì—ë„ CornerNet, CenterNet ë“± Bounding box ëŒ€ì‹  ì¤‘ì‹¬ì , ì–‘ ëì ì„ ì°¾ëŠ” ì—°êµ¬ ë“±ì´ ì§„í–‰ë˜ëŠ” ì¤‘</p>

<h2 id="CNN-Visualization">CNN Visualization</h2>

<p>CNNì„ ì‹œê°í™”í•˜ëŠ” ê²ƒ</p>

<h3 id="Visualizing-CNN">Visualizing CNN</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310120152420.png" alt=""></p>

<p><strong>[img. CNN is a black box]</strong></p>

<p>ë§ì€ ê²½ìš° CNNì˜ ë‚´ë¶€ ë¡œì§ ë“±ì„ ì•Œ ìˆ˜ ì—†ê±°ë‚˜, ì‹ ê²½ì“°ì§€ ì•Šê³  ê°œë°œí•˜ëŠ” ê²½ìš°ê°€ ë§ë‹¤.</p>

<p>ì–´ì§¸ì„œ ì´ëŸ¬í•œ ê²°ê³¼ê°€ ë‚˜ì™”ëŠ”ê°€? ë¬´ì—‡ì´ ë¬¸ì œì¸ê°€? ì–´ë–»ê²Œ í•˜ë©´ ê°œì„  ê°€ëŠ¥í•œê°€? ë“±ì„ ì•Œì•„ë³´ê¸° ìœ„í•´ Black box ìƒíƒœì´ CNN ë‚´ë¶€ë¥¼ ì•Œì•„ë³¼ í•„ìš”ê°€ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310120939768.png" alt=""></p>

<p><strong>[img. ZFNet ì˜ˆì œ]</strong></p>

<p>ZFNet ë“±ì—ì„œëŠ” ê° levelì˜ featureë¥¼ í™•ì¸í•˜ì—¬ í•™ìŠµì„ íŒŒì•…í•  ìˆ˜ ìˆì–´ì„œ ì´ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ê°œì„ ì‹œí‚¬ ìˆ˜ ìˆì—ˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310121352942.png" alt=""></p>

<p><strong>[img. ê°„ë‹¨í•œ Filter weight visualization]</strong></p>

<p>ì €ì°¨ì›ì¸ 1ë²ˆì§¸ conv layerì˜ ê²½ìš° 3ì±„ë„ ë˜ëŠ” 1ì±„ë„ë¡œ ì´ë£¨ì–´ì ¸ìˆì–´ ìƒë‹¨ê³¼ ê°™ì´ ì§ê´€ì ìœ¼ë¡œ Visualizationì´ ê°€ëŠ¥í•˜ì§€ë§Œ, layerê°€ ê¹Šì–´ì§€ë©´(ê³ ì°¨ì›ì´ ë˜ë©´) ì±„ë„ ìˆ˜ê°€ ëŠ˜ì–´ë‚˜ë©´ì„œ ì¸ê°„ì´ ì´í•´ ê°€ëŠ¥í•œ í˜•íƒœì˜ visualizationì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310122007325.png" alt=""></p>

<p><strong>[img. Types of neural network visualization]</strong></p>

<p>ì™¼ìª½ìœ¼ë¡œ ê°ˆìˆ˜ë¡ ëª¨ë¸ì— ëŒ€í•œ ì´í•´, ì˜¤ë¥¸ìª½ì„ ê°ˆìˆ˜ë¡ ë°ì´í„° ë¶„ì„</p>

<h3 id="Analysis-of-model-behaviors">Analysis of model behaviors</h3>

<p>ê³ ì°¨ì› layerì˜ featureë“¤ì„ ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ì</p>

<p><strong>ê³ ì°¨ì› Embedding feature analysis 1ë²ˆì§¸ ë°©ë²• - ì˜ˆì œ ê²€ìƒ‰ ë°©ë²•</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310122418084.png" alt=""></p>

<p><strong>[img. Nearest neighbors (NN) in a feature space]</strong></p>

<p>NN-searchì˜ ê²½ìš° feature spaceì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ ì‚¬ì§„ë“¤ì„ ë¹„êµ(ì˜ˆì œ ê²€ìƒ‰)í•¨ìœ¼ë¡œì¨ ë¶„ì„ì´ ê°€ëŠ¥í•˜ë‹¤.</p>

<p>ìƒë‹¨ì˜ ì½”ë¼ë¦¬ ì‚¬ì§„ë“¤ì„ ë³´ì•„, ì˜ clustering ëœê±¸ ì•Œ ìˆ˜ ìˆìœ¼ë©°, í•˜ë‹¨ì˜ ê°•ì•„ì§€ ì‚¬ì§„ìœ¼ë¡œ pixel ìœ„ì¹˜(ê°•ì•„ì§€ í˜•íƒœ, ìœ„ì¹˜)ê°€ ë°”ë€Œì–´ë„ ëª¨ë¸ì´ ì˜ ì°¾ì•„ë‚¸ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>

<p>ì´ëŸ¬í•œ ì˜ˆì œ ê²€ìƒ‰ ë°©ë²•ì˜ Stepì€ ë‹¤ìŒê³¼ ê°™ë‹¤.</p>

<ol>
  <li>ì‹ ê²½ë§ì„ í†µí•˜ì—¬ Databaseì—ì„œ ê° Inputì˜ ê³ ì°¨ì› featureë¥¼ ë½‘ì•„ë‚´ High dimensional feature spaceì— ìœ„ì¹˜ì‹œí‚¨ë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310123615524.png" alt=""></p>

<p><strong>[img. feature ì¶”ì¶œ ë° DB ìœ„ì¹˜]</strong></p>

<ol>
  <li>ê²€ìƒ‰í•˜ê³  ì‹¶ì€ Inputì˜ ê³ ì°¨ì› featureë¥¼ ë½‘ì•„ ë‚¸ ë’¤ ë§ˆì°¬ê°€ì§€ë¡œ High dimensional feature spaceì— ìœ„ì¹˜ì‹œí‚¨ë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310123644222.png" alt=""></p>

<p><strong>[img. Input ì‚¬ì§„ë“¤ì˜ featureì˜ ìœ„ì¹˜]</strong></p>

<ol>
  <li>ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì˜ featureë¥¼ ê°€ì ¸ì˜¨ ë’¤, ë§¤ì¹­ë˜ëŠ” Inputì„ ê°€ì ¸ì˜¨ë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310123531547.png" alt=""></p>

<p><strong>[img. ì‚¬ì§„ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒë“¤]</strong></p>

<ol>
  <li>ê·¸ Inputë“¤ê³¼ ë¹„êµí•˜ì—¬ Visualization í•œë‹¤.</li>
</ol>

<p>ë‹¨, ì´ ë°©ë²•ì€ ì „ì²´ì ì¸ í˜•íƒœê°€ ì•„ë‹Œ ì¼ë¶€ ì˜ˆì œë§Œ íŒŒì•…í•œë‹¤ëŠ” ë‹¨ì ì´ ìˆìŒ</p>

<p><strong>ê³ ì°¨ì› Embedding feature analysis 2ë²ˆì§¸ ë°©ë²• - Dimensionality reduction(ì°¨ì› ì¶•ì†Œ)</strong></p>

<p>ìš°ë¦¬ê°€ ì‚¬ëŠ” 3ì°¨ì›(ì‹œê°„ì„ í¬í•¨í•˜ë©´ 4ì°¨ì›) ê³µê°„ì— ë§ê²Œ ê³ ì°¨ì› ê³µê°„ì„ ë‚®ì¶”ëŠ” ë°©ë²•</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310123901553.png" alt=""></p>

<p><strong>[img. ê³ ì°¨ì› ê³µê°„ì„ ì €ì°¨ì› ê³µê°„ìœ¼ë¡œ ë³€í˜•]</strong></p>

<p>ëŒ€í‘œì ì¸ ë°©ë²•ìœ¼ë¡œ t-SNEê°€ ìˆë‹¤</p>

<p>t-distributed stochastic neighbor embedding(t-SNE)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310124022837.png" alt=""></p>

<p><strong>[img. t-SNEë¥¼ í†µí•œ ìˆ«ì ì†ê¸€ì”¨ êµ¬ë¶„(MNIST) feature spaceì˜ visualization]</strong></p>

<ul>
  <li>
    <p>ê³ ì°¨ì› ë°ì´í„°ë¥¼ 2ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•œ ê²°ê³¼</p>
  </li>
  <li>
    <p>3,5,8ì˜ clusterê°€ í•œê» ë­‰ì³ìˆëŠ” ê±¸ë¡œ ë³´ì•„ CNNì´ ë¹„ìŠ·í•˜ë‹¤ê³  ëŠë‚€ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>
  </li>
</ul>

<p><strong>ì¤‘, ê³ ì°¨ì› í•´ì„: Activation investigation 1-Layer activation</strong></p>

<p>Layerì˜ Activationì„ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ íŠ¹ì„±ì„ íŒŒì•…í•˜ëŠ” ë°©ë²•</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310125246083.png" alt=""></p>

<p><strong>[img. AlexNetì˜ Activation ë¶„ì„]</strong></p>

<p>íŠ¹ì • Activationì˜ ì±„ë„(hidden node)ì„ masking í•œë’¤ overlayí•˜ì—¬ ë¬´ìŠ¨ ì¼ì„ í•˜ëŠ” ë…¸ë“œì¸ê°€ ì•Œì•„ë³¼ ìˆ˜ ìˆë‹¤.</p>

<p><strong>ì¤‘ì°¨ì› í•´ì„: Activation investigation 2-Maximally activating patches</strong></p>

<p>ê° ì±„ë„ì˜ hidden nodeì˜ ê°€ì¥ í° ê°’ì„ ê°€ì§€ëŠ” patch(activation)ë¥¼ ê°€ì ¸ì™€ ë‚˜ì—´í•˜ëŠ” ê²ƒ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310125802162.png" alt=""></p>

<p><strong>[img. hidden node ë³„ image patch]</strong></p>

<p>ì´ë¥¼ í†µí•´ ê° íˆë“  ë…¸ë“œê°€ ì°¾ëŠ” ë¶€ë¶„(=í•˜ëŠ” ì¼)ì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>

<p>êµ­ë¶€ì ì´ë¯€ë¡œ ì¤‘ì°¨ì› ì •ë„ í•´ì„ì— ì–´ìš¸ë¦°ë‹¤.</p>

<p>1) íŠ¹ì • layerì˜ íŠ¹ì • channelì„ ê³ ë¥¸ë‹¤.</p>

<p>2) input ì´ë¯¸ì§€ë¥¼ ì§‘ì–´ ë„£ì€ í›„ ì„ íƒí•œ ì±„ë„ì˜ activation ê°’ì„ ì €ì¥í•œë‹¤</p>

<p>3) ìµœëŒ€ activation valueì˜ Receptive fieldë¥¼ Inputì—ì„œ cropí•˜ì—¬ image patchë¡œ ë§Œë“ ë‹¤.</p>

<p><strong>ê²°ê³¼ í•´ì„: Activation investigation 3-Class visualization</strong></p>

<p>ì˜ˆì œ ë°ì´í„° ì‚¬ìš©ì—†ì´ ë„¤íŠ¸ì›Œí¬ê°€ ê¸°ì–µí•˜ëŠ” ì´ë¯¸ì§€ê°€ ë¬´ì—‡ì¸ì§€ íŒë‹¨</p>

<p>ex)ì´ CNNì€ íŠ¹ì • í´ë˜ìŠ¤ì˜ ì´ë¯¸ì§€ë¥¼ ëŒ€ëµ ì–´ë–»ê²Œ ìƒê²¼ë‹¤ê³  ê¸°ì–µí•˜ê³  ìˆëŠ”ê°€?</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310132627390.png" alt=""></p>

<p><strong>[img. CNNì´ ê¸°ì–µí•˜ê³  ìˆëŠ” ê°œì™€ ê°•ì•„ì§€ì˜ ëª¨ìŠµ]</strong></p>

<p>í¸í–¥ ë“±ì„ ì•Œì•„ë³¼ ìˆ˜ë„ ìˆë‹¤. (ex) ìœ„ ìƒˆ ì‚¬ì§„ì€ ë§ì€ ë°ì´í„°ê°€ ë‚˜ë¬´ì™€ í•¨ê»˜ ì°í˜)</p>

<p>\(I^*=\underset{I}{argmaxf(I)}-Reg(I) =\\
I^*=\underset{I}{argmaxf(I)}-\lambda \left\|I\right\|^2_2\\
\lambda \left\|I\right\|^2_2, Reg(I):Regularizaion\ term\\
I: ì˜ìƒ\ ì…ë ¥, f(I):CNN\ ëª¨ë¸\)<br>
<strong>[math. Gradient ascent, ì¼ì¢…ì˜ Loss]</strong></p>

<p>Gradient ascentë¥¼ í†µí•˜ì—¬ Visualizationì„ ìœ„í•œ ì´ë¯¸ì§€ë¥¼ í•©ì„±í•˜ê²Œ ëœë‹¤.</p>

<p>$argmaxf(I)$ë¥¼ í†µí•˜ì—¬ Input image Ië¥¼ ëŒë©° ê° í´ë˜ìŠ¤ì˜ ê°€ì¥ ë†’ì€ ìŠ¤ì½”ì–´ë¥¼ ì–»ëŠ”ë‹¤.</p>

<p>ë„ˆë¬´ í° ìŠ¤ì½”ì–´ ê°’ì´ ë‚˜ì˜¤ëŠ” ê²ƒì„ ë§‰ê³ , ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë°”ê¾¸ê¸° ìœ„í•´ Regularizaion term ì¶”ê°€</p>

<p>ìµœëŒ€ ìŠ¤ì½”ì–´ê°’ì„ ì°¾ìœ¼ë ¤ëŠ” ê³¼ì •ì´ë¯€ë¡œ Gradient ascentì´ë©°, ë¶€í˜¸ë§Œ ë°”ê¾¸ë©´ Gradient descentì´ë¯€ë¡œ í•´ë‹¹ ì•Œê³ ë¦¬ì¦˜ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.</p>

<p>1) ì„ì˜ì˜ ì˜ìƒ(ê²€ì •, í•˜ì–‘, íšŒìƒ‰ í˜¹ì€ ëœë¤í•œ ì´ë¯¸ì§€)ì„ CNNì— ë„£ì–´ ê´€ì‹¬ classì˜ prediction scoreë¥¼ ì¶”ì¶œ</p>

<p>â€‹	- ì²˜ìŒ ì£¼ëŠ” ì˜ìƒë¶€í„° ë°”ë€Œê¸° ì‹œì‘í•˜ë¯€ë¡œ ì´ˆê¸°ê°’ì˜ ì„¤ì •ì— ë”°ë¼ ì™„ì„± ì´ë¯¸ì§€ê°€ ë°”ë€ë‹¤.</p>

<p>2) Backpropagationìœ¼ë¡œ gradient maximizingí•˜ì—¬ ê´€ì‹¬ classì˜ prediction scoreê°€ ë†’ì•„ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ ì…ë ¥ë‹¨ì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë°ì´íŠ¸í•´ì¤€ë‹¤.</p>

<p>3)  ì—…ë°ì´íŠ¸ëœ ì˜ìƒìœ¼ë¡œ 1~2ë¥¼ ê³„ì† ë°˜ë³µí•œë‹¤</p>

<h3 id="Model-decision-explanation">Model decision explanation</h3>

<p>ëª¨ë¸ì´ íŠ¹ì • ì…ë ¥ì„ ì–´ë–¤ ê°ë„ë¡œ í•´ì„í•˜ëŠ” ê°€ì— ëŒ€í•œ ì„¤ëª…</p>

<h4 id="Saliency-test-ê³„ì—´">Saliency test ê³„ì—´</h4>

<p>ì£¼ì–´ì§„ ì˜ìƒì˜ ì œëŒ€ë¡œ íŒì •ë˜ê¸° ìœ„í•œ ê° ì˜ì—­ì˜ ì¤‘ìš”ë„ë¥¼ íŒë³„</p>

<p>ì´ë•Œ ì¤‘ìš”ë„ê°€ í‘œì‹œëœ ê·¸ë¦¼ì„ Saliency mapì´ë¼ê³  í•œë‹¤.</p>

<p><strong>Occlusion map</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310141629430.png" alt=""></p>

<p><strong>[img. Occlusion map ì˜ˆì‹œ]</strong></p>

<p>íŠ¹ì • í”½ì…€ì„ ê°€ë ¤ì„œ ë°”ë€ŒëŠ” Predicdtion score ê°’ì„ Heatmap í˜•ì‹ìœ¼ë¡œ í‘œí˜„í•œ ê²ƒ</p>

<p>ì˜ìƒì˜ ê°€ë¦° ë¶€ë¶„ì— ë”°ë¼, ë§ì´ ë–¨ì–´ì§€ë©´ ì¤‘ìš”í•œ ì˜ì—­ì´ë©° ì ê²Œ ë–¨ì–´ì§€ë©´ ëœ ì¤‘ìš”í•œ ë¶€ë¶„ì´ë‹¤.</p>

<p>ì´ ë–¨ì–´ì§„ ì •ë„ë¥¼ í‘œì‹œí•˜ì—¬ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.</p>

<p><strong>via backpropagtion</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310141852568.png" alt=""></p>

<p><strong>[img. backpropagationì„ ì´ìš©í•œ saliency map ì˜ˆì‹œ, ë°ì€ ë¶€ë¶„ì´ íŒë‹¨ì— ì¤‘ìš”í•œ ì˜ì—­]</strong></p>

<p>ì•ì„œ í–ˆì—ˆë˜ Class visualizationì˜ Gradient ascentì™€ ë¹„ìŠ·</p>

<p>ëœë¤ ì´ë¯¸ì§€ê°€ ì•„ë‹Œ íŠ¹ì • ì´ë¯¸ì§€ë¥¼ classificationì„ í•œ ë’¤, class scoreì— ëŒ€í•œ backpropagationìœ¼ë¡œ ê´€ì‹¬ ì˜ì—­ì˜ ì ìˆ˜ë¥¼ í‘œì‹œí•˜ëŠ” ë°©ë²•</p>

<p>1) ì…ë ¥ ì˜ìƒì„ ë„£ì–´ íŠ¹ì • classì˜ scoreë¥¼ ì–»ì–´ë‚¸ë‹¤</p>

<p>2) Backpropagationìœ¼ë¡œ Inputê¹Œì§€ ì§„í–‰í•´ gradientë¥¼ ì–»ì–´ë‚¸ë‹¤.</p>

<p>3) gradientì˜ ì ˆëŒ€ê°’ ë˜ëŠ” ì œê³±ê°’ì„ í•˜ì—¬ ì–»ì–´ë‚¸ gradientì˜ í¬ê¸°ë¥¼ ì´ë¯¸ì§€í˜•íƒœë¡œ ì–»ëŠ”ë‹¤</p>

<ul>
  <li>ì´ë¥¼ gradient magnitude mapì´ë¼ê³  í•œë‹¤.</li>
  <li>ì´ë¥¼ ì—¬ëŸ¬ë²ˆ ë°˜ë³µí•˜ì—¬ ë”ìš± ì •í™•í•œ Saliency mapë¥¼ ì–»ì–´ë‚¼ ìˆ˜ ìˆë‹¤.</li>
</ul>

<p>backpropagationì„ ì´ìš©í•œ ë” ì§„ë³´ì ì¸ visualization ë°©ë²•ìœ¼ë¡œ <em>Deconvolution</em>ì´ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310205954715.png" alt=""></p>

<p><strong>[img. Dconvolutionì˜ ê²°ê³¼ë¬¼]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310205930822.png" alt=""></p>

<p><strong>[img. ReLUì˜ ì‘ìš©ê³¼ deconvnetì˜ ì°¨ì´]</strong></p>

<p>ë³´í†µ CNNì˜ ê²½ìš° Forward pass ì‹œ ìŒìˆ˜ëŠ” ReLU í•¨ìˆ˜ë¥¼ í†µê³¼í•˜ë©° 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ë˜ë©°,</p>

<p>Backward pass ì‹œ ì´ë¥¼ ê¸°ì–µí•˜ì—¬, í•´ë‹¹ í”½ì…€ì„ ë‹¤ì‹œ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•œë‹¤.</p>

<p>í•˜ì§€ë§Œ deconvnetì€ backward ì‹œ Forward passë•Œ ì²˜ëŸ¼ ìŒìˆ˜ê°€ 0ìœ¼ë¡œ ë§ˆìŠ¤í‚¹ëœë‹¤.<br>
\(ReLU:h^{l+1}=max(0,h^l)\\
backpropagation:\frac{\partial L}{\partial h^l}=[(h^l&gt;0)]\frac{\partial L}{\partial h^{l+1}}\\
deconvnet:\frac{\partial L}{\partial h^l}=[(h^{l+1}&gt;0)]\frac{\partial L}{\partial h^{l+1}}\)<br>
<strong>[math. ê¸°ì¡´ì˜ passì™€ deconvnetì˜ passì˜ ìˆ˜ì‹í™”]</strong></p>

<p>ë˜í•œ, ê¸°ì¡´ì˜ ë°©ë²•ê³¼ deconvnetì˜ And ì—°ì‚°í•˜ì—¬ ë§Œë“  Guided Backpropagation ë˜í•œ ê°€ëŠ¥í•˜ë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310212138122.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">$\frac{\partial L}{\partial h^l}=[(h^{l+1}&gt;0)\&amp;(h^{l+1}&gt;0)]\frac{\partial L}{\partial h^{l+1}}$</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Guided backpropagation]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310212829292.png" alt=""></p>

<p><strong>[img. Guided backpropagationê³¼ ë‹¤ë¥¸ ë°©ë²•ë“¤ ë¹„êµ]</strong></p>

<p>ìˆ˜í•™ì ìœ¼ë¡œ êµ¬í•œ ê²ƒì´ ì•„ë‹ˆë¼ ê²½í—˜ì ìœ¼ë¡œ êµ¬í–ˆì§€ë§Œ ê²°ê³¼ëŠ” ê´œì°®ê²Œ ë‚˜ì˜¨ë‹¤ê³  í•œë‹¤.</p>

<p>forward ì‹œ ê²°ê³¼ë¥¼ ë¯¸ì¹œ ì–‘ìˆ˜ pixelê³¼ backward ì‹œ â€˜ì´ ë¶€ë¶„ì€ ì¦í­í•˜ë¼â€™ì˜ ì˜ë¯¸ë¥¼ ê°€ì§„ ì–‘ìˆ˜ pixelë§Œ ë°›ì•„ë“¤ì¸ ê²°ê³¼ =&gt; ì¦‰ classificationì— ê¸ì •ì  ì˜í–¥ì„ ë¼ì¹œ pixelë§Œ í‘œì‹œë˜ê²Œ ë¨</p>

<p><strong>Class activation mapping(CAM)</strong></p>

<p>ì–´ë–¤ ë¶€ë¶„ì„ ì°¸ì¡°í•˜ì—¬ ê²°ê³¼ê°€ ë‚˜ì™”ëŠ”ì§€ ë³´ì—¬ì¤Œ.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310214251783.png" alt=""></p>

<p><strong>[img. CAM ì˜ˆì‹œ]</strong></p>

<p>ê¸°ì¡´ì˜ CNN êµ¬ì¡°ë¥¼ ì¡°ê¸ˆ ë°”ê¾¸ì–´ì•¼ í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310220029775.png" alt=""></p>

<p><strong>[img. CAMì„ ì“¸ ìˆ˜ ìˆê²Œ ê°œì¡°ëœ CNN]</strong></p>

<p>ê¸°ì¡´ì˜ ì¶œë ¥ ì´ì „ì˜ FC Layer ëŒ€ì‹  Conv Layer ì´í›„ì— Global average pooling (GAP) Layerì™€ FC layer í•œ ì¸µì´ ì‚½ì…ëœë‹¤.</p>

<p>ì´í›„ Classificationì— ëŒ€í•´ ì¬í•™ìŠµëœë‹¤.<br>
\(S_c=\overset{Channels}{\sum_k}w_k^c\overset{GAP\ feature}{F_k}\overset{GAP}{=}\sum_kw_k^c\sum_{(x,y)}\overset{Feature\ map\\before\ Gap}{f_k(x,y)}=\\
\sum_{(x,y)}\ \ \overset{CAM_c(x,y)}{\sum_kw_k^cf_k(x,y)}\\
S_c:Score\ of\ the\ class\ c\\
k: ë§ˆì§€ë§‰\ conv\ layer\ channel\ ìˆ˜\)<br>
<strong>[math. CAMì´ í¬í•¨ëœ CNN êµ¬ì¡° ìœ ë„]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310221704489.png" alt=""></p>

<p><strong>[img. GAP layer ë¶€ë¶„ì˜ ì‘ìš©]</strong></p>

<p>(+) ì„±ëŠ¥ì´ ì¢‹ì•„ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” Visualization ë°©ë²•</p>

<p>(+) ê³µê°„ ì •ë³´ë¥¼ ì£¼ì§€(supervision?) ì•Šì•„ë„ ê³µê°„ì— ëŒ€í•œ ì •ë³´ê°€ ë‚˜íƒ€ë‚¨</p>

<p>ì´ë¥¼ í†µí•´ bounding boxë¥¼ ì³ì£¼ë©´ object detectionìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥</p>

<ul>
  <li>Weakly supervised learningì´ë¼ê³  í•¨</li>
</ul>

<p>(-) êµ¬ì¡°ë¥¼ ë°”ê¾¸ê³  ì¬í•™ìŠµì„ í•´ì•¼í•˜ë©°, ì´ ê³¼ì •ì—ì„œ ì„±ëŠ¥ì´ ë°”ë€” ìˆ˜ ìˆë‹¤ëŠ” ì ì´ ë‹¨ì </p>

<p><strong>Grad-CAM</strong></p>

<p>êµ¬ì¡°ë¥¼ ë°”ê¾¸ì§€ ì•Šì•„ë„ í™œìš©í•  ìˆ˜ ìˆëŠ” CAM êµ¬ì¡°</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310222311528.png" alt=""></p>

<p><strong>[img. Grad-CAMì˜ ì˜ˆì‹œ]</strong></p>

<p>(+) CAMê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥, êµ¬ì¡°ë¥¼ ë°”ê¾¸ì§€ ì•Šì•„ë„ ë¨</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310222717615.png" alt=""></p>

<p><strong>[img. Grad-CAMì˜ êµ¬ì¡°]</strong></p>

<p>$\overset{CAM_c(x,y)}{\sum_kw_k^cf_k(x,y)}$ ë¶€ë¶„ì—ì„œ $w_k^c$(importance wieghts)ë§Œ êµ¬í•˜ë©´ ë§µì„ ê·¸ë¦´ ìˆ˜ ìˆë‹¤.</p>

<p>Backpropagationì„ Input ì´ë¯¸ì§€ê°€ ì•„ë‹Œ ê´€ì‹¬ì„ ê°€ì§€ëŠ” activation mapê¹Œì§€ë§Œ ì§„í–‰í•˜ë©°, ê·¸ë ‡ê²Œ êµ¬í•œ importance weight ($\alpha_k^c$)ì™€ activation map($A^k$)ë¥¼ ì„ í˜•ê²°í•©í•˜ì—¬ ReLUë¥¼ ì”Œì›Œ ì–‘ìˆ˜ê°’ë§Œ ì‚¬ìš©<br>
\(\overset{Global\ average\ pooling}{\alpha^c_k=\frac{1}{Z}\sum_i \sum_j \frac{\partial y^c}{\partial A_{ij}^k}}\\
L^c_{Grad-CAM}=ReLU(\sum_k\alpha^c_kA^k)\\
\alpha^c_k: importance\ weight\ of\ the\ k-th\ feature\ map\ w.r.t\ the\ class\ c\\
\frac{\partial y^c}{\partial A_{ij}^k} : Gradients\ via\ backprop\)<br>
<strong>[math. Grad-CAM ìˆ˜ì‹]</strong></p>

<p>ì˜ìƒ ì¸ì‹ ë¿ë§Œ ì•„ë‹ˆë¼ CNN êµ¬ì¡°ë§Œ ì¡´ì¬í•˜ë©´ ì–´ë–¤ Taskì—ë„ í™œìš© ê°€ëŠ¥</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310224715849.png" alt=""></p>

<p><strong>[img. Grad-CAM í™œìš© ì˜ˆì‹œì™€ Guided Grad-CAM]</strong></p>

<p>ì¶”ê°€ë¡œ Guided Backpropì„ ì¶”ê°€í•˜ê³ , Grad-CAMì„ ë‚´ì í•˜ì—¬ Guided Grad-CAMì„ êµ¬í•˜ëŠ” ê²ƒì´ ì¼ë°˜í™” ë˜ì–´ìˆë‹¤.</p>

<ul>
  <li>Guided Backprop(sharp í•˜ì§€ë§Œ class êµ¬ë¶„ ë¶ˆê°€) + Grad-CAM (Roughí•˜ê³  smoothí•˜ì§€ë§Œ class êµ¬ë¶„ ê°€ëŠ¥) = Guided Grad-CAM (ì„œë¡œ ë‹¨ì  ë³´ì™„)</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310225109232.png" alt=""></p>

<p><strong>[img. SCOUTER ì˜ˆì‹œ]</strong></p>

<p>ìµœê·¼ì—ëŠ” í•´ì„ ê²°ê³¼ì— ëŒ€í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µì„ ì¤„ ìˆ˜ ìˆëŠ” Visualization ë°©ë²•(SCOUTER)ë„ ë“±ì¥í•¨</p>

<p>Visualization ê¸°ìˆ ì„ ì‘ìš©í•´ GANì— ì´ìš©í•˜ì—¬ ëª…ë ¹ì„ ë‚´ë¦´ ìˆ˜ ìˆìŒ(GAN dissection)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310225451782.png" alt=""></p>

<p><strong>[img. í‘œì‹œí•œ ë¶€ë¶„ì— ë¬¸ì„ ìƒì„±í•˜ëŠ” ì˜ˆì‹œ]</strong></p>

<h2 id="Instance-panoptic-segmentation-and-landmark-localization">Instance/panoptic segmentation and landmark localization</h2>

<p>Semantic segmentation, Object Detectionì€ ë”ìš± ì–´ë ¤ìš´ Taskë¡œ ê³ ë„í™”ë˜ë©´ì„œ ì—°êµ¬ê°€ ì¤„ì–´ë“¦</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094300040.png" alt=""><br>Original Image</th>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094309340.png" alt=""><br>Semantic segmentation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094320216.png" alt=""><br><strong>Instance segmentation</strong></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210310094328026.png" alt=""><br><strong>Panoptic segmentation</strong></td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Image ì¸ì‹ Tasks]</strong></p>

<p>Instance segmentation, Panoptic segmentationì€ ììœ¨ì£¼í–‰ ë“±, ì‚°ì—… ë“±ì—ì„œ ë§ì´ ì“°ì„</p>

<h3 id="Instance-segmentation">Instance segmentation</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311123630521.png" alt=""></p>

<p><strong>[img. Instance segmentation vs Semantic segmentation]</strong></p>

<p>ê°™ì€ ë¬¼ì²´ class ë¼ë„ Instanceê°€ ë‹¤ë¥´ë©´ êµ¬ë¶„í•´ì•¼í•˜ëŠ” ë¬¸ì œ, ì‹¤ì œ ì‘ìš©ì‚¬ë¡€ ë§ì´ ì‚¬ìš©ë¨</p>

<p>Object Detection ëª¨ë¸ë“¤ì˜ ì—°ì¥í•´ì„œ ë§ì´ ì‚¬ìš© ë¨.</p>

<h4 id="Mask-R-CNN">Mask R-CNN</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311124009152.png" alt=""></p>

<p><strong>[img. Mask R-CNN = Faster R-CNN + Mask branch]</strong></p>

<p>Faster R-CNNê³¼ ì—¬ëŸ¬ ëª¨ë¡œ ë¹„ìŠ·í•˜ì§€ë§Œ ê°œì„ ì„ ë§ì´ ì‹œí‚´</p>

<ol>
  <li>RoI pooling ëŒ€ì‹ , ì •êµí•œ ì†Œìˆ˜ì  ì¢Œí‘œë„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆëŠ” RoIAlign pooling layer ì‚¬ìš©</li>
  <li>ë§ˆì§€ë§‰ layerì— ë³‘ë ¬ë¡œ mask branchë¼ëŠ” Fully convolutional Networkê°€ ì¶”ê°€ë˜ì–´ Outputì„ Upsampling ë’¤, class ìˆ˜ë§Œí¼ì˜ ì±„ë„(ì—¬ê¸°ì„œëŠ” 80ê°œ)ì— Binary classification
    <ul>
      <li>class ì˜ˆì¸¡ê²°ê³¼ë¥¼ ê°€ì ¸ì™€ ì°¸ì¡°í•  maskë¥¼ ì •í•¨</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311124414989.png" alt=""></p>

<p><strong>[img. R-CNN familyì˜ ì¶”ê°€]</strong></p>

<p>ê·¸ë¦¼ì˜ ì˜ˆì‹œ branch ëŒ€ì‹ , Key point branch ë¼ëŠ” ê²ƒì„ ì¶”ê°€í•˜ë©´ ì‚¬ëŒì˜ ìì„¸ë¥¼ ì¶”ì •í•˜ëŠ” Taskë„ ê°€ëŠ¥</p>

<h4 id="YOLACT-You-Only-Look-At-CoefficienTs">YOLACT(You Only Look At CoefficienTs)</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311124722607.png" alt=""></p>

<p><strong>[img. YOLACT êµ¬ì¡°]</strong></p>

<p>ì‹¤ì‹œê°„ Instance segmentation model</p>

<ol>
  <li>Feature Pyramid êµ¬ì¡°ë¥¼ ì´ìš©í•´ ê³ í•´ìƒë„ì´ë©°,</li>
  <li>Protonet ë¶€ë¶„ì—ì„œ Maskì˜ ì €í•´ìƒë„ì˜ Prototype Soft segmentation componentë¥¼ ì¶”ì¶œí•œ ë’¤,</li>
  <li>Prediction Headì—ì„œ ê° Class ê°„ì˜ Mask Coefficientsë¥¼ êµ¬í•˜ì—¬ ì´ë¥¼ ì´ìš©í•´ 2ë²ˆì˜ prototypeì™€ ì„ í˜•ê²°í•©(Weighted Sum)í•˜ì—¬ detectionì— ì í•©í•œ Classë³„ Mask Mapì„ ë§Œë“¤ì–´ì¤€ë‹¤.</li>
  <li>ì´í›„ Cropê³¼ Threshholdë¥¼ í†µí•´ ê²°ê³¼ë¥¼ ë„ì¶œ</li>
</ol>

<h4 id="YolactEdge">YolactEdge</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311125500858.png" alt=""></p>

<p><strong>[img. YolactEdge êµ¬ì¡°]</strong></p>

<p>ìœ„ì˜ YOLACTë¥¼ ë”ìš± ê²½ëŸ‰í™”í•˜ì—¬ ì˜ìƒ ì²˜ë¦¬ë¥¼ ì†Œí˜•ê¸°ê¸°ë“¤ì— ì‚¬ìš©ê°€ëŠ¥í•œ ëª¨ë¸</p>

<p>ì´ì „ frameì˜ featureë¥¼ ë‹¤ìŒ keyframeì— í™œìš©í•˜ì—¬ ì—°ì‚°ëŸ‰ ì¤„ì„ (ì„±ëŠ¥ ë¹„ìŠ·, ì†ë„ ë¹ ë¦„)</p>

<p>ì•„ì§ì€ í˜„ì‹¤ì— ì‚¬ìš©í•˜ê¸° í˜ë“  ì„±ëŠ¥</p>

<h3 id="Panoptic-segmentation">Panoptic segmentation</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311125730327.png" alt=""></p>

<p><strong>[img. Panoptic segmentation vs Semantic segmentation]</strong></p>

<p>ë°°ê²½ì •ë³´ + instnace êµ¬ë¶„ ê°€ëŠ¥</p>

<h4 id="UPSNet">UPSNet</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311125929668.png" alt=""></p>

<p><strong>[img. UPSNet ì˜ˆì‹œ]</strong></p>

<p>FPN(feature pyrmid network) êµ¬ì¡°ì— ë³‘ë ¬ë¡œ êµ¬ì„±ëœ semeantic Headì™€ Instance head ê·¸ë¦¬ê³  ì´ë¥¼ ë³‘í•©í•˜ëŠ” Panoptic Headë¡œ êµ¬ì„±ëœ êµ¬ì¡°</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311130255661.png" alt=""></p>

<p><strong>[img. Panoptic Headì˜ ìì„¸í•œ êµ¬ì¡°]</strong></p>

<p>Instance headì˜ Instance Mask Outputì˜ ê²½ìš° ë¦¬ì‚¬ì´ì§•ê³¼ íŒ¨ë”©ì„ ê±°ì¹œ í›„ Semnatic headì˜ ë¬¼ì²´ maskì™€ í•©í•´ì§„ ë’¤, output ì±„ë„ë¡œ concat</p>

<ul>
  <li>ì´ë¥¼ í†µí•´ ìœ„ì¹˜ë¥¼ ì•Œ ìˆ˜ ìˆìŒ</li>
</ul>

<p>Semantic headì˜ ë¬¼ì²´ mask Outputì˜ ê²½ìš°, ìœ„ì˜ Instance maskì™€ ì‚¬ìš©ëœ ê²°ê³¼ë“¤ì€ Maxëœ ë’¤ ê¸°ì¡´ ë¬¼ì²´ maskì—ì„œ ë¹ ì§„ ë’¤ 1ì±„ë„ë¡œ outputì— ì¶”ê°€ë¨</p>

<ul>
  <li>ëª¨ë‘ ë¹ ì§€ê³  ë‚¨ì€ ë¬¼ì²´ maskëŠ” Unknown maskê°€ ëœë‹¤.(classì— ì •ì˜ë˜ì§€ ì•Šì€ ë¬¼ì²´)</li>
</ul>

<p>Semantic headì˜ ë°°ê²½ì •ë³´ Mask Outputì€ ê·¸ëŒ€ë¡œ Output ì±„ë„ì— ì¶”ê°€ë¨</p>

<h4 id="VPSNet">VPSNet</h4>

<p>ì˜ìƒì— ì‚¬ìš©ê°€ëŠ¥í•œ Panoptic segmetnation ëª¨ë¸</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311131747338.png" alt=""></p>

<p><strong>[img. VPSNet êµ¬ì¡°]</strong></p>

<ol>
  <li>
    <p>ë‘ í”„ë ˆì„ê°„ì˜ ëª¨ì…˜ë§µ(í•´ë‹¹ í”½ì…€ì´ ë‹¤ìŒ í”„ë ˆì„ì— ì–´ë””ë¡œ ìœ„ì¹˜ê°€ ë°”ë€Œì—ˆëŠ”ê°€?)ë¥¼ ì´ì „ í”„ë ˆì„ feature mapì— ì ìš©í•˜ì—¬ featureì˜ ì›€ì§ì„ì„ trackingí•œ ë’¤, FPNì„ í†µí•´ ë½‘ì€ í•´ë‹¹ featrue mapì— í•©ì³ì„œ ì‚¬ìš©</p>
  </li>
  <li>
    <p>Track headë¥¼ í†µí•´ ì´ì „ í”„ë ˆì„ê³¼  í˜„ì¬ í”„ë ˆì„ ê°„ì˜  RoI feature ì—°ê´€ì„±ì„ ì°¾ì•„ë‚¸ë‹¤.</p>
  </li>
  <li>
    <p>ì´í›„ UPS Netê³¼ ë¹„ìŠ·í•¨</p>
  </li>
</ol>

<h3 id="Landmark-localization">Landmark localization</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311133106112.png" alt=""></p>

<p><strong>[img. Landmark localization ì˜ˆì‹œ]</strong></p>

<p>key point í˜¹ì€ landmark ë¼ê³  ë¶ˆë¦¬ìš°ëŠ” ì˜ìƒì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ì •ì˜í•˜ì—¬ ìœ„ì¹˜ì™€ classë¥¼ ì¶”ì í•˜ëŠ” ê²ƒ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311133426838.png" alt=""></p>

<p><strong>[img. Coordinate regression vs Heatmap classification]</strong></p>

<p>ê¸°ì¡´ì˜ box bounding ì°¾ë˜ ë°©ë²•(Coordinate regression)ìœ¼ë¡œ keypointë¥¼ ì°¾ìœ¼ë ¤ê³  í•˜ë‹ˆ ë¬¸ì œê°€ ìˆì—ˆê³  Heatmap classificationì´ ì¢€ë” ì •í™•í•˜ì§€ë§Œ ê³„ì‚°ëŸ‰ì´ í¼</p>

<ul>
  <li>ê° ì±„ë„ì— keypointë¥¼ í• ë‹¹í•˜ê³  classë¡œ ìƒê°í•¨</li>
</ul>

<p>Gaussian Heat mapì„ í˜•ì„±í•˜ê¸° ìœ„í•´ Landmark locationì„ ë‹¤ìŒê³¼ ê°™ì´ ë³€í˜•í•œë‹¤. <br>
\(G_\sigma(x,y) = \exp\left(-\frac{(x-x_c)^2+(y-y_c)^2}{2\sigma^2}\right)\\
(x_c, y_c):center\ location\)<br>
<strong>[math. points to Gaussian ìˆ˜ì‹]</strong></p>

<p>ì‰½ê²Œ ë§í•´ í•´ë‹¹ location ì¢Œí‘œë¥¼ í‰ê· ì ìœ¼ë¡œ ì‚¼ê³  ì£¼ë³€ì— Gaussianì„ ì”Œìš´ë‹¤.</p>

<p>Heatmap í˜•ì‹ì„ ì‚¬ìš©í•˜ë©´ generalization ì„±ëŠ¥ì´ ì¢‹ì•„ì§.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311135139848.png" alt=""></p>

<p><strong>[img. Gaussian ë„ì‹]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generate gaussian
</span><span class="n">size</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">+</span> <span class="mi">1</span> <span class="c1"># ì¶œë ¥ í•´ìƒë„ í¬ê¸°
# ëª¨ë“  ì˜ìƒ ì¢Œí‘œì˜ ë°°ì—´
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">arrange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> 

<span class="n">x0</span> <span class="o">=</span> <span class="n">y0</span> <span class="o">=</span> <span class="n">size</span> <span class="o">//</span> <span class="mi">2</span> <span class="c1"># ì¤‘ê°„ì´ í‰ê· ì ì´ë¼ê³  ê°€ì •
# numpyì˜ í–‰ë ¬ ë§ì…ˆì˜ ê²½ìš° sx1, 1Xsê°€ ë”í•´ì§€ë©´ sxs í–‰ë ¬ì´ ë‚˜ì˜´ 
</span>
<span class="c1"># The gaussian is not normalized, we want the center value to equal 1
</span><span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="o">&amp;</span><span class="c1">#39;Gaussain&amp;#39;:
</span>    <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span> <span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="o">&amp;</span><span class="c1">#39;Cauchy&amp;#39;:
</span>    <span class="n">g</span> <span class="o">=</span> <span class="n">sigma</span> <span class="o">/</span> <span class="p">(((</span><span class="n">x</span> <span class="o">-</span> <span class="n">x0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y0</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">sigma</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mf">1.5</span><span class="p">)</span>

</code></pre></div></div>
<p><strong>[code. Gaussian ì½”ë“œ êµ¬í˜„ ]</strong></p>

<p>ë°˜ëŒ€ë¡œ ê°€ìš°ì‹œì•ˆì˜ ê²°ê³¼ê°’ì„ ì¢Œí‘œí‰ë©´ìœ¼ë¡œ ë°”ê¾¸ì–´ì„œ ê²°ê³¼ê°’ì„ ë³´ì—¬ì£¼ëŠ” ìˆ˜ì‹ë„ í•„ìš”í•˜ë‹¤.</p>

<h4 id="Hourglass-network">Hourglass network</h4>

<p>Landmarkë¥¼ ìœ„í•œ íŠ¹ë³„í•œ êµ¬ì¡°</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311142756433.png" alt=""></p>

<p><strong>[img. Stacked hourglass êµ¬ì¡°]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311143026096.png" alt=""></p>

<p><strong>[img. í™•ëŒ€í•œ hourglass êµ¬ì¡°]</strong></p>

<p>UNet êµ¬ì¡°ë¥¼ ì—¬ëŸ¬ ìŠ¤íƒ ìŒ“ì€ê²ƒê³¼ ë¹„ìŠ·í•œ êµ¬ì¡°</p>

<ul>
  <li>ë‹¤ë§Œ Concatì´ ì•„ë‹ˆë¼ í•©ìœ¼ë¡œ ë˜ì–´ìˆìœ¼ë©°, ê·¸ëƒ¥ skipí•´ì„œ ì£¼ì–´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ convolution layerë¥¼ í•˜ë‚˜ í†µê³¼í•¨</li>
  <li>UNetë³´ë‹¤ FPNêµ¬ì¡°ì™€ ì¢€ë” ìœ ì‚¬í•¨</li>
</ul>

<p>í¬ê¸°ë¥¼ ì¤„ì—¬ Receptive fieldë¥¼ ëŠ˜ë¦° êµ¬ì¡°</p>

<h4 id="DensePose">DensePose</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311143258133.png" alt=""></p>

<p><strong>[img. imageì˜ UV Map í‘œí˜„]</strong></p>

<p>ëª‡ ê°œ í”½ì…€ì´ ì•„ë‹Œ ì‹ ì²´ ì „ë¶€ ê°™ì€ ì•„ì£¼ Denseí•œ landmarkë¥¼ êµ¬í•˜ì—¬ 3D UV map ìƒì„± ê°€ëŠ¥</p>

<ul>
  <li>3D ëª¨ë¸ì„ ë§Œë“œëŠ” ë°©ë²•ì€ ë‹¤ë¥¸ ë°©ë²•ì„.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311143422824.png" alt=""></p>

<p><strong>[img. UVMap ì˜ˆì‹œ]</strong></p>

<p>UV map : 3D ë§¤ì‰¬ì˜ í‰ë©´ í‘œí˜„</p>

<p>ê° pixelì˜ ì ì˜ ì •ì²´ì„±ì´ ì˜ìƒ ë‚´ë¶€ì—ì„œ ìœ ì§€ë˜ë©´ì„œ ìœ„ì¹˜ë§Œ ë°”ë€ë‹¤.</p>

<p>ì¦‰ ì•„ì£¼ ë§ì€ Landmark ê²€ì¶œì€ ê³§, UV map ìƒì„±ì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311145459415.png" alt=""></p>

<p><strong>[img. DensePoseì˜ êµ¬ì¡°]</strong></p>

<p>DensePose R-CNN = Faster R-CNN + 3D surface regression branch</p>

<ul>
  <li>Patch: ê° body partì˜ sementation map(íŒ”,ë‹¤ë¦¬,ë¨¸ë¦¬)</li>
</ul>

<p>Mask R-CNNê³¼ë„ ë¹„ìŠ·í•˜ë‹¤.</p>

<p>ë°ì´í„° í‘œí˜„ë°©ë²•ê³¼ ë°ì´í„°ì…‹ì„ ì œê³µí•œ ë…¼ë¬¸</p>

<h4 id="RetinaFace">RetinaFace</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311150521526.png" alt=""></p>

<p><strong>[img. RetinaFaceì˜ êµ¬ì¡°]</strong></p>

<p>FPN êµ¬ì¡°ì— ë‹¤ì–‘í•œ branch ë„ì…í•´ Multi taskê°€ ê°€ëŠ¥í•˜ê²Œ í•œ ëª¨ë¸</p>

<p>ì—¬ëŸ¬ Taskë¡œ í•™ìŠµ ì‹œ, ì ì€ ë°ì´í„°ë¡œë„ Backbone ë„¤íŠ¸ì›Œí¬ í•™ìŠµì´ ê°•í•˜ê³  ì„±ëŠ¥ì¢‹ê²Œ ì˜ í•™ìŠµëœë‹¤.</p>

<p>Extension pattern : CVì—ì„œì˜ ë””ìì¸ íŒ¨í„´ ì¤‘ í•˜ë‚˜, ë‹¤ë¥¸ êµ¬ì¡°ë„ branchë¥¼ ì¶”ê°€í•˜ì—¬ ì—¬ëŸ¬ Taskì— í™œìš© ê°€ëŠ¥</p>

<h3 id="Detecting-objects-as-keypoints">Detecting objects as keypoints</h3>

<p>Bounding boxë¥¼ ì°¾ì„ ë•Œ, keypoint(ì¤‘ì•™, ì½”ë„ˆ)ë¥¼ ì‹œì‘ì ìœ¼ë¡œ ì°¾ëŠ” êµ¬ì¡°ë“¤</p>

<h4 id="CornerNet">CornerNet</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311151003579.png" alt=""></p>

<p><strong>[img. CornerNet êµ¬ì¡°]</strong></p>

<p>ì¢Œì¸¡ ìƒë‹¨, ìš°ì¸¡ í•˜ë‹¨ì˜ ì  2ê°œë¥¼ ì°¾ì•„ Bounding boxë¡œ ì‚¼ëŠ” êµ¬ì¡°</p>

<p>ë³‘ë ¬ì ìœ¼ë¡œ 2ê°œë¡œ ë‚˜ëˆˆ ë’¤, ë¨¼ì € Heatmapì—ì„œ ì ì˜ ìœ„ì¹˜ë¥¼ ì°¾ê³ , ê·¸ ì ì˜ classì„ ì˜ë¯¸í•˜ëŠ” Embeddingì„ ì°¾ì€ ë’¤ ê²°í•©í•œë‹¤.</p>

<p>single-stage êµ¬ì¡°ì´ë©°, ì„±ëŠ¥ì€ ì¡°ê¸ˆ ë–¨ì–´ì§€ì§€ë§Œ ì†ë„ê°€ ë¹ ë¥´ë‹¤.</p>

<h4 id="CenterNet">CenterNet</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311151752192.png" alt=""></p>

<p><strong>[img. Centernet 1 ì˜ˆì‹œ]</strong></p>

<p>ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸°ìœ„í•´ ì¤‘ì•™ì  ë˜í•œ ê²€ì¶œí•¨</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311151845802.png" alt=""></p>

<p><strong>[img. CenterNet 2 ì˜ˆì‹œ]</strong></p>

<p>ì–´ì°¨í”¼ ì¤‘ì•™ì ê¹Œì§€ 3ê°œë¥¼ êµ¬í•  êº¼ë©´ width, height, center pointë¡œ ê²€ì¶œ ì •ë³´ë¥¼ ë°”ê¾¼ ëª¨ë¸</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311152058073.png" alt=""></p>

<p><strong>[img. ì„±ëŠ¥ ë¹„êµ]</strong></p>

<p>CenterNetì´ ì„±ëŠ¥ê³¼ ì†ë„ë©´ì—ì„œ ìš°ìœ„ë¥¼ ë³´ì¸ë‹¤.</p>

<h2 id="Conditional-Generative-Model-cGAN">Conditional Generative Model(cGAN)</h2>

<p>ì‚¬ìš©ìê°€ ì»¨íŠ¸ë¡¤ ê°€ëŠ¥í•œ Generative Modelì„ ì˜ë¯¸</p>

<h3 id="Conditional-generative-model-cGAN">Conditional generative model(cGAN)</h3>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311153324899.png" alt=""></p>

<p><strong>[img. Generative Model VS Conditional Generative Model]</strong></p>

<p>ëœë¤í•œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ëŠ” Generative Modelê³¼ ë‹¬ë¦¬ Conditional Generative Modelì€ ì£¼ì–´ì§„ ì¡°ê±´ì— ë”°ë¼ ìƒì„±í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311153608344.png" alt=""></p>

<p><strong>[img. Low quality audio -&gt; high quality audio]</strong></p>

<p>ì˜¤ë””ì˜¤ ìŒì§ˆ í–¥ìƒ, ì¸ê³µì§€ëŠ¥ ë‰´ìŠ¤ ë“± ì—¬ëŸ¬ ë°©ë©´ì— í™œìš© ê°€ëŠ¥</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311153921357.png" alt=""></p>

<p><strong>[img. GANì˜ ì›ë¦¬]</strong></p>

<p>ë³´í†µ ìœ„ì¡° ì§€íë²”(Generator)ê³¼ ì§€í ê°ë³„ì(Discriminator)ë¡œ ë¹„ìœ í•˜ë©°, GeneratorëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ ê°€ì§œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  DiscriminatorëŠ” ì´ë¥¼ ê°€ì§œì¸ì§€ ì§„ì§œì¸ì§€ êµ¬ë³„í•´ë³¸ë‹¤.</p>

<p>Discriminatorê°€ ê°ë³„í•´ë‚´ë©´ í•´ë‹¹ lossê°€ Generatorë¥¼ í•™ìŠµì‹œí‚¤ê³ , Generatorê°€ Discriminatorë¥¼ ì†ì´ë©´ Discriminatorê°€ í•´ë‹¹ Lossë¡œ í•™ìŠµë˜ëŠ” ìƒí˜¸ ë³´ì™„ì ì¸ ëª¨ë¸ì´ë‹¤. (Adversarial Training, ì ëŒ€ì  í•™ìŠµë²•)</p>

<p>ì´ëŸ¬í•œ Adversarial Trainingì„ ì´ìš©í•˜ëŠ” Generative modelì„ Generative Adversarial Network ì¦‰, GANì´ë¼ê³  ë¶€ë¥¸ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311155857602.png" alt=""></p>

<p><strong>[img. Basic GAN vs Conditional GAN(cGAN)]</strong></p>

<p>ê¸°ë³¸ GANì˜ ê²½ìš° Generatorì— ëœë¤í•œ zë¥¼ ë„£ê³  ìƒì„±í•œ ê²°ê³¼ë¥¼ Discrminatorê°€ íŒë³„í•˜ëŠ” êµ¬ì¡°</p>

<p>Conditional GANì€ zëŠ” ì˜µì…˜ìœ¼ë¡œ ë„£ê³  Cë¼ëŠ” ì¡°ê±´ì„ ë„£ì–´ì£¼ëŠ” ë¶€ë¶„ì´ ë‹¤ë¥´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210311182255485.png" alt=""></p>

<p><strong>[img. Conditional GANë¥¼ ì´ìš©í•œ ì´ë¯¸ì§€ì˜ í™”í’ ë°”ê¾¸ê¸°]</strong></p>

<p>ì´ì™¸ì—ë„ ê·¸ë¦¼ì˜ í™”ì§ˆì„ ì¢‹ê²Œ ë°”ê¾¸ëŠ” Super resolution, í‘ë°±ì´ë‚˜ ì±„ìƒ‰ ë˜ì§€ ì•Šì€ ê·¸ë¦¼ ì±„ìƒ‰ ë“±ì˜ ì¼ì— ì‚¬ìš©ëœë‹¤.</p>

<p>ì˜ˆë¥¼ ë“¤ì–´ ì €í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ê³ í•´ìƒë„ë¡œ ë°”ê¾¸ëŠ” Super resolutionì´ ëŒ€í‘œì ì¸ cGAN í™œìš©ì˜ ì˜ˆì‹œì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312123342201.png" alt=""></p>

<p><strong>[img. Super Resoultionì— ì‚¬ìš©ë˜ë˜ ê³¼ê±° êµ¬ì¡°(Naive Regression Model)ì™€ GAN êµ¬ì¡°]</strong></p>

<p>Low Resolution ì´ë¯¸ì§€ë¥¼ GANì—ì„œëŠ” High Resolution ì´ë¯¸ì§€ë¡œ ë°”ê¾¸ê³  ì´ë¥¼ Discriminatorê°€ í•™ìŠµí•˜ë©´ì„œ ì´ë£¨ì–´ì§„ë‹¤.</p>

<p>ê³¼ê±°ì—ëŠ” Naive Regression modelì´ë¼ëŠ” ì¢€ë” ë‹¨ìˆœí•œ Lossë¥¼ Discriminator ëŒ€ì‹  ì‚¬ìš©í•œ êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">MSE VS GAN ê²°ê³¼ë¬¼ ë¹„êµ</th>
      <th style="text-align: center">MAE/MSE loss</th>
      <th>&nbsp;</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312122128991.png" alt=""></td>
      <td style="text-align: center">$MAE = \frac{1}{n}\sum^n_{i=1}</td>
      <td>y_i-\hat{y}_i</td>
      <td>\MSE=\frac{1}{n}\sum^n_{i=1}(y_i-\hat{y}_i)^2$</td>
    </tr>
  </tbody>
</table>

<p><strong>[tables. GAN loss vs MAE/MSE loss]</strong></p>

<p>MAEëŠ” ê²°ê³¼ì™€ì˜ ì°¨ì´ì˜ í¬ê¸°ë¥¼ lossë¡œ, MSEëŠ” ê²°ê³¼ì™€ì˜ ì°¨ì´ì˜ ì œê³±ì„ lossë¡œ ì‚¬ìš©í•œë‹¤.</p>

<p>MAE/MSE ê°™ì€ Regressionì˜ ê²°ê³¼ë¬¼ì€ blurryí•œ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ”ë°, ë‘ loss ëª¨ë‘ ì´ë¯¸ì§€ì˜ í”½ì…€ë“¤ì˜ í‰ê· ì„ í¬í•¨í•˜ëŠ” loss ì´ê¸° ë•Œë¬¸ì´ë‹¤.</p>

<p>GANì€ Discriminatorë¥¼ ì†ì´ê¸° ìœ„í•´ ì—ëŸ¬ê°€ ì¹˜ìš°ì³ë„ í˜„ì‹¤ì— ê°€ê¹ê²Œ ë§Œë“ ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312122105022.png" alt=""></p>

<p><strong>[img. ì±„ìƒ‰ì„ ì˜ˆì‹œë¡œë“  lossì˜ ì°¨ì´]</strong></p>

<p>ì§„ì§œ ì´ë¯¸ì§€ê°€ í°ìƒ‰ ì•„ë‹ˆë©´ ê²€ì€ìƒ‰ì´ ì •ë‹µì´ë¼ë©´ L1 lossëŠ” ê·¸ ì‚¬ì´ í‰ê·  ê°’ì´ë©´ì„œ, ì¡´ì¬í•˜ì§€ ì•Šì€ íšŒìƒ‰ ì´ë¯¸ì§€ë¥¼, GAN lossëŠ” ê·¸ ë‘˜ì¤‘ì— í•˜ë‚˜ì¸ ê²€ì • ì•„ë‹ˆë©´ í° ì´ë¯¸ì§€ë¥¼ ë§Œë“ ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312122047864.png" alt=""></p>

<p><strong>[img. MSE lossë¥¼ ì“´ SRResNetê³¼ GAN lossë¥¼ SRGANì˜ ì°¨ì´ì— ì£¼ëª©]</strong></p>

<h3 id="Image-translation-GANs">Image translation GANs</h3>

<p>Image translationì´ë€, í•œ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ì„ ë‹¤ë¥¸ ì´ë¯¸ì§€ ë„ë©”ì¸ í˜¹ì€ ë‹¤ë¥¸ ìŠ¤íƒ€ì¼ë¡œ ë³€í™”ì‹œí‚¤ëŠ” ë¬¸ì œ.</p>

<p>í¬ê²Œ ë³´ìë©´ ìœ„ì˜ Super resolution ë˜í•œ Image translationì˜ í•œ ì¢…ë¥˜</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312122407888.png" alt=""></p>

<p><strong>[img. Image Translation ì˜ˆì‹œ]</strong></p>

<h4 id="Pix2Pix">Pix2Pix</h4>

<p>Image translationì„ CNN Laeyrê°€ í¬í•¨ëœ í•™ìŠµ êµ¬ì¡°ë¡œ ì²˜ìŒ ì •ë¦¬í•œ ì—°êµ¬ <br>
\(G^* = arg\ \underset{G}{min}\ \underset{D}{max}\ \mathcal{L}_{cGAN}(G,D)+\lambda\mathcal{L}_{L1}(G)\\
where\ \mathcal{L}_{cGAN}(G,D)=\mathbb{E}_{x,y}[\log D(x,y)]+\mathbb{E}_{(x,y)}[\log(1-D(x,G(x,z))]\\
and\ \mathcal{L}_{L1}(G)=\mathbb{E}_{x,y,z}[\left\|y-G(x,y)\right\|_1]\\
x:ground-truth,\ y: output,\ z:random\ factor\)<br>
<strong>[math. Pix2Pixì˜ Loss, Total loss(GAN loss + L1 loss)]</strong></p>

<p>L1 Lossë¥¼ ì ë‹¹í•œ ì¡°ê±´ìœ¼ë¡œ, GAN lossë¥¼ ë”í•´ Realisticí•œ ì¶œë ¥ì„ ë§Œë“¤ë„ë¡ ë°”ê¾¼ Total lossë¥¼ ì‚¬ìš©í•¨</p>

<ul>
  <li>MAE L1 LossëŠ” y-G(x,y)ë¡œ ê²°ê³¼ì™€ ì‹¤ì œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¹„êµí•˜ì§€ë§Œ GAN lossëŠ” Discriminatorë¥¼ í†µí•´ ê°„ì ‘ì ìœ¼ë¡œ ë¹„êµí•œë‹¤.</li>
  <li>ê·¸ëŸ¬ë¯€ë¡œ GANë¡œ Realisticí•˜ê³   L1 Lossìœ¼ë¡œ ì˜ë„ì™€ ë¹„ìŠ·í•œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.</li>
  <li>ë˜í•œ, ë‹¹ì‹œì—ëŠ” GANì˜ ì—°êµ¬ê°€ ë§ì´ ì§„í–‰ë˜ì§€ ì•Šì•„ì„œ í•™ìŠµì´ ì•ˆì •ì ì´ì§€ ì•Šì•˜ë‹¤.</li>
</ul>

<p>ë˜í•œ GAN Loss ë¶€ë¶„ì€ cGANì´ë¯€ë¡œ z ë¿ë§Œ ì•„ë‹ˆë¼ ì¡°ê±´ì¸ xê°€ ê°™ì´ ë“¤ì–´ê°</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312132131634.png" alt=""></p>

<p><strong>[img. loss ì¢…ë¥˜ì— ë”°ë¥¸ ê²°ê³¼ ë¹„êµ]</strong></p>

<h4 id="CycleGAN">CycleGAN</h4>

<p>ìœ„ì˜ Pix2PixëŠ” Supervised learning ë°©ë²•ì„ ì‚¬ìš©í•´ì„œ pairwise dataê°€ í•„ìš”í•˜ì§€ë§Œ ì´ëŸ¬í•œ ë°ì´í„°ì…‹ì„ ì–»ëŠ” ê²ƒì´ ì–´ë ¤ì›Œì„œ CycleGANì´ ë“±ì¥í–ˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312132419560.png" alt=""></p>

<p><strong>[img. paired vs unpaired data]</strong></p>

<p>CycleCANì„ ì´ìš©í•˜ë©´ ë„ë©”ì¸ ê°„ì˜ ê´€ê³„ê°€ ì—†ì–´ë³´ì´ê³ , 1:1 ëŒ€ì‘í•˜ëŠ” pairê°€ ì—†ëŠ” ë‘ ë°ì´í„°ì…‹ìœ¼ë¡œë„ image translationì„ í•  ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>ì‘ìš©ë²”ìœ„ì™€ ë°ì´í„°ì…‹ í™•ë³´ë°©ë²•ì´ ëŠ˜ì–´ë‚¨</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312132703158.png" alt=""></p>

<p><strong>[img. CycleGAN ê²°ê³¼ë¬¼ ì˜ˆì‹œ]</strong></p>

<p>Cycleì´ë¼ëŠ” ì´ë¦„ì—ì„œ ì•Œ ìˆ˜ ìˆë“¯ì´, CycleGANì˜ LossëŠ” ë°ì´í„°ì…‹ X,Yì— ëŒ€í•˜ì—¬, X -&gt; Yë¡œ ê°€ëŠ” ë°©í–¥ì˜ Lossì™€ Y -&gt; Xë¡œ ê°€ëŠ” ë°©í–¥ì˜ Lossë¥¼ Cycle ëŒë“¯ì´ ë™ì‹œì— í•™ìŠµ ì‹œí‚¨ë‹¤.</p>

<p>ì¶”ê°€ë¡œ Cycle-consistency loss í…€ì€ X-&gt;Y-&gt;Xë¡œ ëŒì•„ì™”ì„ ë•Œ, ë³€í•œ Xê°€ ì›ë³¸ Xì™€ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ë„ë¡ í•˜ëŠ” Lossì´ë‹¤.<br>
\(L_{GAN}(X\rightarrow Y)+L_{GAN}(Y\rightarrow X) + L_{cycle}(G,F)\\
where\ G/F\ are\ generators\)<br>
<strong>[math. CycleGAN loss = GAN loss (in bot direction) + Cycle-consistency loss]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134522568.png" alt=""></p>

<p><strong>[img. Cycle-consistency loss í…€ì´ ì¡´ì¬ í•˜ì§€ ì•Šì„ ì‹œì˜ CycleGAN Loss ì„¤ëª…]</strong></p>

<p>Cycle-consistency loss í…€ì´ ì¡´ì¬ í•˜ì§€ ì•Šì„ ì‹œì˜ êµ¬ì¡°ì´ë‹¤.</p>

<ul>
  <li>G, F: generator</li>
  <li>$D_x, D_y$: discriminator</li>
  <li>GAN loss : $L(D_x)+L(D_Y)+L(G)+L(F)$</li>
  <li>ì¼ì¢…ì˜ 2ê°œì˜ GANì´ë‹¤.</li>
</ul>

<p>í•˜ì§€ë§Œ ì´ëŸ° GAN lossë§Œ ì‚¬ìš©ì‹œ Mode Collapse ë¬¸ì œê°€ ë°œìƒí•œë‹¤.</p>

<ul>
  <li>Inputì˜ ìƒê´€ì—†ì´ í•˜ë‚˜ì˜ Outputë§Œ ê³„ì† ì¶œë ¥í•˜ëŠ” ë¬¸ì œ</li>
  <li>ì¦‰ Inputê³¼ Outputì´ ì„œë¡œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠìŒ(ì–‘ë°©í–¥ ëª¨ë¸ì´ê¸° ë•Œë¬¸ì—)</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312135638222.png" alt=""></p>

<p><strong>[img. Mode Collapse ë¬¸ì œ]</strong></p>

<p>ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Cycle-consistency lossê°€ ë“±ì¥í•˜ì˜€ë‹¤.</p>

<ul>
  <li>Style ê²°ê³¼ ë¿ë§Œì•„ë‹ˆë¼ contentë„ ìœ ì§€ì‹œì¼œ ì¤Œ</li>
</ul>

<p>Xì—ì„œ Y, ê·¸ë¦¬ê³  ë‹¤ì‹œ Xë¡œ ëŒì•„ì™”ì„ ë•Œ ì›ë³¸ Xì™€ ê°™ì•„ì•¼ í•œë‹¤(contents ìœ ì§€).</p>

<p>supervisionì´ ì—†ëŠ” self-supervision ë°©ë²•(ë ˆì´ë¸”ë§ í•„ìš” ì—†ìŒ)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134547495.png" alt=""></p>

<p><strong>[img. X-&gt;Y-&gt;Xì™€ Y-&gt;X-&gt;Y ì²˜ëŸ¼ ëŒì•„ì™”ì„ ë•Œì˜ Cycle-consistency loss]</strong></p>

<h4 id="Perceptual-loss">Perceptual loss</h4>

<p>GANì€ Discriminator, Generative ëª¨ë¸ì´ ë²ˆê°ˆì•„ê°€ë©° í•™ìŠµë˜ì–´ì•¼ í•˜ë¯€ë¡œ í•™ìŠµí•˜ê¸° ì‰½ì§€ ì•Šë‹¤.</p>

<p>ë” ì‰¬ìš´ ë°©ë²•ì„ ì•Œì•„ë³´ê¸° ìœ„í•´ Perceptual lossê°€ ë‚˜íƒ€ë‚¬ë‹¤.</p>

<p>Peceptual lossëŠ” ë†’ì€ ì§ˆì˜ ê²°ê³¼ë¥¼ ì–»ê¸°ìœ„í•´ ì œì•ˆëœ ë°©ë²•ì´ë‹¤.</p>

<p>GAN loss(Adversarial loss)ì˜ ê²½ìš°,</p>

<ul>
  <li>íŠ¸ë ˆì´ë‹ê³¼ ì½”ë”©ì´ í˜ë“¬(ë‘ ëª¨ë¸ì„ ë°˜ë³µ, ì™•ë³µ í•™ìŠµí•´ì•¼í•˜ë¯€ë¡œ)</li>
  <li>ëŒ€ì‹ , pre-training network í•„ìš” ì—†ì–´, ë°ì´í„°ë§Œ ìˆìœ¼ë©´ ë‹¤ì–‘í•œ ìƒí™©ì— í™œìš© ê°€ëŠ¥</li>
</ul>

<p>Peceptual lossì˜ ê²½ìš°,</p>

<ul>
  <li>í•™ìŠµê³¼ ì½”ë”©ì´ í¸í•¨(í‰ë²”í•œ foward &amp; backward computation), ë”°ë¼ì„œ ë” ë¹ ë¦„</li>
  <li>ëŒ€ì‹  learned lossë¥¼ ìœ„í•´ pre-trained networkê°€ í•„ìš”</li>
</ul>

<p>pretrained-networkì˜ filterë¥¼ visualization í•´ë³´ë©´, ì‚¬ëŒì˜ visual perception ê³¼ ë¹„ìŠ·í•˜ë‹¤.</p>

<p>ì´ë¯¸ì§€ì—ì„œ filterë“¤ì´ ë°©í–¥ì„±, edge, ìƒ‰ê¹” ë“±ì„ ì°¾ì•„ peceptual spaceë¡œ ë³€í™˜í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312142140216.png" alt=""></p>

<p><strong>[img. pretraineëœ networkì˜ low level layerì—ì„œì˜ filter]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134625327.png" alt=""></p>

<p><strong>[img. perceptual lossì˜ ê²°ê³¼ë¬¼ ì˜ˆì‹œ]</strong></p>

<p>Perceptual lossë¥¼ í™œìš©í•´ Input ì´ë¯¸ì§€ë¥¼ ì›í•˜ëŠ” Styleë¡œ ë°”ê¾¸ëŠ” Image Transform Netì˜ ì˜ˆì‹œë¥¼ ë³´ë©´,</p>

<p>ì—¬ê¸°ì„œëŠ” VGG-16ì„ Loss Networkë¡œ ì‚¬ìš©í•˜ë©°, ì´ë¥¼ ì´ìš©í•´ featureë¥¼ activation map í˜•íƒœë¡œ ë½‘ì•„ë‚¸ë‹¤.</p>

<p>ì´ë•Œ Loss NetworkëŠ” Pretrained-Networkì´ë¯€ë¡œ ê³ ì •ë˜ì–´ ì—…ë°ì´íŠ¸ ë˜ì§€ ì•Šìœ¼ë©°, ê·¸ ì•ë‹¨ì— ìˆëŠ” Image Transform Netì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ Backpropagationì„ ì§„í–‰í•˜ì—¬ ì—…ë°ì´íŠ¸í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134645479.png" alt=""></p>

<p><strong>[img. Perceptual lossë¥¼ í™œìš©í•˜ëŠ” Image Transform Net êµ¬ì¡°]</strong></p>

<p>ì´ ë•Œ, Style Targetê³¼ Content Target 2ê°œì— ê´€í•œ Lossë¥¼ êµ¬í•˜ê²Œ ë˜ëŠ”ë°, ê°ê° Feature Reconstruction loss, Style Reconstruction lossë¼ê³  í•œë‹¤.</p>

<ol>
  <li>Feature Reconstruction loss</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312143846321.png" alt=""></p>

<p><strong>[img. Feature Reconstruction lossì˜ ì›ë¦¬]</strong></p>

<p>ì¤‘ê°„ ë ˆì´ì–´ì— feature 1ê°œë¥¼ ë½‘ëŠ”ë‹¤.</p>

<p>Transformed Image netì˜ ê²°ê³¼ë¬¼ì¸ $\hat{y}$ê°€ Content Targetê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ì¸¡ì •í•˜ëŠ” Lossë¡œ,   ì¼ë°˜ì ìœ¼ë¡œ ì›ë³¸ ì´ë¯¸ì§€ xë¥¼ Inputìœ¼ë¡œ loss networkì— ë„£ì–´ì–»ì–´ë‚¸ featureì™€ loss networkì—ì„œ ì–»ì–´ë‚¸ $\hat{y}$ì˜ featureë¥¼ ë¹„êµí•˜ì—¬ L2 Lossë¡œ ê³„ì‚°í•œë‹¤.</p>

<p>ì´í›„ , ì´ ê°’ìœ¼ë¡œ Backpropgationì„ í•˜ì—¬ Transformed Image Netì„ í•™ìŠµì‹œí‚¨ë‹¤.</p>

<ol>
  <li>Style Reconstruction loss</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134711159.png" alt=""></p>

<p><strong>[img. Style Reconstruction lossì˜ ì›ë¦¬]</strong></p>

<p>Feature Reconstruction lossì™€ ë¹„ìŠ·í•˜ê²Œ, Style Targetê³¼  $\hat{y}$ì˜ Featureë¥¼ ë½‘ì•„ë‚¸ë‹¤.</p>

<p>ë‹¤ë¥¸ ì ì€ ì´ë•Œ, Featureë¥¼ ì§ì ‘ ë¹„êµí•˜ëŠ”ê²Œ ì•„ë‹ˆë¼, ì „ì²´ì ì¸ Styleì„ ë¹„êµí•˜ê¸° ìœ„í•´, Gram matricesë¼ëŠ” feature mapì˜ í†µê³„ì  íŠ¹ì§•ì„ ë‹´ì•„ë‚¸ featureì˜ channel size X channel sizeì˜ tensorë¥¼ ë¹„êµí•˜ì—¬ L2 Lossë¥¼ ê³„ì‚°í•œë‹¤.</p>

<p>Gram matricesë€?</p>

<ul>
  <li>Gram matricesëŠ” Featureì˜ ê³µê°„ì  ì •ë³´ë¥¼ ì—†ì• ê¸° ìœ„í•´ poolingì„ ì´ìš©í•˜ë©°, Feature ì±„ë„ë“¤ì„  channel X (Height*Width) í˜•íƒœë¡œ ë°”ê¾¼ ë’¤,  ë‚´ì í•˜ì—¬ ê³±í•´ì„œ ì–»ëŠ”ë‹¤.</li>
  <li>diagonal component(í–‰ë ¬ì˜ í–‰ì¢Œí‘œì™€ ì—´ì¢Œí‘œê°€ ê°™ì€ ë¶€ë¶„)ì€ ìê¸°ìì‹ ì˜ í†µê³„ì  íŠ¹ì„±ì„ ì˜ë¯¸í•˜ë©°, ê·¸ ì´ì™¸ì—ëŠ” í•´ë‹¹ ì±„ë„ê³¼ ë‹¤ë¥¸ ì±„ë„ì˜ ì—°ê´€ì„±ì„ ì˜ë¯¸í•œë‹¤.
    <ul>
      <li>ê³µë¶„ì‚° í–‰ë ¬ êµ¬í•˜ê¸°</li>
    </ul>
  </li>
  <li>ì¦‰ Gram MatricesëŠ” ì±„ë„ê°„ì˜ ê´€ê³„ì™€ í†µê³„ì  íŠ¹ì„±ì´ í¬í•¨ëœ ì •ë³´ì„</li>
  <li>ê° featureì˜ ì±„ë„ì€ ì¼ì¢…ì˜ detection ì—­í• ì„ í•˜ê¸° ë•Œë¬¸ì—, Gram MatricesëŠ” ì´ ìŠ¤íƒ€ì¼ì€ ì–´ë–¤ detectionë“¤ì´ ë§ì´ ë‚˜íƒ€ë‚˜ëŠ” ê°€?ë¥¼ ë¶„ì„í•œ ê²ƒì´ë‹¤.</li>
</ul>

<p>Taskì— ë”°ë¼ ìŠ¤íƒ€ì¼ê³¼ ê´€ê³„ì—†ëŠ” ì¼ì´ë¼ë©´, Style reconstruction loss ëŒ€ì‹  Feature reconstuction lossë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šì„ ìˆ˜ë„ ìˆë‹¤.</p>

<h3 id="Various-GAN-applications">Various GAN applications</h3>

<p>GANì˜ ì˜ˆì‹œë¥¼ ì•Œì•„ë³´ì.</p>

<ol>
  <li>Deepfake</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134759092.png" alt=""></p>

<p><strong>[img. ì‚¬ëŒ ì–¼êµ´ ìƒì„±ê¸°, ê°€ì§œ ì—°ì„¤ ìƒì„±ê¸°]</strong></p>

<p>ì´ë¥¼ ì˜¤ë‚¨ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ëŸ¬í•œ Deepfakeë¥¼ ë°©ì–´í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ì‹œë„ ë˜í•œ ì´ë£¨ì–´ì§€ê³  ìˆë‹¤.</p>

<p><strong>Face de-identification</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134923519.png" alt=""></p>

<p><strong>[img. Face de-identification]</strong></p>

<p>í”„ë¼ì´ë²„ì‹œ ì¹¨í•´ ë°©ì§€ë¥¼ ìœ„í•´ ì¸ê°„ì€ ì°¨ì´ë¥¼ ì•Œì§€ ëª»í•˜ì§€ë§Œ ì»´í“¨í„°ëŠ” í˜¼ëˆì„ ê°€ì§ˆ ìˆ˜ ìˆê²Œë”, ì¡°ê¸ˆì˜ ë³€ê²½ì„ í•˜ëŠ” ì—°êµ¬ë„ ì§„í–‰ì¤‘</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210312134900295.png" alt=""></p>

<p><strong>[img. passwordë¥¼ ì´ìš©í•´ ì¹¨í•´ ë°©ì§€ ì˜ˆì‹œ]</strong></p>

<p>ê¸°íƒ€ ë¹„ë””ì˜¤ë¥¼ í†µí•´ í¬ì¦ˆë¥¼ ë”°ë¼í•˜ê²Œ ë§Œë“œê±°ë‚˜,  CG ìƒì„±, ê²Œì„ ë“±ì—ë„ ì‚¬ìš© ê°€ëŠ¥</p>

<h2 id="Multi-modal-learning-Captioning-and-Speaking">Multi-modal learning: Captioning and Speaking</h2>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313165726962.png" alt=""></p>

<p><strong>[img. Unimodal vs Multi-modal]</strong></p>

<p>Multi-modal learning : ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ë°ì´í„°ë“¤ì„ í•¨ê»˜ í™œìš©í•˜ëŠ” í•™ìŠµ(ex) Text + Sound)</p>

<h3 id="Overview-of-multi-modal-learning">Overview of multi-modal learning</h3>

<p><strong>multi-modal learningì˜ ì–´ë ¤ì›€</strong></p>

<ol>
  <li>ë°ì´í„°ì˜ í‘œí˜„ ë°©ë²•ì´ ëª¨ë‘ ë‹¤ë¦„</li>
</ol>

<ul>
  <li>ì´ë¯¸ì§€ : H X W X 3 ë°°ì—´, Text : Word Embedding + Positional Encoding ë“±</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313171140286.png" alt=""></p>

<p><strong>[img. ë°ì´í„° í‘œí˜„ ì°¨ì´]</strong></p>

<ol>
  <li>ì •ë³´ëŸ‰ì˜ ë¶ˆê· í˜•, feature spaceì˜ ë¶ˆê· í˜•.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313171157797.png" alt=""></p>

<p><strong>[img. ì•„ë³´ì¹´ë„ ëª¨ì–‘ ê°€êµ¬ì— ëŒ€í•œ ê¸€ í•˜ë‚˜ëŠ” ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•  ìˆ˜ ìˆë‹¤]</strong></p>

<ol>
  <li>íŠ¹ì • modalityì— í¸í–¥ëœ ëª¨ë¸ì´ ìƒì„±ë  ìˆ˜ ìˆìŒ</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313171544052.png" alt=""></p>

<p><strong>[img. ì£¼ì–´ì§„ ë°ì´í„°ê°€ ë™ì¼í•´ë„ ì°¸ì¡°í•˜ëŠ” modalityì˜ ë¹„ìœ¨ì€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ]</strong></p>

<ul>
  <li>ì˜ˆë¥¼ ë“¤ì–´, ë™ë¬¼ Classification Taskì—ì„œ ì‚¬ì§„ê³¼ ìš¸ìŒì†Œë¦¬, ë™ë¬¼ì— ëŒ€í•œ ì„¤ëª…ì´ ì í˜€ìˆëŠ” ê¸€ì„ ì¤˜ë„, ì‚¬ì§„ë§Œ ë³´ê³  ë™ë¬¼ Classë¥¼ ê²°ì •í•  ìˆ˜ ìˆìŒ</li>
  <li>ë”¥ëŸ¬ë‹ì€ ì‰¬ìš´ ê¸¸ë§Œ ì„ íƒí•˜ë ¤í•˜ê¸° ë•Œë¬¸</li>
</ul>

<p><strong>Multi modal learningì˜ ì—¬ëŸ¬ íŒ¨í„´</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313172559574.png" alt=""></p>

<p><strong>[img. Multi modal learningì˜ ì—¬ëŸ¬ íŒ¨í„´]</strong></p>

<ol>
  <li>Matching</li>
</ol>

<ul>
  <li>ì„œë¡œ ë‹¤ë¥¸ Modalityë¥¼ ê°™ì€ Spaceë¡œ ë³´ë‚´ì–´ ì„œë¡œ Matching</li>
</ul>

<ol>
  <li>Translating</li>
</ol>

<ul>
  <li>ì„œë¡œ ë‹¤ë¥¸ Modalityë¥¼ ë‹¤ë¥¸ Modalityë¡œ ë³€í™˜</li>
</ul>

<ol>
  <li>Referencing</li>
</ol>

<ul>
  <li>ì–´ë–¤ Modality ì •ë³´ë¥¼ Inputìœ¼ë¡œ ê°™ì€ Modalityì˜ ê²°ê³¼ë¬¼ë¡œ ë³€í™˜í•  ë•Œ, ë‹¤ë¥¸ Modalityë¥¼ ì°¸ì¡°í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒ</li>
</ul>

<h3 id="Multi-modal-tasks-1-Visual-data-Text">Multi-modal tasks (1) - Visual data &amp; Text</h3>

<h4 id="Text-embedding">Text embedding</h4>

<p>Ascii ì½”ë“œë¥¼ ì‚¬ìš©í•˜ëŠ” Character ê´€ì ì—ì„œëŠ” ì‚¬ìš©í•˜ê¸° í˜ë“¤ê³ , Word ë ˆë²¨ì˜ embeddingì„ Inputìœ¼ë¡œ ì´ìš©í•¨.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313173716047.png" alt=""></p>

<p><strong>[img. Word embedding ì˜ˆì‹œ]</strong></p>

<p>ê° Word embeddingì€ ë‹¨ì–´ì˜ ëŒ€ëµì ì¸ ì˜ë¯¸ì™€ ì—°ê´€ì„±ì„ ê°€ì§„ featureë¥¼ í‘œí˜„í•œëŠ” Vectorì˜ í˜•íƒœì´ë‹¤.</p>

<p>ì´ë¥¼ ì°¨ì›ê³µê°„ì— í‘œí˜„í•˜ë©´ ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ëŠ” ë¹„ìŠ·í•œ ê³³ì— ìœ„ì¹˜í•˜ë©°, ë¹„ìŠ·í•œ ê´€ê³„ë¥¼ ê°€ì§„ ë‹¨ì–´ìŒ ë²¡í„° ë‘˜ì˜ ë°©í–¥(ì°¨ì´ ë²¡í„°) ë˜í•œ ë¹„ìŠ·í•œ ë°©í–¥ì„ ê°€ì§€ê²Œ ëœë‹¤. (ì¼ë°˜í™”ê°€ ë˜ì–´ ìˆìŒ)</p>

<p><strong>Word embedding ìƒì„± ë°©ë²• : word2vec</strong></p>

<p>ëŒ€í‘œì ìœ¼ë¡œ <em>Skip-gram model</em>ì´ë¼ëŠ” ë°©ë²•ì´ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313174938346.png" alt=""><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313174953023.png" alt=""></p>

<p><strong>[img. Skip-gram modelì˜ ì˜ˆì‹œ]</strong></p>

<p>Inputìœ¼ë¡œ ë‹¨ì–´ì˜ one hot vector(Vì°¨ì›)ë¥¼ ì˜ë¯¸í•˜ë©°, ì´ë¥¼ Wì™€ ê³±í•˜ì—¬ N-ì°¨ì›ì˜ embedding vectorê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤.</p>

<ul>
  <li>ì´ë•Œ one-hot vectorì— ì˜í•´ Wì˜ í•œ Rowë§Œ slicing ë˜ê²Œ ëœë‹¤. ì¦‰ WëŠ” embedding vecotrì˜ Rowë“¤ì˜ ì§‘í•©ì´ë‹¤.</li>
</ul>

<p>ì´í›„ ê·¸ Embedding vectorë¥¼ ì´ìš©í•´ í•´ë‹¹ ë‹¨ì–´ì˜ ì£¼ë³€ì— ë‚˜íƒ€ë‚œ nê°œì˜ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡í•˜ëŠ” Taskë¡œ í•™ìŠµí•œë‹¤.</p>

<ul>
  <li>ë‚˜íƒ€ë‚˜ëŠ” ì£¼ë³€ ë‹¨ì–´ë¥¼ í†µí•˜ì—¬ ê´€ê³„ì„±ì„ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<h4 id="Joint-embedding">Joint embedding</h4>

<p>ì„œë¡œ ë‹¤ë¥¸ Modalityì˜ Matchingì„ í•˜ê¸° ìœ„í•œ ê³µí†µëœ Embedding ë²¡í„°ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ë°©ë²•</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313184519681.png" alt=""></p>

<p><strong>[img. Joint embeddingì€ Multi-Modality learningì—ì„œ Matcing íŒ¨í„´ì„ ìœ„í•´ ì‚¬ìš© ]</strong></p>

<p><strong>Image tagging</strong></p>

<p>Image taggingì€ ì‚¬ì§„ì— tagë¥¼ ì§€ì •í•˜ê±°ë‚˜, ë°˜ëŒ€ë¡œ tagë¥¼ í†µí•´ ì‚¬ì§„ì„ ê°€ì ¸ì˜¤ëŠ” Taskì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313184903379.png" alt=""></p>

<p><strong>[img. Image Tagginì˜ ì˜ˆì‹œ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313193522529.png" alt=""></p>

<p><strong>[img. Textì™€ Imageì˜ matching ì˜ˆì‹œ]</strong></p>

<p>ìœ„ì˜ ì˜ˆì‹œì˜ ê²½ìš° ê°ê° Textì™€ Imageë¥¼ feature vectorì™€ í•œ í›„,  ê·¸ ì´í›„ ì„œë¡œ ë‹¤ë¥¸ ëª¨ë¸ì„ í†µí•˜ì—¬ ê°™ì€ ì°¨ì›ì˜ (d-dimension) vectorë¡œ ë°”ê¾¼ ë’¤, ê·¸ ë‘˜ì„ í†µí•˜ì—¬ Joint embedding  vectorë¥¼ í•™ìŠµí•œë‹¤.</p>

<p>ì´ë•Œ Joint embedding VectorëŠ” ë‘ ë‹¤ë¥¸ Modality ë°ì´í„°ì˜ ì—°ê´€ì„±, ê±°ë¦¬ë¥¼ ì˜ë¯¸í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313193932616.png" alt=""></p>

<p><strong>[img.  joint visual-semantic embedding space ë‚´ë¶€]</strong></p>

<p>ì´ë ‡ê²Œ êµ¬í•œ joint embedding vector ë‘˜ì˜ ë‘ ì°¨ì› ìƒì˜ ê±°ë¦¬ë¥¼ ê´€ë ¨ì´ ìˆëŠ” Labelì€ ê°€ê¹ê²Œ, ê´€ë ¨ ì—†ìœ¼ë©´ ë©€ê²Œ ë˜ë„ë¡ í•™ìŠµí•œë‹¤.</p>

<ul>
  <li>ì´ëŸ° Distance ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì„ Metric learningì´ë¼ê³  í•œë‹¤.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313195855010.png" alt=""></p>

<p><strong>[img. Multi-modal analogy]</strong></p>

<p>ë˜í•œ, ì´ë ‡ê²Œ í•™ìŠµëœ embeddingì„ ì´ìš©í•˜ì—¬ Multi-modal analogyë¼ëŠ” property ìƒê²¨ë‚œë‹¤.</p>

<ul>
  <li>ì„œë¡œ ë‹¤ë¥¸ Modality embeddingë¥¼ í¬í•¨í•˜ì—¬, embedding ë”í•˜ê±°ë‚˜ ë¹¼ì„œ ê°€ì¥ ê°€ê¹Œìš´ embeddingì„ ë°ì´í„° í˜•íƒœë¡œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.</li>
  <li>ì˜ˆë¥¼ ë“¤ì–´ ìœ„ì˜ ì´ë¯¸ì§€ì²˜ëŸ¼ ê°œ ì‚¬ì§„ì— ê°œ ë‹¨ì–´ë¥¼ ë¹¼ê³  ê³ ì–‘ì´ ë‹¨ì–´ë¥¼ ì¶”ê°€í•˜ë©´, ê³ ì–‘ì´ ì‚¬ì§„ë“¤ì´ ë‚˜íƒ€ë‚œë‹¤.
    <ul>
      <li>ì‹¬ì§€ì–´, ê° ì²«ë²ˆì§¸ ì‚¬ì§„ë“¤ì˜ ì…ë ¥í•œ ì‚¬ì§„ì˜ ë°°ê²½ê³¼ ë¹„ìŠ·í•˜ë‹¤.</li>
    </ul>
  </li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313201642274.png" alt=""></p>

<p><strong>[img. ë ˆì‹œí”¼ë¥¼ í†µí•´ ì‚¬ì§„ì„ ì˜ˆìƒí•˜ëŠ” application ì˜ˆì‹œ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313202403238.png" alt=""></p>

<p><strong>[img. ìœ„ ì–´í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì¡°]</strong></p>

<ol>
  <li>
    <p>TextëŠ” encoderë¥¼ í†µí•˜ì—¬ instructionê³¼ Ingredientë¥¼ í•˜ë‚˜ì˜ outputìœ¼ë¡œ concat í•œ ë’¤, FCLì„ í†µí•˜ì—¬ d ì°¨ì›ì˜ vectorë¡œ ë§Œë“ ë‹¤.</p>
  </li>
  <li>ImageëŠ” conv layerì„ í†µí•˜ì—¬ featureë¥¼ ë½‘ì•„ë‚¸ ê²°ê³¼ë¥¼ FCLì„ í†µí•˜ì—¬ d0 ì°¨ì›ì˜ vectorë¡œ ë§Œë“ ë‹¤.</li>
  <li>ë‘ embedding vectorë¥¼ cosine similarty lossë¡œ lossë¥¼ êµ¬í•˜ì—¬ í•™ìŠµí•˜ë©°, ë˜ëŠ” ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì—¬ ë”ìš± ì¢‹ì€ ì„±ëŠ¥ì˜ semantic regularization lossë¥¼ ì´ìš©í•˜ì—¬ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.</li>
</ol>

<h4 id="Cross-modal-translation">Cross modal translation</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313204332841.png" alt=""></p>

<p><strong>[img. modal ê°„ì˜ ë³€í™˜ì„ í•˜ëŠ” Translating]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313204437528.png" alt=""></p>

<p><strong>[img. Image captioning ]</strong></p>

<p><strong>Image Captioning</strong></p>

<p>Image Captioningì€ ì´ë¯¸ì§€ì˜ ì„¤ëª… Textë¥¼ ìƒì„±í•˜ëŠ” ëŒ€í‘œì ì¸ cross modal translation Taskì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313210508665.png" alt=""></p>

<p><strong>[img. Image ë¶„ì„ì„ ìœ„í•œ CNNê³¼ Text ìƒì„±ì„ ìœ„í•œ RNNìœ¼ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.]</strong></p>

<p>Image Captioning ì—ì„œëŠ” CNNê³¼ RNN êµ¬ì¡°ê°€ í•„ìš”í•˜ë©° ëŒ€í‘œì ì¸ êµ¬ì¡°ë¡œ <em>Show and tell</em>ì´ ìˆë‹¤.</p>

<ol>
  <li>Encoder êµ¬ì¡°ë¡œ ImageNetì— ì˜í•´ pre-trainëœ CNN modelì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ vectorë¡œ ë°”ê¾¼ ë’¤,</li>
  <li>ì´ë¥¼ Decoderì¸ LSTM RNNì˜ Conditionìœ¼ë¡œ ì œê³µí•˜ê³ , ì‹œì‘ í† í°(ë³´í†µ 0ì´ë‚˜ <start> í† í°)ì„ ì¤€ ë’¤,</start></li>
  <li>í•´ë‹¹ LSTMì˜ Outputì„ ë‹¤ìŒ LSTMì˜ Inputìœ¼ë¡œ ì£¼ëŠ” ê³¼ì •ì„ ë°˜ë³µí•œë‹¤.</li>
  <li>
    <end> í† í°ì´ ë‚˜ì˜¬ë•Œ ê¹Œì§€ ë°˜ë³µí•˜ì—¬ ê²°ê³¼ë¬¼ì€ ë§Œë“ ë‹¤.

</end>
  </li>
</ol>
<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313210617115.png" alt=""></p>

<p><strong>[img. Show and Tell êµ¬ì¡°, ì¢Œì¸¡ì˜ CNNê³¼ ìš°ì¸¡ RNNì„ í™œìš©]</strong></p>

<p>Show and Tellì€ ë‹¨ í•œë²ˆì˜ Image ë¶„ì„ ë’¤ì— íƒœê¹…ì„ í•˜ë‚˜, ì‹¤ì œë¡œëŠ” ë‹¨ì–´ ë§ˆë‹¤ Imageì—ì„œ ì¤‘ìš”ì‹œ í•´ì•¼í•  featureê°€ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤.</p>

<p>Show, attend, and tell ì´ë¼ëŠ” êµ¬ì¡°ëŠ” attend êµ¬ì¡°ë¥¼ í†µí•˜ì—¬ ë‹¨ì–´ë³„ë¡œ attentionì„ ë‹¬ë¦¬í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìƒì„± ì‹œ, ì´ë¯¸ì§€ì—ì„œ featureì˜ ê°€ì¤‘ì¹˜ë¥¼ ë°”ê¿”ê°€ë©° í•  ìˆ˜ ìˆë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313222709143.png" alt=""></p>

<p><strong>[img. show, attend, and tellì˜ attention]</strong></p>

<ol>
  <li>CNNì„ ì´ìš©í•˜ì—¬ Input Imageì˜ 14x14 feature mapì„ ìƒì„±í•œë‹¤.
    <ul>
      <li>ê¸°ì¡´ì˜ Vector í˜•íƒœê°€ ì•„ë‹ˆë¼ëŠ” ì ì´ íŠ¹ì§•</li>
    </ul>
  </li>
  <li>í•´ë‹¹ feature mapì„ RNNì— ì…ë ¥í•˜ì—¬ ë‹¨ì–´ë¥¼ ìƒì„±í•  ë•Œë§ˆë‹¤ ë‹¤ë¥¸ attentionìœ¼ë¡œ ë‹¨ì–´ë¥¼ ìƒì„±</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210313220048887.png" alt=""></p>

<p><strong>[img. Show, attend, and tell êµ¬ì¡°]</strong></p>

<p>Show, attend, and tell êµ¬ì¡°ì˜ ê²½ìš°, ì‚¬ëŒì´ ì‚¬ì§„ì„ ì¸ì‹í•  ë•Œ ì „ì²´ì ì¸ ë¶€ë¶„ì„ ë³´ëŠ” ê²ƒì´ ì•„ë‹Œ, ì¼ë¶€ì— ê´€ì‹¬(attention)ì„ ê°€ì¤‘í•˜ì—¬ ë³¸ë‹¤ëŠ” ê²ƒì— ì°©ì•ˆë˜ì—ˆë‹¤.</p>

<p>1) Input imageë¥¼ CNNì„ í†µí•´ ì–»ì€ feature mapê³¼,</p>

<p>2) ìœ„ featuremapì„ RNNì— ë„£ì–´ ì–»ì€ spatial attention</p>

<p>1)ê³¼ 2)ì„ ê²°ê³¼ë¬¼ì„ inner product(weighted sum)í•˜ì—¬ ì–»ì€ soft attention embedding(z) ë²¡í„°ë¥¼ ì–»ì–´ë‚¸ë‹¤.</p>

<ul>
  <li>ì‚¬ì‹¤, Translating ë³´ë‹¤ëŠ” Reasoningì˜ Cross modal reasoningì— ë” ê°€ê¹ë‹¤.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314041635448.png" alt=""></p>

<p><strong>[img. ì‚¬ëŒì´ ì‚¬ì§„ì„ ì¸ì‹í•  ë•Œ ë³´ëŠ” ë¶€ë¶„ (ì¢Œ), attention ê²°í•© ë°©ë²•]</strong></p>

<p>RNNì—ì„œ ê²°ê³¼ë¥¼ ë‚´ëŠ” ê³¼ì •ì„ ì¢€ ë” ìì„¸íˆ ì‚´í´ë³´ë©´,</p>

<ol>
  <li>Feature mapì„ hidden statë¡œ ì²«ë²ˆì§¸ RNN ëª¨ë“ˆ h0ì— ë„£ì–´ì£¼ê³  spatial attention s1ì„ ì–»ëŠ”ë‹¤.</li>
  <li>ì´ë ‡ê²Œ ì–»ì€ s1ê³¼ feature mapì„ inner productí•˜ì—¬ ì–»ì€ z1 vectorë¥¼ start token y1ê³¼ í•¨ê»˜ ë‘ë²ˆì§¸ RNN ëª¨ë“ˆ h1ì— ë„£ì–´ì¤€ë‹¤.</li>
  <li>ê·¸ ê²°ê³¼ ì²«ë²ˆì§¸ ë‹¨ì–´ d1(â€˜Aâ€™)ì™€ ë‘ë²ˆì§¸ spatial attention s2ê°€ ë‚˜ì˜¨ë©°, ì´ë¥¼ ë‹¤ì‹œ feature mapê³¼ í•©ì³ soft attention embedding z2ë¥¼ ë§Œë“ ë‹¤.</li>
  <li>ì´ ì´í›„ ì„¸ë²ˆì§¸ RNN ëª¨ë“ˆ h2ì—ëŠ” z2ì™€ ì´ì „ì— ì¶œë ¥í•œ ë‹¨ì–´ y2(ë˜ëŠ” d1, â€˜Aâ€™)ë¥¼ í•¨ê»˜ ë„£ì–´ì£¼ê³ , End Token ë‚˜ì˜¬ë•Œ ê¹Œì§€ ë°˜ë³µí•œë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314041733532.png" alt=""></p>

<p><strong>[img. RNNì˜ ë‹¨ì–´ build ê³¼ì •]</strong></p>

<p>ë˜í•œ, ë°˜ëŒ€ë¡œ Textë¥¼ í†µí•˜ì—¬ Imageë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë©°, ì´ë•Œ, ì—¬ëŸ¬ Output Imageê°€ ë‚˜ì˜¤ëŠ” ê²ƒì´ ê°€ëŠ¥í•˜ë¯€ë¡œ Conditional GANì„ ì´ìš©í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314050205760.png" alt=""></p>

<p><strong>[img. Text-to-image by generative model]</strong></p>

<p>Text to image ëª¨ë¸ì˜ Generatorì˜ ê²½ìš°</p>

<p>Textì˜ Vectorê°€ ì£¼ì–´ì§€ë©´, ì´ë¥¼ Gaussian Random factorì™€ ê²°í•©í•˜ì—¬ ë‹¤ì–‘í•œ outputì´ ë‚˜ì˜¤ë„ë¡ í•´ì¤€ ë’¤, Decoderë¥¼ ê±°ì³ì„œ imageë¥¼ ìƒì„±í•´ì¤€ë‹¤.</p>

<p>Discriminatorì˜ ê²½ìš°</p>

<p>Inputëœ Imageë¥¼ encoderë¡œ ë½‘ì€ feature mapê³¼ ìœ„ì— ì‚¬ìš©í–ˆë˜ Text Vectorë¥¼ í•©ì¹œ ë²¡í„°ë¥¼  labelëœ ë°ì´í„°ì™€ ë¹„êµí•˜ì—¬ íŒë‹¨í•¨.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314050718230.png" alt=""></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314050658466.png" alt=""></td>
    </tr>
  </tbody>
</table>

<p><strong>[img. . Text-to-image Generatorì™€ Discriminator êµ¬ì¡°]</strong></p>

<h4 id="Cross-modal-reasoning">Cross modal reasoning</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314052621396.png" alt=""></p>

<p><strong>[img. Modalityê°„ì˜ Referencingì„ ì´ìš©í•˜ëŠ” Cross Modal reasoning]</strong></p>

<p><strong>Visual question answering</strong></p>

<p>ì˜ìƒê³¼ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ì´ë¥¼ í†µí•´ ë‹µì„ ë„ì¶œí•˜ëŠ” Task</p>

<p>ê°ê° Textì™€ Imageì—ì„œ ì¶”ì¶œí•œ ê°™ì€ ì°¨ì›ì˜ vectorë¥¼ point-wise multiplicationì„ í†µí•˜ì—¬ Joint embedding í•œ ë’¤, ì´ vectorë¥¼ FCLì„ í†µí•˜ì—¬ ë‹µì„ ë„ì¶œí•œë‹¤.</p>

<p>ëª¨ë“  êµ¬ì¡°ì—ì„œ í•™ìŠµì´ ê°€ëŠ¥í•œ End-to-End êµ¬ì¡°ì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314052755045.png" alt=""></p>

<p><strong>[img. Visual question answering êµ¬ì¡°]</strong></p>

<h3 id="Multi-modla-tasks-2-Visual-data-Audio">Multi-modla tasks(2) - Visual data &amp; Audio</h3>

<h4 id="Sound-representation">Sound representation</h4>

<p>Sound dataëŠ” ìì—°ìƒíƒœì—ì„œ 1ì°¨ì› Waveform í˜•íƒœë¡œ ì¡´ì¬í•˜ì§€ë§Œ, ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” Spectrogramì´ë‚˜, MFCC ë“±ì˜ í˜•íƒœë¡œ ë°”ê¿”ì¤˜ì•¼ í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314055637416.png" alt=""></p>

<p><strong>[img. Sound dataì˜ ë‹¤ì–‘í•œ í˜•íƒœ]</strong></p>

<ol>
  <li><strong>Fourier transform</strong></li>
</ol>

<p>ëŒ€ì¤‘ì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ì†Œë¦¬ì˜ í˜•íƒœì¸ Spectrogramìœ¼ë¡œ ë³€í™˜ì„ ìœ„í•œ ë°©ë²•</p>

<p>wave í˜•íƒœì˜ dataë¥¼ ë¶„ì„í•˜ì—¬ ê° frequency ë³„ ì„¸ê¸°ë¥¼ ê¸°ë¡í•œ ê²ƒì´ Power spectrum í˜•íƒœì´ë‹¤.</p>

<ul>
  <li>Power spectrum : ì£¼íŒŒìˆ˜ì™€ ì„¸ê¸°ì— ëŒ€í•œ ê·¸ë˜í”„</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314122450480.png" alt=""></p>

<p><strong>[img. Fourier transform]</strong></p>

<p>Waveformì— Fourier transformì´ìš©í•˜ë©´ í•˜ë‚˜ì˜ íŒŒì¥ìœ¼ë¡œ í‘œí˜„ê°€ëŠ¥ í•˜ë‚˜, ì‹œê°„ì— ëŒ€í•œ ì •ë³´ê°€ ì‚¬ë¼ì§€ê²Œ ëœë‹¤.</p>

<p>êµ¬ì²´ì ìœ¼ë¡œ ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì•„ì£¼ ì‘ì€ ì‹œê°„ êµ¬ê°„ tì— ëŒ€í•´ì„œë§Œ FTí•˜ì—¬ Spectrogramìœ¼ë¡œ ë°”ê¾¸ëŠ”  <em>Short-Time Fourier transform(STFT)</em>ë¼ëŠ” ë°©ë²•ì´ ì‚¬ìš©ëœë‹¤.</p>

<ol>
  <li>Hamming windowì˜ í˜•íƒœì²˜ëŸ¼ Boundary ë¶€ë¶„ì€ ì¡°ê¸ˆ, ê°€ìš´ë° ë¶€ë¶„ì€ ê°•ì¡°í•˜ëŠ” ì‹ìœ¼ë¡œ element wise ê³±ì„ í•´ì¤€ë‹¤.</li>
</ol>

<ul>
  <li>ì´ë•Œ windowê°€ ë‹¬ë¼ì§ˆ ë•Œë§ˆë‹¤(= ì •ì˜í•œ ì‹œê°„ tê°€ ì§€ë‚ ë•Œë§ˆë‹¤) ê°’ì´ í™•ë‹¬ë¼ì§€ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ ë§‰ê¸° ìœ„í•´ windowê°€ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œ í•˜ë©´ì„œ Spectrumì„ êµ¬í•˜ê²Œ ëœë‹¤.</li>
  <li>í•˜ë‹¨ì˜ ì˜ˆì‹œëŠ” ì‹œê°„ tì¸ Aë¥¼ 20~25msë¡œ ì¡ê³ , Bë¥¼ 10msë¡œ ì¡ì•˜ìœ¼ë‹ˆ ê° windowë“¤ì€ 10~15ms(A-B)ë§Œí¼ ì´ì „ê³¼ ì´í›„ windowë“¤ê³¼ ê²¹ì¹˜ë©´ì„œ ë³€í™˜ì´ ì§„í–‰ëœë‹¤.</li>
</ul>

<ol>
  <li>ì´ë ‡ê²Œ êµ¬í•œ Spectrumë“¤ì„ stackí•˜ì—¬ Spectrogramì„ êµ¬í•˜ê²Œ ëœë‹¤.</li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314123237637.png" alt=""></p>

<p><strong>[img. STFTì˜ ì˜ˆì‹œ]</strong></p>

<p>Spectrogramì€ ì‹œê°„ì¶•ê³¼ Frequecy ì¶•ìœ¼ë¡œ í‘œí˜„í•œ ê·¸ë˜í”„ì— ê°•ë„(ì„¸ê¸°, Magnitude)ë¥¼ ìƒ‰ìœ¼ë¡œ í‘œí˜„í•œ 3ì°¨ì› ê·¸ë˜í”„ì´ë‹¤.</p>

<ul>
  <li>Dimensionì„ ì¡°ê¸ˆ ë‚®ì¶”ë©´ Melspectrogram, MFCC ë“±ì˜ ë‹¤ë¥¸ í‘œí˜„ ë°©ë²•ë„ ìˆë‹¤.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314130743494.png" alt=""></p>

<p><strong>[img. Spectrogram. ì‹œê°„ë³„ë¡œ ìƒ‰ì´ ëŒ€ë¹„ë˜ëŠ” ë¶€ë¶„ì€ windowingì˜ í”ì ì´ë‹¤.]</strong></p>

<p><strong>Application- Scene recognition by sound</strong></p>

<p>Sound-Image Task ì¤‘ Matchingì— í•´ë‹¹í•˜ëŠ” Scene recognition by sound taskë¥¼ ì•Œì•„ë³´ì</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314131555165.png" alt=""><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314131606093.png" alt=""></p>

<p><strong>[img. Scene recognition by sound, ì˜ìƒì— ëŒ€í•œ sound íƒœê¹… Task]</strong></p>

<p><strong>SoundNet</strong></p>

<p>ì˜¤ë””ì˜¤ í‘œí˜„ì— ëŒ€í•œ í•™ìŠµì„ ì²˜ìŒ ì œì‹œí•¨, Teacher-student í•™ìŠµ ëª¨ë¸</p>

<ol>
  <li>labelë˜ì§€ ì•Šì€ ì˜ìƒì„ í”„ë ˆì„ë³„ë¡œ pretrainedëœ Object detectionê³¼ Scene detection ëª¨ë¸ë“¤ì—ê²Œ ê°ê° Inputìœ¼ë¡œ ë„£ê³  outputì„ ì–»ëŠ”ë‹¤.</li>
  <li>Raw waveformì„ CNN layerì— ë„£ì–´ì¤€ ë’¤, ìœ„ì˜ output dimensionê³¼ ê°™ì€ ì°¨ì›ì˜ two head outputì„ ì–»ëŠ”ë‹¤.
    <ul>
      <li>ì´ë•Œ, Spectrogramì´ ì•„ë‹ˆë¼ Raw Waveformì„ ì“´ ì´ìœ ëŠ” ë‹¨ìˆœíˆ ì—°êµ¬ ì´ˆê¸°ë¼ ëª¨ë¥´ê³  ì•ˆì¼ë‹¤ê³  í•œë‹¤.</li>
    </ul>
  </li>
  <li>1ì˜ outputê³¼ 2ì˜ outputì„ KL lossë¥¼ í†µí•´ lossë¥¼ ì–»ì€ ë’¤, 1ë²ˆ ëª¨ë¸ë“¤ì€ fixedí•œ ì±„ë¡œ 2ë²ˆ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ë‹¤. (Teacher-student í•™ìŠµ)</li>
  <li>ì´ë ‡ê²Œ í•™ìŠµëœ 2ë²ˆì˜ ëª¨ë¸ì„ ë‹¤ë¥¸ Taskì— ì ìš©í•  ë•Œì—ëŠ” ì¤‘ì•™ì˜ pool5ì˜ outputì¸ feature vectorë¥¼ taskì— ë§ê²Œ layerë¥¼ ì¶”ê°€ë¡œ ìŒ“ì•„ ì‚¬ìš©í•œë‹¤.
    <ul>
      <li>ì£¼ë¡œ ì´ë ‡ê²Œ Pre-trained ëª¨ë¸ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•™ìŠµì‹œí‚¨ë‹¤.</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314131813882.png" alt=""></p>

<p><strong>[img. SoundNetì˜ êµ¬ì¡°]</strong></p>

<h4 id="Cross-modal-translation">Cross modal translation</h4>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314142514349.png" alt=""></p>

<p><strong>1. Speech2Face</strong></p>

<p>ìŒì„±ì„ í†µí•˜ì—¬ ì‚¬ëŒì˜ ì–¼êµ´ì„ ìƒìƒí•˜ëŠ” Network</p>

<p>ê°ê° ë‹´ë‹¹ Taskì— ëŒ€í•˜ì—¬ Pretrainedëœ ëª¨ë¸ì„ í™œìš©í•˜ëŠ” Module êµ¬ì¡°ë¥¼ í™œìš©</p>

<p>ì‚¬ëŒì´ ë§í•˜ëŠ” ì˜ìƒì„ ê·¸ëŒ€ë¡œ ì“°ë©´ ë˜ë¯€ë¡œ annotationì´ í•„ìš”ì—†ëŠ” self-supervised ëª¨ë¸</p>

<p>ì´ë•Œ ì‚¬ìš©ëœ Pretrained ëª¨ë¸ë¡œ</p>

<ol>
  <li>Face Recognition : VGG-Face Model
    <ul>
      <li>ì–¼êµ´ ì‚¬ì§„ì„ 4096-Dì˜ Face Feature vectorë¡œ ë°”ê¿” ì¤Œ</li>
    </ul>
  </li>
  <li>Face Decoder : facenet
    <ul>
      <li>ì–¼êµ´ ì‚¬ì§„ì„ Landmark locationì„ ì´ìš©í•˜ì—¬ ë¬´í‘œì •ìœ¼ë¡œ ë°”ê¿”ì¤Œ</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314142608069.png" alt=""></p>

<p><strong>[img.Speech2Face êµ¬ì¡°]</strong></p>

<p>ì´í›„,</p>

<ol>
  <li>Spectrogram í˜•íƒœë¡œ ë°”ê¾¼ ì‚¬ìš´ë“œ ë°ì´í„°ë¥¼</li>
  <li>Voice Encoderì— ë„£ì–´ ì•ì„œ êµ¬í–ˆë˜ Face Recogntionì˜ Feature dimensionê³¼ ê°™ì€ vectorë¥¼ ìƒì„±í•˜ê³ </li>
  <li>Face featureì™€ ë¹„êµí•˜ì—¬ Lossë¥¼ êµ¬í•˜ì—¬ í•™ìŠµí•œë‹¤.
    <ul>
      <li>ì´ë•Œ, í•™ìŠµë˜ëŠ” ê²ƒì€ Speech2Face Modelì¸ Voice Encoder ë¶€ë¶„ì´ë©°, ê¸°íƒ€ Pretrained ëœ ë¶€ë¶„ì€ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠëŠ”ë‹¤.</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314152015701.png" alt=""></p>

<p><strong>[img. Speech2Faceì—ì„œ í•™ìŠµë˜ëŠ” ë¶€ë¶„]</strong></p>

<ol>
  <li><strong>Image-to-speech synthesis</strong></li>
</ol>

<p>ì‚¬ì§„ì— ëŒ€í•œ ë¬˜ì‚¬ë¥¼ ìŒì„±ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ëŠ” Task, Module network êµ¬ì¡°ë¥¼ í™œìš©</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314161355636.png" alt=""></p>

<p><strong>[img. Image-to-speech Task]</strong></p>

<ol>
  <li>Input Imageë¥¼ 14x14 feature mapìœ¼ë¡œ í˜•ì„± í›„ Attentionì„ í™œìš©í•œ RNN êµ¬ì¡°ì— hidden stateë¡œ ì‚¬ìš©í•œë‹¤.</li>
</ol>

<ul>
  <li>ê¸°ë³¸ì ìœ¼ë¡œ Show, Attend, and Tell êµ¬ì¡°ì™€ ê°™ì§€ë§Œ, subword unitì´ë¼ëŠ” í† í° ë¹„ìŠ·í•œ  ê²ƒì´ output ì´ë‹¤.(Learned Units)</li>
</ul>

<ol>
  <li>í•´ë‹¹ Unitì„ Unit-to-Speech Modelì¸ Tacotron 2ë¥¼ ì´ìš©í•´ subwordë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•œë‹¤.
    <ul>
      <li>ì›ë³¸ Tacotron 2ëŠ” TTS(Text To Speech) ëª¨ë¸, ì¦‰, textë¥¼ inputìœ¼ë¡œ ë°›ì§€ë§Œ ì—¬ê¸°ì„œëŠ” subwordë¥¼ ë°›ëŠ”ë‹¤ëŠ” ì ì´ ë‹¤ë¥´ë‹¤.</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314161515132.png" alt=""></p>

<p><strong>[img. Image to speech Task]</strong></p>

<p>ì´ë•Œ, ìœ„ì˜ ë‘ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´, Pre-trained model(ResDAVEnet-VQ)ì„ ì´ìš©í•´ speechë¥¼ Unitìœ¼ë¡œ ë°”ê¾¸ê³  ì´ë¥¼ Learned Unitsì˜ Ground-Truthë¡œ ì‚¬ìš©í•œë‹¤.</p>

<p>1) ì¦‰ Image-to-Unit Modelì€ Ground-Truth Unitê³¼ ë¹„êµí•˜ì—¬ Lossë¡œ ë‚˜ì™€ì•¼ í•˜ê³ ,</p>

<p>2) Unit-to-Speech Modelì€ Ground-Truth Unitì„ Inputìœ¼ë¡œ ë°›ìœ¼ë©´ Pre-trained model(ResDAVEnet-VQ)ì˜ Input Speechê°€ ë‚˜ì™€ì•¼ í•œë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314205744504.png" alt=""></p>

<p><strong>[img. í•™ìŠµì„ ìœ„í•œ Speech-to-Unit Model]</strong></p>

<h4 id="Cross-modal-reasoning">Cross modal reasoning</h4>

<p><strong>Sound source localization</strong></p>

<p>ì‚¬ìš´ë“œê°€ ì£¼ì–´ì§€ë©´ í•´ë‹¹ ì‚¬ìš´ë“œê°€ ì‚¬ì§„ì˜ ì–´ë–¤ Objectê°€ ë‚´ëŠ”ì§€ ì˜ˆì¸¡í•˜ëŠ” Task</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314220447590.png" alt=""><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314220505377.png" alt=""></p>

<p><strong>[img. Sound source localizationì€ Cross modal Referencingì— ì†í•œë‹¤.]</strong></p>

<p>labelëœ ë°ì´í„°ì˜ ì—¬ë¶€ì— ë”°ë¼ 3ê°€ì§€ ë²„ì „ì´ ìˆìœ¼ë©° ê¸°ì´ˆì ì¸ ê³¼ì •ì€</p>

<p>1) image Inputì„ í†µí•´ì„œ Visual netì—ì„œ WxHxF image feature mapì„ ë‚´ë³´ë‚¸ë‹¤.</p>

<p>2) audio Inputì„ í†µí•´ì„œ Audio netì—ì„œ 1x1xF audio feature mapì„ ë‚´ë³´ë‚¸ë‹¤.</p>

<p>3) image feature mapì˜ ê° pixel ë§ˆë‹¤ audio feature mapì„ ë‚´ì í•˜ì—¬ ê´€ê³„ì„±(attention)ì„ íŒŒì•…í•˜ê³ , ì´ ê²°ê³¼ë¬¼ mapì´ Localization Score mapì´ë‹¤.</p>

<p>ì—¬ê¸°ì„œ ë¶€í„°ëŠ” ê° ë²„ì „ì— ë”°ë¼ ë‹¤ë¥´ë‹¤.</p>

<ol>
  <li>Fully supervised version : labelì´ ëœ ë°ì´í„°ì…‹ì´ ìˆëŠ” ê²½ìš°</li>
</ol>

<p>4) ê²°ê³¼ë¬¼ë¡œ ë‚˜ì˜¨ Localization Scoreë¥¼ Ground-truth Loclization scoreì™€ ë¹„êµí•˜ì—¬ lossë¥¼ êµ¬í•œ ë’¤, Backpropagation í•œë‹¤.</p>

<ol>
  <li>unsupervised verison: labelëœ ë°ì´í„°ì…‹ì´ ì—†ìŒ</li>
</ol>

<ul>
  <li>ë¹„ë””ì˜¤ì—ëŠ” ë³´í†µ Soundê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ëŠ” ì ì„ annotationìœ¼ë¡œ í™œìš©</li>
</ul>

<p>4) 1)ì—ì„œ êµ¬í–ˆë˜ WxHxF image feature mapì„ ê²°ê³¼ë¬¼ì´ì—ˆë˜ Localization Score mapê³¼ Weighted sum poolingí•˜ì—¬ 1x1xFì˜ Attended visual featureë¥¼ ë§Œë“ ë‹¤.</p>

<p>5) Audio netì—ì„œ ë§Œë“  1x1xF audio feature mapê³¼ ë¹„êµí•´ì„œ metric learn Lossë¥¼ êµ¬í•œë‹¤.</p>

<ul>
  <li>ê°™ì€ ë¹„ë””ì˜¤ì—ì„œ ë‚˜ì˜¨ ì†Œë¦¬ë©´ positive pair</li>
  <li>ë‹¤ë¥¸ ë¹„ë””ì˜¤ì—ì„œ ë‚˜ì˜¨ ì†Œë¦¬ë©´ negative pairë¡œ ì´ìš©í•œë‹¤.</li>
  <li>ì—¬ëŸ¬ ì˜ìƒì—ì„œ íŠ¹ì • ì‚¬ìš´ë“œê°€ ë‚˜ì˜¬ ë•Œë§ˆë‹¤ ë¹„ìŠ·í•œ image feature mapì´ ë‚˜ì˜¨ë‹¤ë©´, ê·¸ image feature mapì˜ ê°€ì¤‘ì¹˜ê°€ ë†’ì€ ì§€ì ì´ sound sourceì´ê¸° ë•Œë¬¸</li>
</ul>

<ol>
  <li>semisupervised version: labelëœ ë°ì´í„°ì…‹ì´ ìˆì§€ë§Œ Audio net outputê³¼ë„ ë¹„êµí•¨</li>
</ol>

<p>4) 1. 2. ë°©ë²•ì„ ì „ë¶€ ì‚¬ìš©í•˜ì—¬ lossë¥¼ 2ê°œë¥¼ êµ¬í•˜ê³  ë§ì¶°ë³¸ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314225611105.png" alt=""></p>

<p><strong>[img. Sound source localizationì˜ ì—¬ëŸ¬ê°€ì§€ ë²„ì „]</strong></p>

<p><strong>Speech separation</strong></p>

<p>ë™ì‹œì— ë§í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ë§ì„ ê°ê° 1ì‚¬ëŒì”© ë§í•˜ëŠ” Audioë¥¼ ê°€ì ¸ì˜¤ëŠ” Task</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314225228243.png" alt=""></p>

<p><strong>[img. Speech separation]</strong></p>

<p>Dataset í•„ìš”í•œ Supervised Learningì´ë©°, ì´ë•Œ ë°ì´í„°ì…‹ì€ ë‹¨ìˆœíˆ ëª©ì†Œë¦¬ 2ê°œë¥¼ ê²¹ì³ì„œ ë§Œë“¤ ìˆ˜ ìˆë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ê³¼ì •</th>
      <th style="text-align: center">ë„ì‹</th>
      <th style="text-align: left">ì„¤ëª…</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">Visual<br>stream</td>
      <td style="text-align: center"><img src="image-20210314235141102.png" alt="image-20210314235141102"></td>
      <td style="text-align: left">Nê°œì˜ ë‚˜ëˆŒ ì‚¬ëŒ ë§Œí¼, <br>Face Embeddingì„ í†µí•´ <br>ê°ì featureë¥¼ êµ¬í•œë‹¤.</td>
    </tr>
    <tr>
      <td style="text-align: center">Audio<br>stream</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314235235719.png" alt=""></td>
      <td style="text-align: left">Audio Spectrogramìœ¼ë¡œ<br> speech featureë¥¼ êµ¬í•œë‹¤.</td>
    </tr>
    <tr>
      <td style="text-align: center">Audio-visual<br>fusion</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210314235245107.png" alt=""></td>
      <td style="text-align: left">ìœ„ì—ì„œ êµ¬í•œ featureë“¤ì„<br> concatí•œ ë’¤, Nê°œì˜ <br>complex maskë¥¼ ë½‘ì•„ë‚¸ë‹¤.</td>
    </tr>
    <tr>
      <td style="text-align: center">output</td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315000341431.png" alt=""></td>
      <td style="text-align: left">ì˜¤ë¦¬ì§€ë„ spectrogramê³¼ <br>maskë¥¼ ê³±í•´ í•„í„°ë§ ê²°ê³¼ <br>spectrogramì„ ISTFTë¡œ<br>waveformìœ¼ë¡œ ë°”ê¾¼ ë’¤,<br>ì›ë³¸ê³¼ ë¹„êµí•´ì„œ L2 Lossë¥¼ êµ¬í•˜ì—¬ í•™ìŠµ</td>
    </tr>
  </tbody>
</table>

<p><strong>[table. Speech separation ê³¼ì •]</strong></p>

<p>ì´ì™¸ì—ë„ Cross modal taskë¡œ, Lip movements generation, Tesla self-driving ë“±ì´ ìˆë‹¤.</p>

<h2 id="3D-undersanding">3D undersanding</h2>

<h3 id="Seeing-the-world-in-3D-perspective">Seeing the world in 3D perspective</h3>

<p>ìš°ë¦¬ëŠ” 3D ì„¸ìƒì— ì‚´ê³  ìˆê¸° ë•Œë¬¸ì—, 3D ê³µê°„ì— ëŒ€í•œ ì´í•´ê°€ ì¤‘ìš”í•˜ë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">ì˜ˆì‹œ</th>
      <th>ì˜ì—­</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085123440.png" alt=""></td>
      <td>VR</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085130426.png" alt=""></td>
      <td>AR</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085154016.png" alt=""></td>
      <td>3D Print</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085207489.png" alt=""></td>
      <td>Medical</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085217203.png" alt=""></td>
      <td>Bio</td>
    </tr>
  </tbody>
</table>

<p><strong>[img. 3Dë¥¼ í™œìš©í•˜ëŠ” ì˜ì—­ì˜ ì˜ˆì‹œ]</strong></p>

<p>ë¹›ì€ ì§ì§„ì„±ì„ ë„ê¸° ë•Œë¬¸ì— 3Dì˜ í˜•íƒœëŠ” 2ì°¨ì›ì— í‘œí˜„ì´ ê°€ëŠ¥í•˜ë©°, ìš°ë¦¬ê°€ ì‹¤ì œë¡œ 3D ë¬¼ì²´ë¥¼ ì¸ì‹í•˜ëŠ” ë°©ë²•ì€ 3D worldë¥¼ 2D spaceì— projectioní•˜ëŠ” imageì´ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085444009.png" alt=""></p>

<p><strong>[img. ì›ê·¼ì— ëŒ€í•œ ì—°êµ¬ì™€ ê³¼ê±°ì™€ í˜„ì¬ì˜ ê²°ì‹¤]</strong></p>

<p>3ì°¨ì› ê³µê°„ì„ 2ì°¨ì› ê³µê°„ì— í‘œí˜„í•˜ëŠ” ê²ƒì„ Projectionì„ í†µí•˜ì—¬ ê°€ëŠ¥í–ˆë‹¤ë©´, ë°˜ëŒ€ë¡œ 2ì°¨ì› ê³µê°„ì˜ ì •ë³´ë¥¼ ì´ìš©í•´ 3ì°¨ì› ê³µê°„ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒì€ Triangulationìœ¼ë¡œ ê°€ëŠ¥í•˜ë‹¤.</p>

<ul>
  <li>2ì¥ ì´ìƒì˜ ì´ë¯¸ì§€ì—ì„œ 3D pintì˜ í•œ ì ì˜ pixel ì´ë™ê°’ê³¼ ì´ë¯¸ì§€ë¥¼ ì´¬ì˜í–ˆë˜ ìœ„ì¹˜ë¥¼ ì•Œê³  ìˆìœ¼ë©´ Triangulationì„ í†µí•´ ì´ë¡ ìƒ 3D ëª¨ë¸ì„ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315085636357.png" alt=""></p>

<p><strong>[img. Triangulationì˜ ì˜ˆì‹œ]</strong></p>

<p>2ì°¨ì› ì´ë¯¸ì§€ëŠ” ê° í”½ì…€ì„ ì˜ë¯¸í•˜ëŠ” 2ì°¨ì› arrayì— RGB ê°’ì„ ì €ì¥í•¨ìœ¼ë¡œì¨ í‘œí˜„ ê°€ëŠ¥í•˜ë‹¤.</p>

<p>3ì°¨ì› ë°ì´í„°ì˜ í‘œí˜„ì€ ì—¬ëŸ¬ê°€ì§€ ë°©ë²•ì´ ìˆë‹¤.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">&nbsp;</th>
      <th style="text-align: center">3D ë°ì´í„° í‘œí˜„ ì˜ˆì‹œ</th>
      <th style="text-align: center">&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090240429.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090245681.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090252859.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">Multi-view images</td>
      <td style="text-align: center">Volumetric(voxel)</td>
      <td style="text-align: center">Part assembly</td>
    </tr>
    <tr>
      <td style="text-align: center">2ì°¨ì› ì´ë¯¸ì§€ ì—¬ëŸ¬ì¥</td>
      <td style="text-align: center">3ì°¨ì› array</td>
      <td style="text-align: center">ê¸°ë³¸ 3D ë„í˜•ì˜ ì§‘í•©</td>
    </tr>
    <tr>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090258370.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090304829.png" alt=""></td>
      <td style="text-align: center"><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090329872.png" alt=""></td>
    </tr>
    <tr>
      <td style="text-align: center">Point cloud</td>
      <td style="text-align: center">Mesh (Graph CNN)</td>
      <td style="text-align: center">Implicit shape(function)</td>
    </tr>
    <tr>
      <td style="text-align: center">3ì°¨ì› Point ë“¤ì˜ ì§‘í•©</td>
      <td style="text-align: center">Vertexì˜ ì‚¼ê° edge</td>
      <td style="text-align: center">ê³ ì°¨ì›ì˜ í•¨ìˆ˜</td>
    </tr>
  </tbody>
</table>

<p><strong>[img. 3Dì˜ ë‹¤ì–‘í•œ í‘œí˜„ ë°©ë²•ë“¤]</strong></p>

<h4 id="3D-datasets">3D datasets</h4>

<p><strong>ShapeNet</strong></p>

<p>ëŒ€ìš©ëŸ‰ 3D model ë°ì´í„°ì…‹(51,300ê°œ, 55 ì¹´í…Œê³ ë¦¬)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315090929981.png" alt=""></p>

<p><strong>[img. ShapeNetì˜ objectë“¤]</strong></p>

<p><strong>PartNet(ShapeNetPart2019)</strong></p>

<p>ShapeNetì˜ ê°œëŸ‰, ì¶”ê°€ë¡œ Detailì´ annotation ë˜ì–´ìˆìŒ(ex)ìë™ì°¨ ëª¨ë¸ -&gt; ìë™ì°¨ ë°”í€´, ì°½ë¬¸, ì²œì¥ ë“±ì´ ë”°ë¡œ ë‚˜ëˆ ì§)</p>

<p>(26,671ê°œì˜ 3D model ì´ 573,585ê°œì˜ partë¡œ ë‚˜ëˆ ì§)</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315091038307.png" alt=""></p>

<p><strong>[img. PartNet ì˜ˆì‹œë“¤]</strong></p>

<p><strong>SceneNet</strong></p>

<p>500ë§Œê°œì˜ ëœë¤í•˜ê²Œ Generationëœ RGB-Depth Indoor imageë“¤</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315091318160.png" alt=""></p>

<p><strong>[img. SceneNet, ëœë¤í•˜ê²Œ ë§Œë“¤ì–´ì§]</strong></p>

<p><strong>ScanNet</strong></p>

<p>RGB-Depth 250ë§Œê°œì˜ ì‹¤ì œ Indoor scan data</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315091502679.png" alt=""></p>

<p><strong>[img. ScanNet]</strong></p>

<p><strong>Outdoor 3D scene datasets</strong></p>

<p>ì£¼ë¡œ ììœ¨ì£¼í–‰ì„ ìœ„í•œ ì•¼ì™¸ ë°ì´í„°ì…‹ë“¤, Lidarë¡œ ìŠ¤ìº”í•œ ê²ƒì´ ë§ìŒ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315091528122.png" alt=""></p>

<p><strong>[img. Outdoor 3D scene ëª¨ìŒ]</strong></p>

<h3 id="3D-tasks">3D tasks</h3>

<p>2ì°¨ì› classificationì´ë‚˜ object detection, semantic segmentation ë“±, 3Dì—ë„ ê°™ì€ Taskê°€ ìˆë‹¤.</p>

<p>ììœ¨ì£¼í–‰, ì˜ë£Œ, ì œì¡°ì—… ë“±ì— í™œë°œíˆ ì‚¬ìš© ì¤‘</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315093050546.png" alt=""><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315093057024.png" alt=""></p>

<p><strong>[img. 3D taskì˜ ì˜ˆì‹œ]</strong></p>

<p><strong>Mesh R-CNN</strong></p>

<p>2D imageë¥¼ ì…ë ¥ìœ¼ë¡œ ê°ì§€ëœ objectì˜ 3D ë©”ì‰¬ë¥¼ ì¶œë ¥</p>

<p>Mask R-CNN êµ¬ì¡°ë¥¼ ë³€ê²½í•´ì„œ êµ¬í˜„</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315094811949.png" alt=""></p>

<p><strong>[img. Mesh R-CNN ì˜ˆì‹œ]</strong></p>

<p>Mesh R-CNNì€ ê¸°ì¡´ì˜ Mask R-CNNì— 3D meshë¥¼ ì¶œë ¥í•˜ëŠ” 3D branchê°€ ì¶”ê°€ëœ í˜•íƒœ</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315095019376.png" alt=""></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315095042922.png" alt=""></p>

<p><strong>[imgs. Mask R-CNN VS Mesh R-CNN]</strong></p>

<p>3D meshë¥¼ ìƒì„±í•˜ëŠ” ë¬¸ì œë¥¼ ì¡°ê¸ˆë” ì‘ì€ ì—¬ëŸ¬ê°œì˜ ë¶€ ë¬¸ì œë¡œ ë‚˜ëˆ„ì–´ í•´ê²°í•˜ì—¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¼ ìˆ˜ ìˆë‹¤.</p>

<ul>
  <li>normal map, depth map, silhouette ê²€ì¶œ -&gt; 3D ì˜¤ë¸Œì íŠ¸ ìƒì„±</li>
  <li>Depth íƒì§€-&gt; Spherical map(ì–´ëŠ í•œì ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¼ì²´ë¥¼ ë³´ì•˜ì„ ë•Œì˜ ì´ë¯¸ì§€) ìƒì„± -&gt; voxelí™” -&gt; 3D meshí™”</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315095118571.png" alt=""></p>

<p><strong>[img. ë” ë³µì¡í•˜ê³  ì •í™•í•œ  3D mesh ìƒì„±ë²•]</strong></p>

<h3 id="3D-application-example-Photo-refocusing">3D application example- Photo refocusing</h3>

<p>ì‚¬ì§„ì˜ depth mapì„ ì´ìš©í•˜ì—¬ ì‚¬ì§„ì˜ focusë¥¼ ë°”ê¾¸ëŠ” application</p>

<p>Photo refocusing ë˜ëŠ” post-refocusingì´ë¼ê³ ë„ í•¨.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315101738298.png" alt=""></p>

<p><strong>[img. ì•ì˜ ì¡°ê°ìƒì— focusing ëœ ì‚¬ì§„]</strong></p>

<p>depth mapì€ depth sensorë‚˜ neural networkë¥¼ ì´ìš©í•´ ê²€ì¶œ ê°€ëŠ¥í•˜ë‹¤.</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315101921972.png" alt=""></p>

<p><strong>[img. ì‚¬ì§„ì˜ depth map]</strong></p>

<p><strong>êµ¬í˜„ ê³¼ì •</strong></p>

<ol>
  <li>depth thrshold range ìµœì†Œì¹˜ ~ ìµœëŒ€ì¹˜($D_{min}\sim D_{max}$)ë¥¼ ì •í•˜ê¸°</li>
</ol>

<ul>
  <li>ì¦‰ $D_{min}\sim D_{max}$ê¹Œì§€ë§Œ focusí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” blur ì²˜ë¦¬í•˜ê² ë‹¤ëŠ” ì˜ë¯¸</li>
</ul>

<p>ìš°ë¦¬ì˜ ê²½ìš° 0~255ë¡œ í‘œí˜„í•¨</p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315103416424.png" alt=""></p>

<p><strong>[img.  depthmap ì˜ˆì‹œ]</strong></p>

<ol>
  <li>depth map thresholdingìœ¼ë¡œ masking
    <ul>
      <li>focusingí•  focusing areaì™€ blur ì²˜ë¦¬í•  defocsing areaë¡œ ë§ˆìŠ¤í‚¹</li>
    </ul>
  </li>
</ol>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315103523577.png" alt=""></p>

<p><strong>[img. Thresholdê°€ 170ì¼ ë•Œì˜ masking]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">focus_mask</span> <span class="o">=</span> <span class="n">depth_map</span><span class="p">[...,</span> <span class="p">:]</span> <span class="o">&amp;</span><span class="c1">#38;#62; threshold_value
</span><span class="n">defocus_mask</span> <span class="o">=</span> <span class="n">depth_map</span><span class="p">[...,</span> <span class="p">:]</span> <span class="o">&amp;</span><span class="c1">#38;#60;= threshold_value
</span>
</code></pre></div></div>
<p><strong>[img. masking code ì˜ˆì‹œ]</strong></p>

<ol>
  <li>blurrë²„ì „ì˜ imageë¥¼ ìƒì„±</li>
</ol>

<ul>
  <li>Depthì— ë”°ë¼ adaptiveí•˜ê²Œ ì ìš©í•˜ëŠ” ë°©ë²•ë„ ìˆìŒ</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315103745583.png" alt=""></p>

<p><strong>[img. Blur kernalì„ ì´ìš©í•œ image]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">blurred_image</span><span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="n">blur</span><span class="p">(</span><span class="n">original_image</span><span class="p">,</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>

</code></pre></div></div>
<p><strong>[code. cv2ë¥¼ ì´ìš©í•œ blur ì²˜ë¦¬]</strong></p>

<ol>
  <li>Masked focused imageì™€ Masked defocused imageë¥¼ ìƒì„±í•˜ê³  ì´ë¯¸ì§€ blendingì„ í†µí•´ refocusedëœ ì´ë¯¸ì§€ ìƒì„±</li>
</ol>

<ul>
  <li>ê°„ë‹¨í•œ image arrayì˜ ì—°ì‚°ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥</li>
</ul>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315104240365.png" alt=""></p>

<p><strong>[img. Masked images]</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">focused_with_mask</span> <span class="o">=</span> <span class="n">focus_mask</span> <span class="o">*</span> <span class="n">original_image</span>
<span class="n">defocused_with_mask</span> <span class="o">=</span> <span class="n">defocus_mask</span> <span class="o">*</span> <span class="n">blurred_image</span>

</code></pre></div></div>
<p><strong>[code. Masked Image ìƒì„± ì½”ë“œ]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315104319659.png" alt=""></p>

<p><strong>[img. ê²°ê³¼ë¬¼ blend]</strong></p>

<p><img src="/assets/img/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸/image-20210315104654349.png" alt=""></p>

<p><strong>[img. Thresholdì— ë”°ë¥¸ blur ì°¨ì´]</strong></p>

</body></html>
</div>

  </div><a class="u-url" href="/articles/AI/CV/%EC%BB%B4%ED%93%A8%ED%84%B0%EB%B9%84%EC%A0%84%20%EA%B8%B0%EB%B3%B8.html" hidden></a>
  <p class="u-path" hidden>_articles/AI/CV/ì»´í“¨í„°ë¹„ì „ ê¸°ë³¸.md</p>
  <script type="module" src="/assets/scripts/utils/update_recents.js"></script>
</article>

    </div>
  </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">ğŸ§ SUBBRAIN</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="a-name">ğŸ§ SUBBRAIN</li><li><a class="u-email" href="mailto:roadvirushn@gmail.com">roadvirushn@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li>
    <a href="https://github.com/RoadVirusHN"><svg class="svg-icon">
        <use xlink:href="/assets/svg/social-icons.svg#github"></use>
      </svg>
      <span class="username">RoadVirusHN</span></a>
  </li><!---->
</ul></div>

      <div class="footer-col footer-col-3">
        <p>ì´ê²ƒì´ ë””ì§€í„¸ ë™ë¬¼ì˜ ìˆ²ì´ë‹¤!! íŒŒë©¸í¸ (This is the Digital Animal Crossing!! Bad Ending.01)</p>
      </div>
    </div>

  </div>

</footer>
</body>

<script src="/assets/scripts/bundle/common.bundle.js"></script>

</html>